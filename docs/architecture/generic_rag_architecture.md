# Generic RAG ç³»ç»Ÿæ¶æ„è®¾è®¡

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [å®Œæ•´æ¶æ„å›¾](#å®Œæ•´æ¶æ„å›¾)
- [åˆ†å±‚æ¶æ„è®¾è®¡](#åˆ†å±‚æ¶æ„è®¾è®¡)
- [æ ¸å¿ƒè®¾è®¡åŸåˆ™](#æ ¸å¿ƒè®¾è®¡åŸåˆ™)
- [è¯¦ç»†æµç¨‹è¯´æ˜](#è¯¦ç»†æµç¨‹è¯´æ˜)
- [æ¨èç›®å½•ç»“æ„](#æ¨èç›®å½•ç»“æ„)
- [å…³é”®æŠ€æœ¯é€‰å‹](#å…³é”®æŠ€æœ¯é€‰å‹)
- [æ¥å£è®¾è®¡](#æ¥å£è®¾è®¡)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æ‰©å±•ç‚¹](#æ‰©å±•ç‚¹)

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°äº†ä¸€ä¸ª**é€šç”¨çš„ã€å¯æ‰©å±•çš„ã€ç”Ÿäº§çº§åˆ«çš„ RAG (Retrieval-Augmented Generation)** ç³»ç»Ÿæ¶æ„ã€‚è¯¥æ¶æ„åŸºäº **LangChain** å’Œ **LangGraph** æ„å»ºï¼Œæ”¯æŒä»ç®€å•çš„é—®ç­”åˆ°å¤æ‚çš„ Agent æ¨ç†ç­‰å¤šç§åœºæ™¯ã€‚

### æ ¸å¿ƒç‰¹æ€§

âœ… **æ¨¡å—åŒ–è®¾è®¡**: æ‰€æœ‰ç»„ä»¶å¯æ’æ‹”ã€å¯æ›¿æ¢  
âœ… **å¤šç§æ£€ç´¢ç­–ç•¥**: å‘é‡ã€æ··åˆã€çˆ¶å­æ–‡æ¡£ç­‰  
âœ… **æ™ºèƒ½è·¯ç”±**: æ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³ pipeline  
âœ… **æµå¼è¾“å‡º**: æ”¯æŒå®æ—¶å“åº”  
âœ… **è‡ªæˆ‘çº æ­£**: å¹»è§‰æ£€æµ‹å’Œç­”æ¡ˆéªŒè¯  
âœ… **å…¨é“¾è·¯å¯è§‚æµ‹**: é›†æˆ LangSmith/OpenTelemetry  
âœ… **å¯¹è¯è®°å¿†**: æ”¯æŒå¤šè½®å¯¹è¯  
âœ… **Agentic RAG**: æ”¯æŒå·¥å…·è°ƒç”¨å’Œå¤æ‚æ¨ç†  

---

## å®Œæ•´æ¶æ„å›¾

### Query â†’ Response å…¨æµç¨‹æ¶æ„

```mermaid
graph TB
    Start([ç”¨æˆ·æŸ¥è¯¢]) --> API[API Gateway<br/>FastAPI/REST]
    
    API --> Auth{è®¤è¯&é™æµ}
    Auth -->|Pass| QueryPreprocess[æŸ¥è¯¢é¢„å¤„ç†<br/>â€¢ è¯­è¨€æ£€æµ‹<br/>â€¢ æ„å›¾è¯†åˆ«<br/>â€¢ å»å™ªæ¸…æ´—]
    Auth -->|Fail| Return401[è¿”å› 401]
    
    QueryPreprocess --> Router{æ™ºèƒ½è·¯ç”±<br/>Query Router}
    
    Router -->|ç®€å•é—®å€™| DirectResponse[ç›´æ¥å“åº”<br/>æ— éœ€æ£€ç´¢]
    Router -->|äº‹å®æŸ¥è¯¢| RAGPipeline[RAG Pipeline]
    Router -->|å¤æ‚æ¨ç†| AgenticRAG[Agentic RAG]
    Router -->|å¯¹è¯ä¸Šä¸‹æ–‡| ConversationalRAG[Conversational RAG]
    
    %% === RAG Pipeline è¯¦ç»†æµç¨‹ ===
    RAGPipeline --> LoadMemory[åŠ è½½å¯¹è¯è®°å¿†<br/>Conversation History]
    LoadMemory --> QueryTransform[æŸ¥è¯¢è½¬æ¢<br/>Query Transformation]
    
    QueryTransform --> MultiQuery[å¤šæŸ¥è¯¢ç”Ÿæˆ]
    QueryTransform --> StepBack[Step-back æŠ½è±¡åŒ–]
    QueryTransform --> Decompose[å¤æ‚æŸ¥è¯¢åˆ†è§£]
    
    MultiQuery --> MergeQueries[åˆå¹¶æŸ¥è¯¢]
    StepBack --> MergeQueries
    Decompose --> MergeQueries
    
    MergeQueries --> RetrievalLayer{æ£€ç´¢å±‚<br/>Retrieval Strategy}
    
    %% === æ£€ç´¢ç­–ç•¥ ===
    RetrievalLayer -->|å‘é‡æ£€ç´¢| VectorSearch[(å‘é‡æ•°æ®åº“<br/>FAISS/Weaviate/Qdrant)]
    RetrievalLayer -->|æ··åˆæ£€ç´¢| HybridSearch[æ··åˆæ£€ç´¢<br/>Vector + BM25]
    RetrievalLayer -->|çˆ¶å­æ–‡æ¡£| ParentChild[çˆ¶å­æ–‡æ¡£æ£€ç´¢]
    
    VectorSearch --> RetrievalResults[æ£€ç´¢ç»“æœé›†åˆ]
    HybridSearch --> RetrievalResults
    ParentChild --> RetrievalResults
    
    RetrievalResults --> CheckCache{ç¼“å­˜æ£€æŸ¥<br/>Redis Cache}
    CheckCache -->|Cache Hit| CachedDocs[è¿”å›ç¼“å­˜æ–‡æ¡£]
    CheckCache -->|Cache Miss| FetchDocs[è·å–å®Œæ•´æ–‡æ¡£]
    
    CachedDocs --> MergeDocs[åˆå¹¶æ–‡æ¡£ç»“æœ]
    FetchDocs --> MergeDocs
    
    %% === æ–‡æ¡£å¤„ç† ===
    MergeDocs --> DocProcessing[æ–‡æ¡£åå¤„ç†]
    DocProcessing --> Dedup[å»é‡<br/>Document Deduplication]
    Dedup --> MMR[å¤šæ ·æ€§ä¼˜åŒ–<br/>MMR Filtering]
    MMR --> ContextCompression[ä¸Šä¸‹æ–‡å‹ç¼©<br/>Contextual Compression]
    
    ContextCompression --> Reranker{é‡æ’åºå™¨<br/>Reranker}
    
    Reranker -->|CrossEncoder| CrossEncoderRank[Cross-Encoder<br/>æ·±åº¦è¯­ä¹‰åŒ¹é…]
    Reranker -->|LLM Rerank| LLMRank[LLM-based Reranking]
    Reranker -->|Score Based| ScoreRank[åŸºäºåˆ†æ•°æ’åº]
    
    CrossEncoderRank --> TopKDocs[Top-K æ–‡æ¡£]
    LLMRank --> TopKDocs
    ScoreRank --> TopKDocs
    
    %% === ç”Ÿæˆé˜¶æ®µ ===
    TopKDocs --> PromptConstruction[Prompt æ„å»º]
    PromptConstruction --> AddContext[æ·»åŠ ä¸Šä¸‹æ–‡æ–‡æ¡£]
    AddContext --> AddHistory[æ·»åŠ å¯¹è¯å†å²]
    AddHistory --> AddInstructions[æ·»åŠ ç³»ç»ŸæŒ‡ä»¤]
    
    AddInstructions --> LLMGeneration{LLM ç”Ÿæˆå™¨}
    
    LLMGeneration -->|æµå¼| StreamGeneration[æµå¼ç”Ÿæˆ<br/>Streaming Response]
    LLMGeneration -->|æ‰¹é‡| BatchGeneration[æ‰¹é‡ç”Ÿæˆ<br/>Batch Response]
    
    StreamGeneration --> SelfCorrect{è‡ªæˆ‘çº æ­£<br/>Self-Correction}
    BatchGeneration --> SelfCorrect
    
    SelfCorrect -->|éœ€è¦çº æ­£| Hallucination[å¹»è§‰æ£€æµ‹<br/>Hallucination Check]
    SelfCorrect -->|æ— éœ€çº æ­£| FinalAnswer[æœ€ç»ˆç­”æ¡ˆ]
    
    Hallucination --> CheckFaithfulness{å¿ å®åº¦æ£€æŸ¥}
    CheckFaithfulness -->|ä¸å¿ å®| RetrieveAgain[é‡æ–°æ£€ç´¢<br/>Retry Loop]
    CheckFaithfulness -->|å¿ å®| FinalAnswer
    
    RetrieveAgain --> RetrievalLayer
    
    %% === Agentic RAG åˆ†æ”¯ ===
    AgenticRAG --> PlanningAgent[è§„åˆ’ Agent<br/>Task Decomposition]
    PlanningAgent --> ToolSelection{å·¥å…·é€‰æ‹©}
    
    ToolSelection --> SearchTool[è¯­ä¹‰æœç´¢å·¥å…·]
    ToolSelection --> SummaryTool[æ–‡æ¡£æ€»ç»“å·¥å…·]
    ToolSelection --> CompareTool[æ–‡æ¡£å¯¹æ¯”å·¥å…·]
    ToolSelection --> CalculatorTool[è®¡ç®—å™¨å·¥å…·]
    
    SearchTool --> AgentExecution[Agent æ‰§è¡Œå¾ªç¯<br/>ReAct Pattern]
    SummaryTool --> AgentExecution
    CompareTool --> AgentExecution
    CalculatorTool --> AgentExecution
    
    AgentExecution --> AgentDecision{Agent å†³ç­–}
    AgentDecision -->|éœ€è¦æ›´å¤šä¿¡æ¯| ToolSelection
    AgentDecision -->|ä»»åŠ¡å®Œæˆ| FinalAnswer
    
    %% === Conversational RAG åˆ†æ”¯ ===
    ConversationalRAG --> ConvMemory[å¯¹è¯è®°å¿†ç®¡ç†<br/>Memory Management]
    ConvMemory --> MemoryType{è®°å¿†ç±»å‹}
    
    MemoryType --> BufferMemory[ç¼“å†²è®°å¿†<br/>Buffer Memory]
    MemoryType --> SummaryMemory[æ‘˜è¦è®°å¿†<br/>Summary Memory]
    MemoryType --> KnowledgeGraph[çŸ¥è¯†å›¾è°±è®°å¿†<br/>KG Memory]
    
    BufferMemory --> ConvRetrieval[å¯¹è¯å¼æ£€ç´¢]
    SummaryMemory --> ConvRetrieval
    KnowledgeGraph --> ConvRetrieval
    
    ConvRetrieval --> RAGPipeline
    
    %% === ç›´æ¥å“åº” ===
    DirectResponse --> FinalAnswer
    
    %% === åå¤„ç† ===
    FinalAnswer --> PostProcess[åå¤„ç†<br/>Post-Processing]
    PostProcess --> Citation[æ·»åŠ å¼•ç”¨æ¥æº<br/>Citation]
    Citation --> Formatting[æ ¼å¼åŒ–è¾“å‡º<br/>Markdown/JSON]
    Formatting --> Metadata[æ·»åŠ å…ƒæ•°æ®<br/>â€¢ ç½®ä¿¡åº¦<br/>â€¢ æ¥æºæ–‡æ¡£<br/>â€¢ å»¶è¿Ÿç»Ÿè®¡]
    
    %% === å¯è§‚æµ‹æ€§ ===
    Metadata --> Observability[å¯è§‚æµ‹æ€§å±‚<br/>Observability]
    Observability --> Logging[æ—¥å¿—è®°å½•<br/>Structured Logging]
    Observability --> Tracing[é“¾è·¯è¿½è¸ª<br/>LangSmith Tracing]
    Observability --> Metrics[æŒ‡æ ‡æ”¶é›†<br/>Prometheus Metrics]
    
    Logging --> Monitoring[(ç›‘æ§ç³»ç»Ÿ<br/>Monitoring)]
    Tracing --> Monitoring
    Metrics --> Monitoring
    
    %% === ç¼“å­˜æ›´æ–° ===
    Metadata --> UpdateCache[æ›´æ–°ç¼“å­˜<br/>Cache Update]
    UpdateCache --> FeedbackLoop[åé¦ˆå¾ªç¯<br/>Feedback Loop]
    
    %% === æœ€ç»ˆå“åº” ===
    FeedbackLoop --> ResponseFormat{å“åº”æ ¼å¼}
    ResponseFormat -->|JSON| JSONResponse[JSON Response]
    ResponseFormat -->|Stream| StreamResponse[SSE Stream]
    ResponseFormat -->|WebSocket| WSResponse[WebSocket]
    
    JSONResponse --> APIResponse[API Response]
    StreamResponse --> APIResponse
    WSResponse --> APIResponse
    
    APIResponse --> End([è¿”å›ç”¨æˆ·])
    Return401 --> End
    
    %% === å¼‚æ­¥ä»»åŠ¡ ===
    Monitoring -.->|å¼‚æ­¥| Analytics[(åˆ†æå­˜å‚¨<br/>Analytics DB)]
    FeedbackLoop -.->|å¼‚æ­¥| TrainingData[(è®­ç»ƒæ•°æ®<br/>Fine-tuning Data)]
    
    %% æ ·å¼å®šä¹‰
    classDef startEnd fill:#e1f5e1,stroke:#4caf50,stroke-width:3px
    classDef process fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    classDef storage fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    classDef critical fill:#ffebee,stroke:#f44336,stroke-width:2px
    
    class Start,End startEnd
    class API,QueryPreprocess,LoadMemory,QueryTransform,DocProcessing,PromptConstruction,PostProcess,Observability process
    class Router,RetrievalLayer,CheckCache,Reranker,LLMGeneration,SelfCorrect,CheckFaithfulness,AgentDecision,MemoryType,ResponseFormat decision
    class VectorSearch,HybridSearch,ParentChild,Monitoring,Analytics,TrainingData storage
    class Hallucination,RetrieveAgain critical
```

---

## åˆ†å±‚æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Layer (FastAPI)                       â”‚
â”‚  â€¢ REST endpoints                                            â”‚
â”‚  â€¢ Streaming support (SSE)                                   â”‚
â”‚  â€¢ WebSocket for real-time                                   â”‚
â”‚  â€¢ Authentication & Rate Limiting                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Orchestration Layer (LangGraph)                 â”‚
â”‚  â€¢ Query routing (æ™ºèƒ½è·¯ç”±)                                   â”‚
â”‚  â€¢ Workflow management                                        â”‚
â”‚  â€¢ Human-in-the-loop                                         â”‚
â”‚  â€¢ Error handling & retry                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Core RAG Components                           â”‚
â”‚  â€¢ Retriever (pluggable)         â€¢ Memory (conversation)    â”‚
â”‚  â€¢ Query Transformer             â€¢ Reranker (optional)       â”‚
â”‚  â€¢ Generator (LLM)               â€¢ Cache Manager             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Infrastructure Layer                            â”‚
â”‚  â€¢ Vector stores (FAISS/Weaviate/Qdrant)                    â”‚
â”‚  â€¢ Cache (Redis/in-memory)                                   â”‚
â”‚  â€¢ Metrics & Observability (LangSmith/OpenTelemetry)        â”‚
â”‚  â€¢ Document stores (PostgreSQL/MongoDB)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ ¸å¿ƒè®¾è®¡åŸåˆ™

### 1. æ¥å£æŠ½è±¡ (Interface Abstraction)

æ‰€æœ‰æ ¸å¿ƒç»„ä»¶éƒ½åŸºäºæ¥å£è®¾è®¡ï¼Œæ”¯æŒå¤šç§å®ç°ï¼š

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any
from pydantic import BaseModel

class Document(BaseModel):
    """é€šç”¨æ–‡æ¡£æ¨¡å‹"""
    page_content: str
    metadata: Dict[str, Any]
    score: float = 0.0

class RetrieverInterface(ABC):
    """æ£€ç´¢å™¨æ¥å£"""
    @abstractmethod
    async def retrieve(self, query: str, top_k: int) -> List[Document]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        pass

class RerankerInterface(ABC):
    """é‡æ’åºæ¥å£"""
    @abstractmethod
    async def rerank(self, query: str, documents: List[Document]) -> List[Document]:
        """å¯¹æ–‡æ¡£é‡æ–°æ’åº"""
        pass

class GeneratorInterface(ABC):
    """ç”Ÿæˆå™¨æ¥å£"""
    @abstractmethod
    async def generate(
        self, 
        query: str, 
        context: List[Document],
        stream: bool = False
    ) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        pass

class MemoryInterface(ABC):
    """è®°å¿†æ¥å£"""
    @abstractmethod
    async def save_context(self, inputs: Dict, outputs: Dict):
        """ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡"""
        pass
    
    @abstractmethod
    async def load_memory(self) -> List[Dict]:
        """åŠ è½½å†å²è®°å¿†"""
        pass
```

### 2. å·¥å‚æ¨¡å¼ (Factory Pattern)

ä½¿ç”¨å·¥å‚æ¨¡å¼åˆ›å»ºä¸åŒçš„ç»„ä»¶å®ç°ï¼š

```python
from enum import Enum

class RetrieverType(str, Enum):
    VECTOR = "vector"
    HYBRID = "hybrid"
    MULTI_QUERY = "multi_query"
    ENSEMBLE = "ensemble"
    PARENT_CHILD = "parent_child"

class RetrieverFactory:
    """æ£€ç´¢å™¨å·¥å‚"""
    
    @staticmethod
    def create(
        retriever_type: RetrieverType,
        config: Dict[str, Any]
    ) -> RetrieverInterface:
        if retriever_type == RetrieverType.VECTOR:
            return VectorRetriever(config)
        elif retriever_type == RetrieverType.HYBRID:
            return HybridRetriever(config)
        elif retriever_type == RetrieverType.MULTI_QUERY:
            return MultiQueryRetriever(config)
        elif retriever_type == RetrieverType.ENSEMBLE:
            return EnsembleRetriever(config)
        elif retriever_type == RetrieverType.PARENT_CHILD:
            return ParentChildRetriever(config)
        else:
            raise ValueError(f"Unknown retriever type: {retriever_type}")
```

### 3. é…ç½®é©±åŠ¨ (Configuration-Driven)

ä½¿ç”¨ Pydantic æ¨¡å‹è¿›è¡Œé…ç½®ç®¡ç†ï¼š

```python
from pydantic import BaseModel, Field
from typing import Optional, List

class RetrieverConfig(BaseModel):
    """æ£€ç´¢å™¨é…ç½®"""
    type: RetrieverType = RetrieverType.VECTOR
    top_k: int = Field(default=5, ge=1, le=100)
    similarity_threshold: float = Field(default=0.7, ge=0.0, le=1.0)
    enable_mmr: bool = False
    lambda_mult: float = Field(default=0.5, ge=0.0, le=1.0)

class RerankerConfig(BaseModel):
    """é‡æ’åºé…ç½®"""
    enabled: bool = False
    model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"
    top_n: int = Field(default=3, ge=1)

class GeneratorConfig(BaseModel):
    """ç”Ÿæˆå™¨é…ç½®"""
    model_name: str = "gpt-4"
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int = Field(default=500, ge=1)
    streaming: bool = True

class CacheConfig(BaseModel):
    """ç¼“å­˜é…ç½®"""
    enabled: bool = True
    ttl_seconds: int = 3600
    semantic_cache: bool = False

class RAGPipelineConfig(BaseModel):
    """å®Œæ•´ RAG pipeline é…ç½®"""
    retriever: RetrieverConfig
    reranker: RerankerConfig
    generator: GeneratorConfig
    cache: CacheConfig
    enable_memory: bool = True
    enable_self_correction: bool = False
    timeout_seconds: int = 30
```

---

## è¯¦ç»†æµç¨‹è¯´æ˜

### 1. å…¥å£å±‚ (Entry Layer)

**èŒè´£**: è¯·æ±‚æ¥æ”¶ã€è®¤è¯ã€é™æµ

- **API Gateway**: ç»Ÿä¸€çš„è¯·æ±‚å…¥å£
- **è®¤è¯æˆæƒ**: JWT/OAuth2 èº«ä»½éªŒè¯
- **é€Ÿç‡é™åˆ¶**: é˜²æ­¢æ»¥ç”¨ï¼ˆåŸºäºç”¨æˆ·/IPï¼‰
- **è¯·æ±‚éªŒè¯**: Pydantic æ¨¡å‹éªŒè¯

### 2. æŸ¥è¯¢é¢„å¤„ç† (Query Preprocessing)

**èŒè´£**: æ¸…æ´—å’Œæ ‡å‡†åŒ–æŸ¥è¯¢

- è¯­è¨€æ£€æµ‹ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
- æ‹¼å†™çº æ­£
- æ„å›¾è¯†åˆ«
- å»é™¤å™ªå£°ï¼ˆç‰¹æ®Šå­—ç¬¦ç­‰ï¼‰

### 3. æ™ºèƒ½è·¯ç”± (Query Router)

**èŒè´£**: æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©æœ€ä½³ pipeline

```python
class QueryType(str, Enum):
    GREETING = "greeting"           # ç®€å•é—®å€™
    FACTUAL = "factual"            # äº‹å®æŸ¥è¯¢
    REASONING = "reasoning"         # å¤æ‚æ¨ç†
    CONVERSATIONAL = "conversational" # å¯¹è¯åœºæ™¯
    SUMMARIZATION = "summarization" # æ–‡æ¡£æ€»ç»“

class QueryRouter:
    async def route(self, query: str, history: List[Dict]) -> QueryType:
        """ä½¿ç”¨ LLM æˆ–è§„åˆ™è¿›è¡Œè·¯ç”±"""
        # å¯ä»¥ä½¿ç”¨ semantic router æˆ–ç®€å•çš„åˆ†ç±»æ¨¡å‹
        pass
```

### 4. æŸ¥è¯¢è½¬æ¢ (Query Transformation)

**èŒè´£**: ä¼˜åŒ–æŸ¥è¯¢ä»¥æé«˜æ£€ç´¢æ•ˆæœ

#### A. Multi-Query Generation
ç”Ÿæˆå¤šä¸ªç›¸ä¼¼æŸ¥è¯¢æé«˜å¬å›ç‡ï¼š

```python
class MultiQueryTransformer:
    async def transform(self, query: str) -> List[str]:
        """
        è¾“å…¥: "What are AI agents?"
        è¾“å‡º: [
            "What are AI agents?",
            "How do AI agents work?",
            "What is the definition of AI agents?",
            "Explain artificial intelligence agents"
        ]
        """
        pass
```

#### B. Step-back Prompting
ç”Ÿæˆæ›´æŠ½è±¡çš„æŸ¥è¯¢ï¼š

```python
class StepBackTransformer:
    async def transform(self, query: str) -> str:
        """
        è¾“å…¥: "What are the effects of climate change on polar bears?"
        è¾“å‡º: "What is climate change?"
        """
        pass
```

#### C. Query Decomposition
åˆ†è§£å¤æ‚æŸ¥è¯¢ï¼š

```python
class QueryDecomposer:
    async def decompose(self, query: str) -> List[str]:
        """
        è¾“å…¥: "Compare RAG with fine-tuning and explain which is better"
        è¾“å‡º: [
            "What is RAG?",
            "What is fine-tuning?",
            "Compare RAG and fine-tuning",
            "When to use RAG vs fine-tuning?"
        ]
        """
        pass
```

### 5. æ£€ç´¢å±‚ (Retrieval Layer)

æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥ï¼š

#### A. å‘é‡æ£€ç´¢ (Vector Search)
```python
class VectorRetriever(RetrieverInterface):
    async def retrieve(self, query: str, top_k: int) -> List[Document]:
        embedding = await self.embed_query(query)
        results = await self.vector_store.similarity_search(
            embedding, 
            k=top_k
        )
        return results
```

#### B. æ··åˆæ£€ç´¢ (Hybrid Search)
```python
class HybridRetriever(RetrieverInterface):
    async def retrieve(self, query: str, top_k: int) -> List[Document]:
        # å‘é‡æ£€ç´¢
        vector_results = await self.vector_retriever.retrieve(query, top_k)
        
        # BM25 è¯æ±‡æ£€ç´¢
        bm25_results = await self.bm25_retriever.retrieve(query, top_k)
        
        # åŠ æƒåˆå¹¶
        combined = self._merge_results(
            vector_results, 
            bm25_results,
            weights=[0.7, 0.3]
        )
        return combined[:top_k]
```

#### C. çˆ¶å­æ–‡æ¡£æ£€ç´¢ (Parent-Child)
```python
class ParentChildRetriever(RetrieverInterface):
    async def retrieve(self, query: str, top_k: int) -> List[Document]:
        # æ£€ç´¢å°æ–‡æ¡£å—ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
        child_docs = await self.vector_retriever.retrieve(query, top_k)
        
        # è¿”å›çˆ¶æ–‡æ¡£ï¼ˆå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
        parent_docs = await self._get_parent_documents(child_docs)
        return parent_docs
```

### 6. æ–‡æ¡£å¤„ç† (Document Processing)

**èŒè´£**: ä¼˜åŒ–æ£€ç´¢ç»“æœè´¨é‡

#### A. å»é‡ (Deduplication)
```python
async def deduplicate(documents: List[Document]) -> List[Document]:
    """åŸºäºå†…å®¹ç›¸ä¼¼åº¦å»é‡"""
    seen = set()
    unique_docs = []
    for doc in documents:
        content_hash = hash(doc.page_content)
        if content_hash not in seen:
            seen.add(content_hash)
            unique_docs.append(doc)
    return unique_docs
```

#### B. MMR (Maximum Marginal Relevance)
```python
async def apply_mmr(
    query: str,
    documents: List[Document],
    lambda_mult: float = 0.5
) -> List[Document]:
    """å¢åŠ æ–‡æ¡£å¤šæ ·æ€§"""
    # å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
    pass
```

#### C. ä¸Šä¸‹æ–‡å‹ç¼© (Contextual Compression)
```python
from langchain.retrievers.document_compressors import LLMChainExtractor

async def compress_documents(
    query: str,
    documents: List[Document]
) -> List[Document]:
    """åªä¿ç•™ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹"""
    compressor = LLMChainExtractor.from_llm(llm)
    compressed = await compressor.acompress_documents(documents, query)
    return compressed
```

### 7. é‡æ’åº (Reranking)

**èŒè´£**: æé«˜ Top-K æ–‡æ¡£çš„ç²¾åº¦

#### A. Cross-Encoder Reranking
```python
from sentence_transformers import CrossEncoder

class CrossEncoderReranker(RerankerInterface):
    def __init__(self):
        self.model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    async def rerank(
        self, 
        query: str, 
        documents: List[Document]
    ) -> List[Document]:
        pairs = [(query, doc.page_content) for doc in documents]
        scores = self.model.predict(pairs)
        
        # é‡æ–°æ’åº
        for doc, score in zip(documents, scores):
            doc.score = float(score)
        
        return sorted(documents, key=lambda x: x.score, reverse=True)
```

#### B. LLM-based Reranking
```python
class LLMReranker(RerankerInterface):
    async def rerank(
        self, 
        query: str, 
        documents: List[Document]
    ) -> List[Document]:
        """ä½¿ç”¨ LLM å¯¹æ–‡æ¡£è¿›è¡Œç›¸å…³æ€§è¯„åˆ†"""
        prompt = f"""Rate the relevance of the following document to the query.
Query: {query}
Document: {{document}}
Relevance (0-10):"""
        
        for doc in documents:
            score = await self.llm.apredict(prompt.format(document=doc.page_content))
            doc.score = float(score)
        
        return sorted(documents, key=lambda x: x.score, reverse=True)
```

### 8. ç”Ÿæˆ (Generation)

**èŒè´£**: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ

```python
class StreamingGenerator(GeneratorInterface):
    async def generate(
        self,
        query: str,
        context: List[Document],
        stream: bool = True
    ):
        prompt = self._build_prompt(query, context)
        
        if stream:
            async for chunk in self.llm.astream(prompt):
                yield chunk
        else:
            response = await self.llm.apredict(prompt)
            return response
    
    def _build_prompt(self, query: str, context: List[Document]) -> str:
        context_str = "\n\n".join([
            f"Document {i+1}:\n{doc.page_content}"
            for i, doc in enumerate(context)
        ])
        
        return f"""You are a helpful assistant. Answer the question based on the following context.

Context:
{context_str}

Question: {query}

Answer:"""
```

### 9. è‡ªæˆ‘çº æ­£ (Self-Correction)

**èŒè´£**: æ£€æµ‹å’Œä¿®æ­£å¹»è§‰

```python
class SelfCorrector:
    async def check_faithfulness(
        self,
        query: str,
        answer: str,
        context: List[Document]
    ) -> tuple[bool, float]:
        """æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦å¿ å®äºä¸Šä¸‹æ–‡"""
        prompt = f"""Check if the answer is supported by the context.

Context: {context}
Answer: {answer}

Is the answer faithful? (yes/no):"""
        
        result = await self.llm.apredict(prompt)
        is_faithful = "yes" in result.lower()
        confidence = 0.9 if is_faithful else 0.3
        
        return is_faithful, confidence
```

### 10. Agentic RAG

**èŒè´£**: ä½¿ç”¨å·¥å…·è¿›è¡Œå¤æ‚æ¨ç†

```python
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import Tool

def build_agentic_rag(llm, retriever):
    tools = [
        Tool(
            name="semantic_search",
            func=retriever.retrieve,
            description="Search for relevant documents"
        ),
        Tool(
            name="summarize",
            func=summarizer.summarize,
            description="Summarize a long document"
        ),
        Tool(
            name="compare",
            func=comparator.compare,
            description="Compare multiple documents"
        ),
    ]
    
    return create_react_agent(
        llm,
        tools,
        state_modifier="You are a research assistant with access to tools."
    )
```

### 11. å¯¹è¯å¼ RAG (Conversational RAG)

**èŒè´£**: ç®¡ç†å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

```python
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory

class ConversationalRAG:
    def __init__(self, memory_type: str = "buffer"):
        if memory_type == "buffer":
            self.memory = ConversationBufferMemory()
        elif memory_type == "summary":
            self.memory = ConversationSummaryMemory(llm=llm)
    
    async def query(self, query: str, session_id: str):
        # åŠ è½½å†å²
        history = await self.memory.load_memory_variables({"session_id": session_id})
        
        # ç»“åˆå†å²ä¸Šä¸‹æ–‡é‡å†™æŸ¥è¯¢
        contextualized_query = await self._contextualize_query(query, history)
        
        # æ‰§è¡Œæ£€ç´¢å’Œç”Ÿæˆ
        result = await self.rag_pipeline.run(contextualized_query)
        
        # ä¿å­˜ä¸Šä¸‹æ–‡
        await self.memory.save_context(
            {"input": query},
            {"output": result}
        )
        
        return result
```

---

## æ¨èç›®å½•ç»“æ„

```
rag/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ api/                              # API å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                        # FastAPI åº”ç”¨
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query.py                  # æŸ¥è¯¢æ¥å£
â”‚   â”‚   â”œâ”€â”€ ingest.py                 # æ–‡æ¡£å…¥åº“æ¥å£
â”‚   â”‚   â””â”€â”€ feedback.py               # åé¦ˆæ¥å£
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py                   # è®¤è¯ä¸­é—´ä»¶
â”‚   â”‚   â””â”€â”€ rate_limit.py             # é™æµä¸­é—´ä»¶
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ request.py                # è¯·æ±‚æ¨¡å‹
â”‚       â””â”€â”€ response.py               # å“åº”æ¨¡å‹
â”‚
â”œâ”€â”€ core/                             # æ ¸å¿ƒæŠ½è±¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ interfaces.py                 # æŠ½è±¡æ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ models.py                     # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ exceptions.py                 # è‡ªå®šä¹‰å¼‚å¸¸
â”‚   â””â”€â”€ constants.py                  # å¸¸é‡å®šä¹‰
â”‚
â”œâ”€â”€ config/                           # é…ç½®å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                   # å…¨å±€é…ç½®
â”‚   â”œâ”€â”€ rag_config.py                 # RAG é…ç½®
â”‚   â””â”€â”€ logging_config.py             # æ—¥å¿—é…ç½®
â”‚
â”œâ”€â”€ preprocessing/                    # æŸ¥è¯¢é¢„å¤„ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_cleaner.py              # æŸ¥è¯¢æ¸…æ´—
â”‚   â”œâ”€â”€ language_detector.py          # è¯­è¨€æ£€æµ‹
â”‚   â””â”€â”€ intent_classifier.py          # æ„å›¾åˆ†ç±»
â”‚
â”œâ”€â”€ routing/                          # è·¯ç”±å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_router.py               # æŸ¥è¯¢è·¯ç”±å™¨
â”‚   â”œâ”€â”€ semantic_router.py            # è¯­ä¹‰è·¯ç”±
â”‚   â””â”€â”€ rule_based_router.py          # è§„åˆ™è·¯ç”±
â”‚
â”œâ”€â”€ query_transformation/             # æŸ¥è¯¢è½¬æ¢
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ multi_query.py                # å¤šæŸ¥è¯¢ç”Ÿæˆ
â”‚   â”œâ”€â”€ step_back.py                  # Step-back prompting
â”‚   â”œâ”€â”€ decomposition.py              # æŸ¥è¯¢åˆ†è§£
â”‚   â””â”€â”€ base.py                       # åŸºç±»
â”‚
â”œâ”€â”€ retrievers/                       # æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                       # åŸºç±»
â”‚   â”œâ”€â”€ vector_retriever.py           # å‘é‡æ£€ç´¢
â”‚   â”œâ”€â”€ hybrid_retriever.py           # æ··åˆæ£€ç´¢
â”‚   â”œâ”€â”€ multi_query_retriever.py      # å¤šæŸ¥è¯¢æ£€ç´¢
â”‚   â”œâ”€â”€ ensemble_retriever.py         # é›†æˆæ£€ç´¢
â”‚   â”œâ”€â”€ parent_child_retriever.py     # çˆ¶å­æ–‡æ¡£æ£€ç´¢
â”‚   â””â”€â”€ factory.py                    # æ£€ç´¢å™¨å·¥å‚
â”‚
â”œâ”€â”€ rerankers/                        # é‡æ’åºå™¨
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                       # åŸºç±»
â”‚   â”œâ”€â”€ cross_encoder_reranker.py     # Cross-Encoder
â”‚   â”œâ”€â”€ llm_reranker.py               # LLM é‡æ’åº
â”‚   â”œâ”€â”€ score_based_reranker.py       # åˆ†æ•°é‡æ’åº
â”‚   â””â”€â”€ factory.py                    # é‡æ’åºå·¥å‚
â”‚
â”œâ”€â”€ generators/                       # ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                       # åŸºç±»
â”‚   â”œâ”€â”€ streaming_generator.py        # æµå¼ç”Ÿæˆ
â”‚   â”œâ”€â”€ batch_generator.py            # æ‰¹é‡ç”Ÿæˆ
â”‚   â”œâ”€â”€ prompt_builder.py             # Prompt æ„å»º
â”‚   â””â”€â”€ factory.py                    # ç”Ÿæˆå™¨å·¥å‚
â”‚
â”œâ”€â”€ processing/                       # æ–‡æ¡£å¤„ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ deduplicator.py               # å»é‡
â”‚   â”œâ”€â”€ mmr_filter.py                 # MMR è¿‡æ»¤
â”‚   â”œâ”€â”€ compressor.py                 # ä¸Šä¸‹æ–‡å‹ç¼©
â”‚   â””â”€â”€ chunker.py                    # æ–‡æ¡£åˆ†å—
â”‚
â”œâ”€â”€ memory/                           # è®°å¿†ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                       # åŸºç±»
â”‚   â”œâ”€â”€ buffer_memory.py              # ç¼“å†²è®°å¿†
â”‚   â”œâ”€â”€ summary_memory.py             # æ‘˜è¦è®°å¿†
â”‚   â”œâ”€â”€ knowledge_graph_memory.py     # çŸ¥è¯†å›¾è°±è®°å¿†
â”‚   â””â”€â”€ factory.py                    # è®°å¿†å·¥å‚
â”‚
â”œâ”€â”€ cache/                            # ç¼“å­˜ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ redis_cache.py                # Redis ç¼“å­˜
â”‚   â”œâ”€â”€ memory_cache.py               # å†…å­˜ç¼“å­˜
â”‚   â””â”€â”€ semantic_cache.py             # è¯­ä¹‰ç¼“å­˜
â”‚
â”œâ”€â”€ graphs/                           # LangGraph å·¥ä½œæµ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_rag_graph.py             # åŸºç¡€ RAG graph
â”‚   â”œâ”€â”€ agentic_rag_graph.py          # Agentic RAG graph
â”‚   â”œâ”€â”€ conversational_rag_graph.py   # å¯¹è¯å¼ RAG graph
â”‚   â”œâ”€â”€ self_correcting_graph.py      # è‡ªæˆ‘çº æ­£ graph
â”‚   â””â”€â”€ states.py                     # çŠ¶æ€å®šä¹‰
â”‚
â”œâ”€â”€ agents/                           # Agent ç›¸å…³
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ react_agent.py                # ReAct agent
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search_tool.py            # æœç´¢å·¥å…·
â”‚   â”‚   â”œâ”€â”€ summarize_tool.py         # æ€»ç»“å·¥å…·
â”‚   â”‚   â””â”€â”€ compare_tool.py           # å¯¹æ¯”å·¥å…·
â”‚   â””â”€â”€ planning/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ task_decomposer.py        # ä»»åŠ¡åˆ†è§£
â”‚
â”œâ”€â”€ evaluation/                       # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ retrieval_metrics.py          # æ£€ç´¢æŒ‡æ ‡
â”‚   â”œâ”€â”€ generation_metrics.py         # ç”ŸæˆæŒ‡æ ‡
â”‚   â”œâ”€â”€ faithfulness_checker.py       # å¿ å®åº¦æ£€æŸ¥
â”‚   â””â”€â”€ hallucination_detector.py     # å¹»è§‰æ£€æµ‹
â”‚
â”œâ”€â”€ observability/                    # å¯è§‚æµ‹æ€§
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging.py                    # æ—¥å¿—
â”‚   â”œâ”€â”€ tracing.py                    # é“¾è·¯è¿½è¸ª
â”‚   â”œâ”€â”€ metrics.py                    # æŒ‡æ ‡æ”¶é›†
â”‚   â””â”€â”€ callbacks.py                  # å›è°ƒå¤„ç†
â”‚
â”œâ”€â”€ storage/                          # å­˜å‚¨å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vector_stores/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ faiss_store.py            # FAISS
â”‚   â”‚   â”œâ”€â”€ weaviate_store.py         # Weaviate
â”‚   â”‚   â””â”€â”€ qdrant_store.py           # Qdrant
â”‚   â””â”€â”€ document_stores/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ postgres_store.py         # PostgreSQL
â”‚       â””â”€â”€ mongodb_store.py          # MongoDB
â”‚
â”œâ”€â”€ utils/                            # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ text_processing.py            # æ–‡æœ¬å¤„ç†
â”‚   â”œâ”€â”€ embeddings.py                 # Embedding ç”Ÿæˆ
â”‚   â””â”€â”€ formatting.py                 # æ ¼å¼åŒ–
â”‚
â”œâ”€â”€ pipeline/                         # Pipeline ç¼–æ’
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_pipeline.py               # RAG Pipeline
â”‚   â”œâ”€â”€ ingest_pipeline.py            # å…¥åº“ Pipeline
â”‚   â””â”€â”€ pipeline_builder.py           # Pipeline æ„å»ºå™¨
â”‚
â””â”€â”€ tests/                            # æµ‹è¯•
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ unit/                         # å•å…ƒæµ‹è¯•
    â”œâ”€â”€ integration/                  # é›†æˆæµ‹è¯•
    â””â”€â”€ e2e/                          # ç«¯åˆ°ç«¯æµ‹è¯•
```

---

## å…³é”®æŠ€æœ¯é€‰å‹

### æ£€ç´¢å±‚

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **å‘é‡æ•°æ®åº“** | FAISS / Weaviate / Qdrant | æ ¹æ®è§„æ¨¡é€‰æ‹© |
| **BM25** | Rank-BM25 / Elasticsearch | è¯æ±‡æ£€ç´¢ |
| **æ··åˆæ£€ç´¢** | LangChain EnsembleRetriever | åŠ æƒåˆå¹¶ |

### é‡æ’åºå±‚

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **Cross-Encoder** | sentence-transformers | ç²¾ç¡®ä½†æ…¢ |
| **LLM Reranking** | GPT-4 / Claude | æœ€ç²¾ç¡®ä½†è´µ |
| **Cohere Rerank** | Cohere API | æ€§ä»·æ¯”é«˜ |

### ç”Ÿæˆå±‚

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **LLM** | GPT-4 / Claude / Llama | æ ¹æ®é¢„ç®—é€‰æ‹© |
| **Streaming** | SSE / WebSocket | å®æ—¶å“åº” |
| **Prompt** | LangChain PromptTemplate | æ¨¡æ¿ç®¡ç† |

### ç¼“å­˜å±‚

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **Redis** | Redis | åˆ†å¸ƒå¼ç¼“å­˜ |
| **Semantic Cache** | GPTCache | è¯­ä¹‰ç¼“å­˜ |

### å¯è§‚æµ‹æ€§

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **Tracing** | LangSmith / OpenTelemetry | é“¾è·¯è¿½è¸ª |
| **Metrics** | Prometheus + Grafana | æŒ‡æ ‡ç›‘æ§ |
| **Logging** | Structlog | ç»“æ„åŒ–æ—¥å¿— |

---

## æ¥å£è®¾è®¡

### REST API ç¤ºä¾‹

#### 1. Query Endpoint

```python
# POST /api/v1/query
{
  "query": "What are AI agents?",
  "session_id": "user-123",
  "config": {
    "retriever_top_k": 5,
    "enable_reranking": true,
    "stream": true
  }
}

# Response (Streaming)
data: {"type": "metadata", "retrieval_count": 5}
data: {"type": "chunk", "content": "AI agents are"}
data: {"type": "chunk", "content": " autonomous systems"}
...
data: {"type": "done", "sources": [...]}
```

#### 2. Ingest Endpoint

```python
# POST /api/v1/ingest
{
  "documents": [
    {
      "content": "...",
      "metadata": {"source": "paper.pdf", "page": 1}
    }
  ],
  "collection_name": "research-papers"
}

# Response
{
  "status": "success",
  "document_count": 10,
  "chunk_count": 150,
  "processing_time_ms": 2341
}
```

---

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from rag.pipeline import RAGPipeline
from rag.config import RAGPipelineConfig, RetrieverType

# 1. åˆ›å»ºé…ç½®
config = RAGPipelineConfig(
    retriever=RetrieverConfig(
        type=RetrieverType.HYBRID,
        top_k=5
    ),
    reranker=RerankerConfig(
        enabled=True,
        top_n=3
    ),
    generator=GeneratorConfig(
        model_name="gpt-4",
        streaming=True
    )
)

# 2. åˆå§‹åŒ– Pipeline
pipeline = RAGPipeline(config)

# 3. æŸ¥è¯¢ï¼ˆæµå¼ï¼‰
async for chunk in pipeline.query_stream("What are AI agents?"):
    print(chunk, end="", flush=True)

# 4. æŸ¥è¯¢ï¼ˆéæµå¼ï¼‰
result = await pipeline.query("What are AI agents?")
print(result.answer)
print(result.sources)
```

### å¯¹è¯å¼ä½¿ç”¨

```python
from rag.pipeline import ConversationalRAGPipeline

pipeline = ConversationalRAGPipeline(config)

# å¤šè½®å¯¹è¯
session_id = "user-123"

response1 = await pipeline.query(
    "What are AI agents?",
    session_id=session_id
)

response2 = await pipeline.query(
    "How do they work?",  # è‡ªåŠ¨ç»“åˆä¸Šä¸‹æ–‡
    session_id=session_id
)
```

### Agentic RAG ä½¿ç”¨

```python
from rag.agents import AgenticRAG

agentic_rag = AgenticRAG(
    llm=llm,
    retriever=retriever,
    tools=["search", "summarize", "compare"]
)

result = await agentic_rag.query(
    "Compare RAG with fine-tuning and tell me which is better for my use case"
)
```

---

## æ‰©å±•ç‚¹

### 1. è‡ªå®šä¹‰æ£€ç´¢å™¨

```python
from rag.retrievers import RetrieverInterface

class MyCustomRetriever(RetrieverInterface):
    async def retrieve(self, query: str, top_k: int) -> List[Document]:
        # å®ç°è‡ªå®šä¹‰æ£€ç´¢é€»è¾‘
        pass

# æ³¨å†Œåˆ°å·¥å‚
RetrieverFactory.register("custom", MyCustomRetriever)
```

### 2. è‡ªå®šä¹‰é‡æ’åºå™¨

```python
from rag.rerankers import RerankerInterface

class MyCustomReranker(RerankerInterface):
    async def rerank(self, query: str, documents: List[Document]) -> List[Document]:
        # å®ç°è‡ªå®šä¹‰é‡æ’åºé€»è¾‘
        pass
```

### 3. è‡ªå®šä¹‰ LangGraph Workflow

```python
from langgraph.graph import StateGraph
from rag.graphs import RAGState

def build_custom_graph():
    graph = StateGraph(RAGState)
    
    # æ·»åŠ è‡ªå®šä¹‰èŠ‚ç‚¹
    graph.add_node("custom_step", my_custom_function)
    
    # è‡ªå®šä¹‰æµç¨‹
    graph.set_entry_point("custom_step")
    graph.add_edge("custom_step", "retrieve")
    # ...
    
    return graph.compile()
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¼“å­˜ç­–ç•¥
- æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
- è¯­ä¹‰ç¼“å­˜ï¼ˆç›¸ä¼¼æŸ¥è¯¢ï¼‰
- æ£€ç´¢ç»“æœç¼“å­˜

### 2. å¹¶è¡Œå¤„ç†
- å¤šæŸ¥è¯¢å¹¶è¡Œæ£€ç´¢
- æ‰¹é‡ Embedding ç”Ÿæˆ
- å¼‚æ­¥ I/O

### 3. ç´¢å¼•ä¼˜åŒ–
- ä½¿ç”¨ HNSW ç´¢å¼•ï¼ˆå¿«é€Ÿè¿‘ä¼¼æœç´¢ï¼‰
- å®šæœŸç´¢å¼•é‡å»º
- åˆ†ç‰‡ç­–ç•¥

---

## ç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡ |
|------|------|------|
| **Latency P95** | 95åˆ†ä½å»¶è¿Ÿ | < 2s |
| **Retrieval Recall** | æ£€ç´¢å¬å›ç‡ | > 90% |
| **Answer Faithfulness** | ç­”æ¡ˆå¿ å®åº¦ | > 85% |
| **Cache Hit Rate** | ç¼“å­˜å‘½ä¸­ç‡ | > 60% |
| **Error Rate** | é”™è¯¯ç‡ | < 1% |

---

## å‚è€ƒèµ„æº

- [LangChain æ–‡æ¡£](https://python.langchain.com/)
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangSmith æ–‡æ¡£](https://docs.smith.langchain.com/)
- [Advanced RAG Techniques](https://github.com/langchain-ai/langchain/discussions)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2025-10-20  
**ç»´æŠ¤è€…**: Research Agent Team
