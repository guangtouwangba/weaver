"""
Chat API - HTTP + SSE æ··åˆæ¥å£è®¾è®¡

æä¾›åŸºäºSSEçš„æµå¼èŠå¤©ä½“éªŒå’Œä¼ ç»ŸHTTPç®¡ç†æ¥å£ã€‚
"""

import json
import asyncio
from datetime import datetime
from typing import AsyncGenerator, Optional

from fastapi import APIRouter, Depends, HTTPException, Query, Request
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession

from logging_system import get_logger, log_execution_time, log_errors
from modules.database import get_db_session
from modules.schemas import APIResponse
from modules.schemas.chat import (
    ChatRequest,
    ChatResponse,
    ChatMessage,
    ChatSearchRequest,
    ChatSearchResponse,
    ChatStatisticsResponse,
    ConversationListRequest,
    ConversationListResponse,
    MessageHistoryRequest,
    MessageHistoryResponse,
    MessageRole,
    SSEEventType,
    SSEStartEvent,
    SSEProgressEvent,
    SSEContextEvent,
    SSEDeltaEvent,
    SSECompleteEvent,
    SSEErrorEvent
)
from modules.services.chat_service import ChatService, get_chat_service

router = APIRouter(prefix="/chat", tags=["Chat"])
logger = get_logger(__name__)


# ==================== SSEæµå¼èŠå¤©æ¥å£ ====================

@router.post("/stream", summary="ğŸŒŠ æµå¼èŠå¤©æ¥å£ (SSE)")
@log_execution_time(threshold_ms=10000)
@log_errors()
async def chat_stream(
    request: ChatRequest,
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    # ğŸŒŠ æµå¼èŠå¤©æ¥å£ (Server-Sent Events)
    
    æä¾›å®æ—¶çš„RAGèŠå¤©ä½“éªŒï¼š
    - å®æ—¶æ˜¾ç¤ºRAGæ£€ç´¢è¿›åº¦
    - æµå¼è¾“å‡ºAIç”Ÿæˆå†…å®¹
    - è‡ªåŠ¨é‡è¿å’Œé”™è¯¯æ¢å¤
    
    ## äº‹ä»¶æµæ ¼å¼
    
    ### å¼€å§‹äº‹ä»¶
    ```
    event: start
    data: {"message_id": "msg-uuid", "conversation_id": "conv-uuid"}
    ```
    
    ### è¿›åº¦äº‹ä»¶
    ```
    event: progress
    data: {"stage": "retrieving", "message": "æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£..."}
    ```
    
    ### ä¸Šä¸‹æ–‡äº‹ä»¶
    ```
    event: context
    data: {"contexts": [...], "search_time_ms": 200, "total_results": 5}
    ```
    
    ### å¢é‡å†…å®¹äº‹ä»¶
    ```
    event: delta
    data: {"content": "æœºå™¨å­¦ä¹ ", "message_id": "msg-uuid"}
    ```
    
    ### å®Œæˆäº‹ä»¶
    ```
    event: complete
    data: {"conversation_id": "conv-uuid", "total_tokens": 150, "generation_time_ms": 3000}
    ```
    
    ### é”™è¯¯äº‹ä»¶
    ```
    event: error
    data: {"error": "é”™è¯¯ä¿¡æ¯", "error_type": "ValueError", "stage": "retrieving"}
    ```
    
    ## å‰ç«¯æ¥å…¥ç¤ºä¾‹
    
    ```javascript
    const response = await fetch('/api/v1/chat/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            message: "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            topic_id: 123,
            conversation_id: "conv-uuid"  // å¯é€‰
        })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\\n');
        
        for (const line of lines) {
            if (line.startsWith('event:')) {
                eventType = line.substring(6).trim();
            } else if (line.startsWith('data:')) {
                const data = JSON.parse(line.substring(5));
                handleSSEEvent(eventType, data);
            }
        }
    }
    ```
    """
    
    async def generate_chat_stream() -> AsyncGenerator[str, None]:
        """ç”ŸæˆSSEæµæ•°æ®"""
        try:
            await chat_service.initialize()
            
            # ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
            import uuid
            message_id = str(uuid.uuid4())
            conversation_id = request.conversation_id or str(uuid.uuid4())
            
            # 1. ğŸš€ å¼€å§‹å¤„ç†
            start_event = SSEStartEvent(
                message_id=message_id,
                conversation_id=conversation_id
            )
            yield f"event: {SSEEventType.START}\n"
            yield f"data: {start_event.model_dump_json()}\n\n"
            
            # 2. ğŸ” RAGæ£€ç´¢é˜¶æ®µ
            progress_event = SSEProgressEvent(
                stage="retrieving",
                message="æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...",
                progress=0.2
            )
            yield f"event: {SSEEventType.PROGRESS}\n"
            yield f"data: {progress_event.model_dump_json()}\n\n"
            
            # æ‰§è¡ŒRAGæ£€ç´¢
            retrieved_contexts, search_time_ms = await chat_service._retrieve_contexts(
                query=request.message,
                topic_id=request.topic_id,
                search_type=request.search_type,
                max_results=request.max_results,
                score_threshold=request.score_threshold
            )
            
            # å‘é€æ£€ç´¢ç»“æœ
            context_event = SSEContextEvent(
                contexts=retrieved_contexts,
                search_time_ms=search_time_ms,
                total_results=len(retrieved_contexts)
            )
            yield f"event: {SSEEventType.CONTEXT}\n"
            yield f"data: {context_event.model_dump_json()}\n\n"
            
            # 3. ğŸ¤– AIç”Ÿæˆé˜¶æ®µ
            progress_event = SSEProgressEvent(
                stage="generating",
                message="AIæ­£åœ¨ç”Ÿæˆå›ç­”...",
                progress=0.6
            )
            yield f"event: {SSEEventType.PROGRESS}\n"
            yield f"data: {progress_event.model_dump_json()}\n\n"
            
            # è·å–å¯¹è¯å†å²
            conversation_history = []
            if request.context_window > 0:
                conversation_history = await chat_service.get_conversation_messages(
                    conversation_id, limit=request.context_window * 2
                )
            
            # æ„å»ºæç¤ºè¯
            prompt = chat_service._build_prompt(
                user_message=request.message,
                retrieved_contexts=retrieved_contexts if request.include_context else [],
                conversation_history=conversation_history
            )
            
            # 4. ğŸŒŠ æµå¼ç”ŸæˆAIå›ç­”
            full_response = ""
            tokens_used = 0
            generation_start = datetime.now()
            
            async for chunk in chat_service._generate_ai_response_stream(
                prompt=prompt,
                max_tokens=request.max_tokens,
                temperature=request.temperature
            ):
                if chunk.get("content"):
                    full_response += chunk["content"]
                    
                    # å‘é€å¢é‡å†…å®¹
                    delta_event = SSEDeltaEvent(
                        content=chunk["content"],
                        message_id=message_id,
                        token_count=tokens_used
                    )
                    yield f"event: {SSEEventType.DELTA}\n"
                    yield f"data: {delta_event.model_dump_json()}\n\n"
                
                if chunk.get("tokens"):
                    tokens_used += chunk["tokens"]
            
            generation_time_ms = int((datetime.now() - generation_start).total_seconds() * 1000)
            
            # 5. ğŸ’¾ ä¿å­˜å¯¹è¯
            progress_event = SSEProgressEvent(
                stage="saving",
                message="æ­£åœ¨ä¿å­˜å¯¹è¯è®°å½•...",
                progress=0.9
            )
            yield f"event: {SSEEventType.PROGRESS}\n"
            yield f"data: {progress_event.model_dump_json()}\n\n"
            
            await chat_service.es_service.save_conversation(
                conversation_id=conversation_id,
                user_message=request.message,
                assistant_message=full_response,
                topic_id=request.topic_id,
                retrieved_contexts=retrieved_contexts,
                ai_metadata={
                    "model": "gpt-3.5-turbo",
                    "tokens_used": tokens_used,
                    "generation_time_ms": generation_time_ms,
                    "search_time_ms": search_time_ms,
                    "temperature": request.temperature,
                    "max_tokens": request.max_tokens
                }
            )
            
            # 6. âœ… å‘é€å®Œæˆäº‹ä»¶
            complete_event = SSECompleteEvent(
                conversation_id=conversation_id,
                message_id=message_id,
                total_tokens=tokens_used,
                generation_time_ms=generation_time_ms,
                search_time_ms=search_time_ms
            )
            yield f"event: {SSEEventType.COMPLETE}\n"
            yield f"data: {complete_event.model_dump_json()}\n\n"
            
        except Exception as e:
            logger.error(f"âŒ æµå¼èŠå¤©å¤„ç†å¤±è´¥: {e}")
            
            # å‘é€é”™è¯¯äº‹ä»¶
            error_event = SSEErrorEvent(
                error=str(e),
                error_type=type(e).__name__,
                stage="unknown"
            )
            yield f"event: {SSEEventType.ERROR}\n"
            yield f"data: {error_event.model_dump_json()}\n\n"
        
        finally:
            # ç¡®ä¿èµ„æºè¢«æ­£ç¡®æ¸…ç†
            try:
                await chat_service.close()
                logger.info("ChatServiceèµ„æºå·²æ¸…ç†")
            except Exception as e:
                logger.error(f"æ¸…ç†ChatServiceèµ„æºæ—¶å‡ºé”™: {e}")
    
    return StreamingResponse(
        generate_chat_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control, Content-Type",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
            "X-Accel-Buffering": "no",  # ç¦ç”¨nginxç¼“å†²
        }
    )


# ==================== ä¼ ç»ŸHTTPæ¥å£ ====================

@router.post("/", response_model=APIResponse, summary="ğŸ’¬ ä¼ ç»ŸèŠå¤©æ¥å£")
@log_execution_time(threshold_ms=15000)
@log_errors()
async def chat_sync(
    request: ChatRequest,
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    # ğŸ’¬ ä¼ ç»ŸèŠå¤©æ¥å£ (HTTP)
    
    é€‚ç”¨äºä¸éœ€è¦æµå¼ä½“éªŒçš„åœºæ™¯ï¼š
    - APIé›†æˆ
    - æ‰¹é‡å¤„ç†
    - ç®€å•å®¢æˆ·ç«¯
    
    ç­‰å¾…å®Œæ•´å¤„ç†åè¿”å›æ‰€æœ‰ç»“æœã€‚
    
    ## å“åº”æ ¼å¼
    ```json
    {
        "success": true,
        "data": {
            "message_id": "msg-uuid",
            "conversation_id": "conv-uuid", 
            "content": "AIå›ç­”å†…å®¹",
            "retrieved_contexts": [...],
            "ai_metadata": {...},
            "timestamp": "2024-01-01T00:00:00Z"
        }
    }
    ```
    """
    try:
        response = await chat_service.chat(request)
        return APIResponse(success=True, data=response.model_dump())
    except Exception as e:
        logger.error(f"âŒ èŠå¤©å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å¯¹è¯ç®¡ç†æ¥å£ ====================

@router.get("/conversations", response_model=APIResponse, summary="ğŸ“‹ è·å–å¯¹è¯åˆ—è¡¨")
@log_execution_time()
@log_errors()
async def get_conversations(
    topic_id: Optional[int] = Query(None, description="ä¸»é¢˜IDè¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    offset: int = Query(0, ge=0, description="åç§»é‡"),
    order_by: str = Query("last_message_time", description="æ’åºå­—æ®µ"),
    order_direction: str = Query("desc", description="æ’åºæ–¹å‘"),
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    è·å–å¯¹è¯åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œæ’åºã€‚
    
    ## æŸ¥è¯¢å‚æ•°
    - **topic_id**: å¯é€‰ï¼ŒæŒ‰ä¸»é¢˜è¿‡æ»¤
    - **limit**: æ¯é¡µæ•°é‡ (1-100)
    - **offset**: åç§»é‡
    - **order_by**: æ’åºå­—æ®µ (created_at, updated_at, last_message_time, message_count)
    - **order_direction**: æ’åºæ–¹å‘ (asc, desc)
    """
    try:
        conversations = await chat_service.get_conversations_list(
            topic_id=topic_id,
            limit=limit,
            offset=offset
        )
        
        response_data = ConversationListResponse(
            conversations=conversations,
            total=len(conversations),  # ç®€åŒ–å®ç°
            has_more=len(conversations) == limit
        )
        
        return APIResponse(success=True, data=response_data.model_dump())
    except Exception as e:
        logger.error(f"âŒ è·å–å¯¹è¯åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/conversations/{conversation_id}/messages", response_model=APIResponse, summary="ğŸ“– è·å–å¯¹è¯æ¶ˆæ¯")
@log_execution_time()
@log_errors()
async def get_conversation_messages(
    conversation_id: str,
    limit: int = Query(50, ge=1, le=200, description="æ¶ˆæ¯æ•°é‡"),
    before: Optional[str] = Query(None, description="åœ¨æ­¤æ¶ˆæ¯IDä¹‹å‰"),
    include_context: bool = Query(False, description="æ˜¯å¦åŒ…å«æ£€ç´¢ä¸Šä¸‹æ–‡"),
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    è·å–å¯¹è¯çš„æ¶ˆæ¯å†å²ã€‚
    
    ## è·¯å¾„å‚æ•°
    - **conversation_id**: å¯¹è¯ID
    
    ## æŸ¥è¯¢å‚æ•°  
    - **limit**: æ¶ˆæ¯æ•°é‡ (1-200)
    - **before**: åœ¨æ­¤æ¶ˆæ¯IDä¹‹å‰çš„æ¶ˆæ¯
    - **include_context**: æ˜¯å¦åŒ…å«RAGæ£€ç´¢ä¸Šä¸‹æ–‡
    """
    try:
        messages = await chat_service.get_conversation_messages(
            conversation_id=conversation_id,
            limit=limit,
            before=before
        )
        
        response_data = MessageHistoryResponse(
            messages=messages,
            conversation_id=conversation_id,
            has_more=len(messages) == limit
        )
        
        return APIResponse(success=True, data=response_data.model_dump())
    except Exception as e:
        logger.error(f"âŒ è·å–å¯¹è¯æ¶ˆæ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/conversations/{conversation_id}", response_model=APIResponse, summary="ğŸ—‘ï¸ åˆ é™¤å¯¹è¯")
@log_execution_time()
@log_errors()
async def delete_conversation(
    conversation_id: str,
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    åˆ é™¤æŒ‡å®šå¯¹è¯åŠå…¶æ‰€æœ‰æ¶ˆæ¯ã€‚
    
    ## è·¯å¾„å‚æ•°
    - **conversation_id**: å¯¹è¯ID
    """
    try:
        result = await chat_service.delete_conversation(conversation_id)
        return APIResponse(
            success=True,
            data={"deleted": result, "conversation_id": conversation_id}
        )
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤å¯¹è¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== æœç´¢æ¥å£ ====================

@router.get("/search", response_model=APIResponse, summary="ğŸ” æœç´¢èŠå¤©å†…å®¹")
@log_execution_time()
@log_errors()
async def search_chat_content(
    q: str = Query(description="æœç´¢å…³é”®è¯", min_length=1, max_length=200),
    topic_id: Optional[int] = Query(None, description="ä¸»é¢˜IDè¿‡æ»¤"),
    conversation_id: Optional[str] = Query(None, description="å¯¹è¯IDè¿‡æ»¤"),
    role: Optional[MessageRole] = Query(None, description="æ¶ˆæ¯è§’è‰²è¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="ç»“æœæ•°é‡"),
    highlight: bool = Query(True, description="æ˜¯å¦é«˜äº®å…³é”®è¯"),
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    å…¨æ–‡æœç´¢èŠå¤©è®°å½•ï¼Œæ”¯æŒé«˜äº®æ˜¾ç¤ºã€‚
    
    ## æŸ¥è¯¢å‚æ•°
    - **q**: æœç´¢å…³é”®è¯ (å¿…éœ€)
    - **topic_id**: å¯é€‰ï¼ŒæŒ‰ä¸»é¢˜è¿‡æ»¤
    - **conversation_id**: å¯é€‰ï¼ŒæŒ‰å¯¹è¯è¿‡æ»¤  
    - **role**: å¯é€‰ï¼ŒæŒ‰æ¶ˆæ¯è§’è‰²è¿‡æ»¤ (user, assistant, system)
    - **limit**: ç»“æœæ•°é‡ (1-100)
    - **highlight**: æ˜¯å¦é«˜äº®åŒ¹é…çš„å…³é”®è¯
    
    ## å“åº”æ ¼å¼
    ```json
    {
        "results": [
            {
                "message": {...},
                "highlights": ["é«˜äº®ç‰‡æ®µ1", "é«˜äº®ç‰‡æ®µ2"],
                "score": 0.95
            }
        ],
        "total": 42,
        "query_time_ms": 15
    }
    ```
    """
    try:
        import time
        start_time = time.time()
        
        search_results = await chat_service.search_chat_content(
            query=q,
            topic_id=topic_id,
            limit=limit
        )
        
        query_time_ms = int((time.time() - start_time) * 1000)
        
        response_data = ChatSearchResponse(
            results=search_results,
            total=len(search_results),
            query_time_ms=query_time_ms
        )
        
        return APIResponse(success=True, data=response_data.model_dump())
    except Exception as e:
        logger.error(f"âŒ æœç´¢èŠå¤©å†…å®¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== ç»Ÿè®¡æ¥å£ ====================

@router.get("/statistics", response_model=APIResponse, summary="ğŸ“Š è·å–èŠå¤©ç»Ÿè®¡")
@log_execution_time()
@log_errors()
async def get_chat_statistics(
    topic_id: Optional[int] = Query(None, description="ä¸»é¢˜IDè¿‡æ»¤"),
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    è·å–èŠå¤©ç»Ÿè®¡ä¿¡æ¯ã€‚
    
    ## æŸ¥è¯¢å‚æ•°
    - **topic_id**: å¯é€‰ï¼ŒæŒ‰ä¸»é¢˜è¿‡æ»¤ç»Ÿè®¡
    
    ## å“åº”å†…å®¹
    - æ€»å¯¹è¯æ•°
    - æ€»æ¶ˆæ¯æ•°
    - å¹³å‡æ¯å¯¹è¯æ¶ˆæ¯æ•°
    - æ€»tokenä½¿ç”¨é‡
    - çƒ­é—¨ä¸»é¢˜
    - æ¯æ—¥ç»Ÿè®¡ (æœ€è¿‘7å¤©)
    """
    try:
        stats = await chat_service.get_chat_statistics(topic_id)
        
        response_data = ChatStatisticsResponse(
            total_conversations=stats.get("total_conversations", 0),
            total_messages=stats.get("total_messages", 0),
            avg_messages_per_conversation=stats.get("avg_messages_per_conversation", 0.0),
            total_tokens_used=stats.get("total_tokens_used", 0),
            top_topics=stats.get("top_topics", []),
            daily_stats=stats.get("daily_stats", [])
        )
        
        return APIResponse(success=True, data=response_data.model_dump())
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å¥åº·æ£€æŸ¥æ¥å£ ====================

@router.get("/health", response_model=APIResponse, summary="ğŸ”§ èŠå¤©æœåŠ¡å¥åº·æ£€æŸ¥")
@log_execution_time()
@log_errors()
async def chat_health_check(
    chat_service: ChatService = Depends(get_chat_service),
):
    """
    æ£€æŸ¥èŠå¤©æœåŠ¡çš„å„ä¸ªç»„ä»¶çŠ¶æ€ã€‚
    
    ## æ£€æŸ¥é¡¹ç›®
    - ChatService åˆå§‹åŒ–çŠ¶æ€
    - Elasticsearch è¿æ¥çŠ¶æ€
    - Weaviate å‘é‡æ•°æ®åº“çŠ¶æ€
    - OpenAI API å¯ç”¨æ€§
    """
    try:
        await chat_service.initialize()
        
        health_status = {
            "chat_service": "healthy",
            "elasticsearch": "healthy" if chat_service.es_service.es_client else "unavailable",
            "vector_store": "healthy" if chat_service._vector_store else "unavailable",
            "ai_client": "healthy" if chat_service.ai_client else "mock_mode",
            "timestamp": datetime.now().isoformat()
        }
        
        return APIResponse(success=True, data=health_status)
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=503, detail=f"Service unavailable: {str(e)}")
