"""
RAGé›†æˆèŠå¤©æœåŠ¡

é›†æˆæ–°çš„æ¨¡å—åŒ–RAGæ¶æ„çš„èŠå¤©æœåŠ¡ï¼Œæä¾›æ›´å¼ºå¤§çš„æ£€ç´¢å¢å¼ºç”Ÿæˆèƒ½åŠ›ã€‚
"""

import asyncio
import logging
import time
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession

from .chat_service import ChatService
from modules.schemas.chat import ChatRequest, ChatResponse, RetrievedContext, AIMetadata
from modules.routing import QueryRoutingEngine, RoutingEngineFactory
from modules.routing.config.config_manager import KeywordConfigManager
from modules.rag.factory import RAGPipelineFactory, create_rag_pipeline_from_config, get_default_config
from modules.rag.base import IRAGPipeline, RAGStrategy, RetrievedDocument
from modules.vector_store.weaviate_service import WeaviateVectorStore
from modules.embedding.openai_service import OpenAIEmbeddingService
from config.settings import get_config

logger = logging.getLogger(__name__)


class RAGIntegratedChatService(ChatService):
    """é›†æˆæ–°RAGæ¶æ„çš„èŠå¤©æœåŠ¡"""
    
    def __init__(self, session: AsyncSession = None, ai_client=None):
        super().__init__(session, ai_client)
        
        # æ–°RAGç»„ä»¶
        self.rag_pipeline: Optional[IRAGPipeline] = None
        self.rag_config: Dict[str, Any] = {}
        self.rag_enabled = True
        self.rag_initialized = False
        
        # è·¯ç”±å¼•æ“ç›¸å…³ï¼ˆä»EnhancedChatServiceè¿ç§»ï¼‰
        self.routing_engine: Optional[QueryRoutingEngine] = None
        self.config_manager: Optional[KeywordConfigManager] = None
        self.routing_enabled = True
        self.routing_initialized = False
        
        # RAGç»Ÿè®¡
        self.rag_stats = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "avg_processing_time": 0.0,
            "avg_confidence": 0.0
        }
        
        # è·¯ç”±ç»Ÿè®¡ï¼ˆä»EnhancedChatServiceè¿ç§»ï¼‰
        self.routing_stats = {
            "total_routed": 0,
            "successful_routes": 0,
            "failed_routes": 0,
            "fallback_routes": 0
        }
        
        logger.info("RAGIntegratedChatService åˆå§‹åŒ–")
    
    async def initialize_rag(
        self, 
        pipeline_type: str = "adaptive",
        custom_config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–æ–°çš„RAGç®¡é“
        
        Args:
            pipeline_type: RAGç®¡é“ç±»å‹ ("simple", "hybrid", "adaptive", "multi_hop")
            custom_config: è‡ªå®šä¹‰é…ç½®
        """
        try:
            if self.rag_initialized:
                return
                
            logger.info(f"å¼€å§‹åˆå§‹åŒ–RAGç®¡é“ï¼Œç±»å‹: {pipeline_type}")
            
            # ç¡®ä¿åŸºç¡€æœåŠ¡å·²åˆå§‹åŒ–
            await self.initialize()
            
            # è·å–é…ç½®
            if custom_config:
                self.rag_config = custom_config
            else:
                self.rag_config = get_default_config(pipeline_type)
            
            # åˆ›å»ºRAGç®¡é“
            self.rag_pipeline = await create_rag_pipeline_from_config(
                pipeline_type=pipeline_type,
                vector_store=self._vector_store,
                embedding_service=self._embedding_service,
                db_session=self.session,
                config=self.rag_config
            )
            
            # åˆå§‹åŒ–ç®¡é“
            await self.rag_pipeline.initialize()
            
            self.rag_initialized = True
            logger.info(f"RAGç®¡é“åˆå§‹åŒ–å®Œæˆ: {pipeline_type}")
            
            # å¥åº·æ£€æŸ¥
            health = await self.rag_pipeline.health_check()
            logger.info(f"RAGç®¡é“å¥åº·çŠ¶æ€: {health.get('initialized', False)}")
            
        except Exception as e:
            logger.error(f"RAGç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag_enabled = False
            raise
    
    async def initialize_routing(
        self, 
        mode: str = "default",
        openai_client: Optional[Any] = None
    ) -> None:
        """
        åˆå§‹åŒ–è·¯ç”±å¼•æ“ï¼ˆä»EnhancedChatServiceè¿ç§»ï¼‰
        
        Args:
            mode: è·¯ç”±æ¨¡å¼ ("default", "llm_first", "keyword_only")
            openai_client: OpenAIå®¢æˆ·ç«¯
        """
        try:
            if self.routing_initialized:
                return
                
            logger.info(f"å¼€å§‹åˆå§‹åŒ–è·¯ç”±å¼•æ“ï¼Œæ¨¡å¼: {mode}")
            
            # ä½¿ç”¨å½“å‰æœåŠ¡çš„AIå®¢æˆ·ç«¯ï¼ˆå¦‚æœæ²¡æœ‰æä¾›çš„è¯ï¼‰
            if not openai_client:
                openai_client = self.ai_client
            
            # æ„å»ºè¯­ä¹‰è·¯ç”±é…ç½®
            semantic_config = self._build_semantic_config()
            
            # åˆ›å»ºè·¯ç”±å¼•æ“å’Œé…ç½®ç®¡ç†å™¨
            self.routing_engine, self.config_manager = await RoutingEngineFactory.create_with_config_manager(
                chat_service=self,
                openai_client=openai_client,
                config_dir="config/routing",
                semantic_config=semantic_config
            )
            
            # æ™ºèƒ½ç­–ç•¥ä¼˜å…ˆçº§ï¼šLLMé¦–é€‰ > è¯­ä¹‰è·¯ç”± > å…³é”®è¯åŒ¹é…
            strategy_set = False
            
            # 1. é¦–é€‰ï¼šLLMæ„å›¾è¯†åˆ«ç­–ç•¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if openai_client and "llm_intent" in self.routing_engine.strategies:
                self.routing_engine.set_default_strategy("llm_intent")
                logger.info("ğŸ§  å¯ç”¨LLMæ„å›¾è¯†åˆ«ç­–ç•¥ä½œä¸ºé»˜è®¤ç­–ç•¥ï¼ˆé¦–é€‰ï¼‰")
                strategy_set = True
                
            # 2. æ¬¡é€‰ï¼šè¯­ä¹‰è·¯ç”±ç­–ç•¥ï¼ˆå¦‚æœLLMä¸å¯ç”¨ä½†è¯­ä¹‰è·¯ç”±å¯ç”¨ï¼‰
            elif not strategy_set and semantic_config and semantic_config.get("enabled", False):
                if "semantic_router" in self.routing_engine.strategies:
                    self.routing_engine.set_default_strategy("semantic_router")
                    logger.info("ğŸ¯ å¯ç”¨è¯­ä¹‰è·¯ç”±ç­–ç•¥ä½œä¸ºé»˜è®¤ç­–ç•¥ï¼ˆæ¬¡é€‰ï¼‰")
                    strategy_set = True
                else:
                    logger.warning("è¯­ä¹‰è·¯ç”±ç­–ç•¥æ³¨å†Œå¤±è´¥")
                    
            # 3. å›é€€ï¼šå…³é”®è¯ç­–ç•¥ï¼ˆæœ€åé€‰æ‹©ï¼‰
            if not strategy_set:
                self.routing_engine.set_default_strategy("configurable_keyword")
                logger.info("ğŸ”¤ å¯ç”¨å…³é”®è¯ç­–ç•¥ä½œä¸ºé»˜è®¤ç­–ç•¥ï¼ˆå›é€€é€‰æ‹©ï¼‰")
            
            # ç‰¹æ®Šæ¨¡å¼è¦†ç›–
            if mode == "keyword_only":
                self.routing_engine.set_default_strategy("configurable_keyword")
                logger.info("ğŸ”§ å¼ºåˆ¶ä½¿ç”¨å…³é”®è¯ç­–ç•¥ï¼ˆkeyword_onlyæ¨¡å¼ï¼‰")
            elif mode == "llm_first" and openai_client:
                self.routing_engine.set_default_strategy("llm_intent") 
                logger.info("ğŸ”§ å¼ºåˆ¶ä½¿ç”¨LLMç­–ç•¥ï¼ˆllm_firstæ¨¡å¼ï¼‰")
            
            # ç¡®ä¿ç­–ç•¥è®¾ç½®æˆåŠŸ
            if not hasattr(self.routing_engine, 'default_strategy') or not self.routing_engine.default_strategy:
                self.routing_engine.set_default_strategy("configurable_keyword")
                logger.warning("âš ï¸ å›é€€åˆ°å…³é”®è¯ç­–ç•¥ä½œä¸ºæœ€ç»ˆé»˜è®¤é€‰æ‹©")
            
            self.routing_initialized = True
            logger.info(f"ğŸš€ è·¯ç”±å¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œç­–ç•¥: {self.routing_engine.default_strategy}")
            
        except Exception as e:
            logger.error(f"è·¯ç”±å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.routing_enabled = False
            raise
    
    def _build_semantic_config(self) -> Dict[str, Any]:
        """æ„å»ºè¯­ä¹‰è·¯ç”±é…ç½®ï¼ˆä»EnhancedChatServiceè¿ç§»ï¼‰"""
        try:
            from config.settings import get_config
            config = get_config()
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯­ä¹‰è·¯ç”±
            semantic_enabled = getattr(config, 'semantic_router_enabled', True)
            
            if not semantic_enabled:
                logger.info("è¯­ä¹‰è·¯ç”±åœ¨é…ç½®ä¸­è¢«ç¦ç”¨")
                return {"enabled": False}
            
            # æ„å»ºè¯­ä¹‰è·¯ç”±é…ç½®
            semantic_config = {
                "enabled": True,
                "model": getattr(config, 'semantic_router_model', 'text-embedding-3-small'),
                "threshold": getattr(config, 'semantic_router_threshold', 0.75),
                "routes_file": "config/routing/semantic_routes.yaml"
            }
            
            logger.info(f"è¯­ä¹‰è·¯ç”±é…ç½®: {semantic_config}")
            return semantic_config
            
        except Exception as e:
            logger.warning(f"æ„å»ºè¯­ä¹‰è·¯ç”±é…ç½®å¤±è´¥: {e}")
            return {"enabled": False}
    
    async def chat(self, request: ChatRequest) -> ChatResponse:
        """
        å¤„ç†èŠå¤©è¯·æ±‚ - ä½¿ç”¨æ–°çš„RAGæ¶æ„
        """
        start_time = time.time()
        
        try:
            # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–
            await self._ensure_initialized()
            
            # å¦‚æœå¯ç”¨äº†è·¯ç”±ï¼Œå…ˆè¿›è¡Œè·¯ç”±å¤„ç†
            if self.routing_enabled and self.routing_initialized:
                try:
                    routed_response = await self._handle_routing(request)
                    if routed_response:
                        return routed_response
                except Exception as e:
                    logger.warning(f"è·¯ç”±å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°RAGå¤„ç†: {e}")
            
            # ä½¿ç”¨æ–°çš„RAGç®¡é“å¤„ç†
            if self.rag_enabled and self.rag_initialized:
                return await self._handle_rag_chat(request)
            else:
                # å›é€€åˆ°åŸæœ‰çš„èŠå¤©å¤„ç†
                logger.warning("RAGæœªå¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»ŸèŠå¤©å¤„ç†")
                return await super().chat(request)
                
        except Exception as e:
            logger.error(f"èŠå¤©å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å“åº”
            return ChatResponse(
                message_id=str(uuid.uuid4()),
                conversation_id=request.conversation_id or str(uuid.uuid4()),
                content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯: {str(e)}",
                confidence=0.0,
                retrieved_contexts=[],
                ai_metadata=AIMetadata(
                    model="error",
                    tokens_used=0,
                    processing_time_ms=(time.time() - start_time) * 1000
                )
            )
    
    async def _handle_rag_chat(self, request: ChatRequest) -> ChatResponse:
        """ä½¿ç”¨æ–°RAGæ¶æ„å¤„ç†èŠå¤©è¯·æ±‚"""
        start_time = time.time()
        
        try:
            # å‡†å¤‡ç”¨æˆ·ä¸Šä¸‹æ–‡
            user_context = {
                "top_k": request.max_results,
                "score_threshold": request.score_threshold,
                "rerank_top_k": min(request.max_results, 10),  # é‡æ’åºæ•°é‡
                "topic_id": request.topic_id,
                "search_type": request.search_type.value if request.search_type else "semantic"
            }
            
            # å‡†å¤‡å¯¹è¯å†å²
            conversation_history = []
            if request.context_window > 0 and request.conversation_id:
                # è·å–å¯¹è¯å†å²ï¼ˆè¿™é‡Œå¯ä»¥ä»æ•°æ®åº“è·å–ï¼‰
                conversation_history = await self._get_conversation_history(
                    request.conversation_id, 
                    request.context_window * 2
                )
            
            # è°ƒç”¨RAGç®¡é“
            rag_response = await self.rag_pipeline.process(
                query=request.message,
                user_context=user_context,
                conversation_history=conversation_history
            )
            
            # è½¬æ¢æ£€ç´¢åˆ°çš„æ–‡æ¡£
            retrieved_contexts = []
            for doc in rag_response.retrieved_documents:
                context = RetrievedContext(
                    content=doc.content,
                    source=doc.source,
                    score=doc.score,
                    metadata=doc.metadata,
                    chunk_id=doc.id,
                    document_id=doc.metadata.get("document_id", ""),
                    title=doc.metadata.get("title", "")
                )
                retrieved_contexts.append(context)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_rag_stats(rag_response)
            
            # æ„å»ºå“åº”
            processing_time = (time.time() - start_time) * 1000
            
            response = ChatResponse(
                message_id=str(uuid.uuid4()),
                conversation_id=request.conversation_id or str(uuid.uuid4()),
                content=rag_response.answer,
                confidence=rag_response.confidence,
                retrieved_contexts=retrieved_contexts,
                ai_metadata=AIMetadata(
                    model=self.rag_config.get("generator", {}).get("model", "unknown"),
                    tokens_used=rag_response.metadata.get("tokens_used", 0),
                    processing_time_ms=processing_time,
                    rag_metadata={
                        "strategy": rag_response.metadata.get("strategy", "unknown"),
                        "documents_retrieved": len(retrieved_contexts),
                        "processing_components": list(rag_response.metadata.get("components_used", [])),
                        "rag_processing_time": rag_response.processing_time_ms
                    }
                )
            )
            
            # ä¿å­˜å¯¹è¯è®°å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if request.save_conversation:
                await self._save_conversation_message(request, response)
            
            logger.info(f"RAGèŠå¤©å¤„ç†å®Œæˆ: è€—æ—¶{processing_time:.1f}ms, "
                       f"ç½®ä¿¡åº¦{rag_response.confidence:.3f}, "
                       f"æ£€ç´¢æ–‡æ¡£{len(retrieved_contexts)}ä¸ª")
            
            return response
            
        except Exception as e:
            logger.error(f"RAGèŠå¤©å¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _handle_routing(self, request: ChatRequest) -> Optional[ChatResponse]:
        """å¤„ç†è·¯ç”±é€»è¾‘"""
        try:
            # ä½¿ç”¨è·¯ç”±å¼•æ“å¤„ç†æŸ¥è¯¢
            route_result = await self.routing_engine.route_query(
                query=request.message,
                context={
                    "conversation_id": request.conversation_id,
                    "topic_id": request.topic_id,
                    "user_context": request.dict()
                }
            )
            
            # æ›´æ–°è·¯ç”±ç»Ÿè®¡
            self.routing_stats["total_routed"] += 1
            
            if route_result and route_result.get("content"):
                self.routing_stats["successful_routes"] += 1
                
                # æ„å»ºè·¯ç”±å“åº”
                return ChatResponse(
                    message_id=str(uuid.uuid4()),
                    conversation_id=request.conversation_id or str(uuid.uuid4()),
                    content=route_result["content"],
                    confidence=route_result.get("confidence", 0.8),
                    retrieved_contexts=self._convert_routing_contexts(
                        route_result.get("retrieved_contexts", [])
                    ),
                    ai_metadata=AIMetadata(
                        model="routing_engine",
                        tokens_used=0,
                        processing_time_ms=route_result.get("processing_time_ms", 0),
                        routing_metadata={
                            "route_type": route_result.get("route_type", "unknown"),
                            "strategy_used": route_result.get("strategy_used", "unknown"),
                            "confidence": route_result.get("confidence", 0.0)
                        }
                    )
                )
            else:
                self.routing_stats["fallback_routes"] += 1
                return None
                
        except Exception as e:
            self.routing_stats["failed_routes"] += 1
            logger.warning(f"è·¯ç”±å¤„ç†å¤±è´¥: {e}")
            return None
    
    def _convert_routing_contexts(self, routing_contexts: List[Dict]) -> List[RetrievedContext]:
        """è½¬æ¢è·¯ç”±ä¸Šä¸‹æ–‡ä¸ºæ ‡å‡†æ ¼å¼"""
        contexts = []
        for ctx in routing_contexts:
            if isinstance(ctx, dict):
                context = RetrievedContext(
                    content=ctx.get("content", ""),
                    source=ctx.get("source", "routing"),
                    score=ctx.get("score", 0.0),
                    metadata=ctx.get("metadata", {}),
                    chunk_id=ctx.get("id", ""),
                    document_id=ctx.get("document_id", ""),
                    title=ctx.get("title", "")
                )
                contexts.append(context)
        return contexts
    
    async def _ensure_initialized(self) -> None:
        """ç¡®ä¿æ‰€æœ‰æœåŠ¡éƒ½å·²åˆå§‹åŒ–"""
        if not self._initialized:
            await self.initialize()
        
        if not self.rag_initialized and self.rag_enabled:
            await self.initialize_rag()
        
        if not self.routing_initialized and self.routing_enabled:
            await self.initialize_routing()
    
    def _update_rag_stats(self, rag_response) -> None:
        """æ›´æ–°RAGç»Ÿè®¡ä¿¡æ¯"""
        self.rag_stats["total_queries"] += 1
        
        if rag_response.answer:
            self.rag_stats["successful_queries"] += 1
        else:
            self.rag_stats["failed_queries"] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_time = (self.rag_stats["avg_processing_time"] * 
                     (self.rag_stats["total_queries"] - 1) + 
                     rag_response.processing_time_ms)
        self.rag_stats["avg_processing_time"] = total_time / self.rag_stats["total_queries"]
        
        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        total_confidence = (self.rag_stats["avg_confidence"] * 
                           (self.rag_stats["successful_queries"] - 1) + 
                           rag_response.confidence)
        if self.rag_stats["successful_queries"] > 0:
            self.rag_stats["avg_confidence"] = total_confidence / self.rag_stats["successful_queries"]
    
    async def _get_conversation_history(
        self, 
        conversation_id: str, 
        limit: int
    ) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        try:
            # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“è·å–å¯¹è¯å†å²
            # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚å®ç°
            return []
        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []
    
    async def _save_conversation_message(
        self, 
        request: ChatRequest, 
        response: ChatResponse
    ) -> None:
        """ä¿å­˜å¯¹è¯æ¶ˆæ¯"""
        try:
            # è¿™é‡Œåº”è¯¥ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
            # å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚å®ç°
            pass
        except Exception as e:
            logger.warning(f"ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
    
    async def get_rag_stats(self) -> Dict[str, Any]:
        """è·å–RAGç»Ÿè®¡ä¿¡æ¯"""
        stats = self.rag_stats.copy()
        
        if self.rag_pipeline:
            try:
                pipeline_metrics = await self.rag_pipeline.get_metrics()
                stats["pipeline_metrics"] = {
                    "total_processing_time_ms": pipeline_metrics.total_processing_time_ms,
                    "query_processing_time_ms": pipeline_metrics.query_processing_time_ms,
                    "retrieval_time_ms": pipeline_metrics.retrieval_time_ms,
                    "reranking_time_ms": pipeline_metrics.reranking_time_ms,
                    "generation_time_ms": pipeline_metrics.generation_time_ms
                }
            except Exception as e:
                logger.warning(f"è·å–ç®¡é“æŒ‡æ ‡å¤±è´¥: {e}")
        
        return stats
    
    async def get_routing_stats(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±ç»Ÿè®¡ä¿¡æ¯"""
        return self.routing_stats.copy()
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health = {
            "service": "rag_integrated_chat_service",
            "initialized": self._initialized,
            "rag_enabled": self.rag_enabled,
            "rag_initialized": self.rag_initialized,
            "routing_enabled": self.routing_enabled,
            "routing_initialized": self.routing_initialized
        }
        
        # RAGç®¡é“å¥åº·æ£€æŸ¥
        if self.rag_pipeline:
            try:
                rag_health = await self.rag_pipeline.health_check()
                health["rag_pipeline"] = rag_health
            except Exception as e:
                health["rag_pipeline"] = {"status": "unhealthy", "error": str(e)}
        
        # åŸºç¡€æœåŠ¡å¥åº·æ£€æŸ¥
        try:
            base_health = await super().health_check() if hasattr(super(), 'health_check') else {}
            health["base_service"] = base_health
        except Exception as e:
            health["base_service"] = {"status": "unhealthy", "error": str(e)}
        
        return health
    
    async def switch_rag_pipeline(
        self, 
        pipeline_type: str, 
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """åŠ¨æ€åˆ‡æ¢RAGç®¡é“"""
        try:
            logger.info(f"åˆ‡æ¢RAGç®¡é“åˆ°: {pipeline_type}")
            
            # æ¸…ç†ç°æœ‰ç®¡é“
            if self.rag_pipeline:
                await self.rag_pipeline.cleanup()
            
            # é‡ç½®çŠ¶æ€
            self.rag_initialized = False
            
            # åˆå§‹åŒ–æ–°ç®¡é“
            await self.initialize_rag(pipeline_type, config)
            
            logger.info(f"RAGç®¡é“åˆ‡æ¢å®Œæˆ: {pipeline_type}")
            
        except Exception as e:
            logger.error(f"åˆ‡æ¢RAGç®¡é“å¤±è´¥: {e}")
            self.rag_enabled = False
            raise
    
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            if self.rag_pipeline:
                await self.rag_pipeline.cleanup()
            
            # è°ƒç”¨çˆ¶ç±»æ¸…ç†æ–¹æ³•
            if hasattr(super(), 'cleanup'):
                await super().cleanup()
                
            logger.info("RAGIntegratedChatService èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")


# å·¥å‚å‡½æ•°
async def create_rag_integrated_chat_service(
    session: AsyncSession = None,
    ai_client = None,
    pipeline_type: str = "adaptive",
    rag_config: Optional[Dict[str, Any]] = None,
    enable_routing: bool = True
) -> RAGIntegratedChatService:
    """åˆ›å»ºRAGé›†æˆèŠå¤©æœåŠ¡"""
    
    service = RAGIntegratedChatService(session, ai_client)
    
    # åˆå§‹åŒ–RAG
    await service.initialize_rag(pipeline_type, rag_config)
    
    # åˆå§‹åŒ–è·¯ç”±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if enable_routing:
        await service.initialize_routing()
    
    return service
