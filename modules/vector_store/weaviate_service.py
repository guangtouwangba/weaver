"""
Weaviateå‘é‡å­˜å‚¨æœåŠ¡å®ç°

ä½¿ç”¨Weaviateä½œä¸ºå‘é‡æ•°æ®åº“å­˜å‚¨å’Œæœç´¢æ–‡æ¡£åµŒå…¥ã€‚
"""

import asyncio
import json
import logging
import time
from typing import Any, Dict, List, Optional, Union
from uuid import uuid4

import weaviate
from weaviate.classes.config import Configure, Property, DataType, VectorDistances
from weaviate.classes.query import Filter
from weaviate.exceptions import WeaviateBaseError

from modules.vector_store.base import (
    BulkOperationResult,
    IndexType,
    IVectorStore,
    SearchFilter,
    SearchResult,
    SimilarityMetric,
    SummaryDocument,
    VectorDocument,
    VectorStoreConfig,
    VectorStoreError,
    VectorStoreProvider,
)


class ProxyDisabler:
    """ä¸´æ—¶ç¦ç”¨ç³»ç»Ÿä»£ç†è®¾ç½®çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
        self.original_env = {}
    
    def __enter__(self):
        import os
        for var in self.proxy_vars:
            if var in os.environ:
                self.original_env[var] = os.environ[var]
            os.environ[var] = ''
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        import os
        try:
            for var in self.proxy_vars:
                if var in self.original_env:
                    os.environ[var] = self.original_env[var]
                elif var in os.environ:
                    del os.environ[var]
        except:
            pass  # å¿½ç•¥æ¢å¤ç¯å¢ƒå˜é‡æ—¶çš„é”™è¯¯

logger = logging.getLogger(__name__)


class WeaviateVectorStore(IVectorStore):
    """Weaviateå‘é‡å­˜å‚¨æœåŠ¡å®ç°"""
    
    def __init__(
        self,
        url: str = "http://localhost:8080",
        api_key: Optional[str] = None,
        timeout: int = 30,
        max_retries: int = 3,
        batch_size: int = 100,
        create_collections_on_init: bool = False,  # æ–°å‚æ•°ï¼šæ˜¯å¦åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºé›†åˆ
    ):
        self.url = url
        self.api_key = api_key
        self.timeout = timeout
        self.max_retries = max_retries
        self.batch_size = batch_size
        self._create_collections_on_init = create_collections_on_init
        
        self._client: Optional[weaviate.WeaviateClient] = None
        self._initialized = False
        
        # é›†åˆé…ç½®ç¼“å­˜
        self._collection_configs: Dict[str, VectorStoreConfig] = {}
        
        logger.info(f"Weaviateå‘é‡å­˜å‚¨åˆå§‹åŒ–: {url}")
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        if self._initialized:
            return
        
        try:
            # ç›´æ¥è¿æ¥ï¼Œä¸ä½¿ç”¨ä»£ç†ç¦ç”¨å™¨
            # åˆ›å»ºå®¢æˆ·ç«¯
            auth_config = None
            if self.api_key:
                auth_config = weaviate.auth.AuthApiKey(api_key=self.api_key)
            
            # Parse URL to get host and port
            url_parts = self.url.replace("http://", "").replace("https://", "").split(":")
            host = url_parts[0]
            port = int(url_parts[1]) if len(url_parts) > 1 else 8080
            secure = self.url.startswith("https://")
            
            # ä½¿ç”¨çº¯HTTPè¿æ¥ï¼Œç®€å•å¯é 
            self._client = weaviate.connect_to_local(
                host=host,
                port=port,
                skip_init_checks=True,
            )
            
            # æµ‹è¯•è¿æ¥
            if not self._client.is_ready():
                raise VectorStoreError("WeaviateæœåŠ¡æœªå°±ç»ª")
            
            self._initialized = True
            logger.info("Weaviateå‘é‡å­˜å‚¨è¿æ¥æˆåŠŸ")
            
            # å¦‚æœå¯ç”¨äº†é›†åˆåˆ›å»ºï¼Œåˆ›å»ºé»˜è®¤é›†åˆ(fail fast)
            if self._create_collections_on_init:
                await self._create_default_collections()
            
            logger.info("Weaviateå‘é‡å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"Weaviateåˆå§‹åŒ–å¤±è´¥: {e}")
            raise VectorStoreError(
                f"åˆå§‹åŒ–å¤±è´¥: {e}",
                provider="weaviate",
                error_code="INITIALIZATION_FAILED"
            )
    
    def _build_weaviate_filter(self, filters: SearchFilter) -> Optional[Filter]:
        """æ„å»ºWeaviateåŸç”ŸWhereè¿‡æ»¤æ¡ä»¶
        
        Args:
            filters: æœç´¢è¿‡æ»¤æ¡ä»¶
            
        Returns:
            Filter: Weaviateè¿‡æ»¤å¯¹è±¡ï¼Œå¦‚æœæ— è¿‡æ»¤æ¡ä»¶åˆ™è¿”å›None
        """
        if not filters or not filters.metadata_filters:
            return None
        
        try:
            filter_conditions = []
            
            for key, value in filters.metadata_filters.items():
                if key == "topic_id" and value is not None:
                    # topic_idè¿‡æ»¤ - Weaviateè¦æ±‚ä½¿ç”¨å­—ç¬¦ä¸²ç±»å‹
                    filter_conditions.append(Filter.by_property("topic_id").equal(str(value)))
                    logger.debug(f"ğŸ” æ·»åŠ topic_idè¿‡æ»¤æ¡ä»¶: {value} (è½¬æ¢ä¸ºå­—ç¬¦ä¸²)")
                
                elif key == "document_id" and value is not None:
                    # document_idè¿‡æ»¤ - å­—ç¬¦ä¸²ç±»å‹
                    filter_conditions.append(Filter.by_property("document_id").equal(str(value)))
                    logger.debug(f"ğŸ” æ·»åŠ document_idè¿‡æ»¤æ¡ä»¶: {value}")
                
                elif key == "collection_type" and value is not None:
                    # collection_typeè¿‡æ»¤ - ç”¨äºåŒºåˆ†ä¸åŒç±»å‹çš„å†…å®¹
                    filter_conditions.append(Filter.by_property("collection_type").equal(str(value)))
                    logger.debug(f"ğŸ” æ·»åŠ collection_typeè¿‡æ»¤æ¡ä»¶: {value}")
                    
                else:
                    # é€šç”¨metadataè¿‡æ»¤ - åœ¨metadata JSONå­—æ®µä¸­æŸ¥æ‰¾
                    # ä½¿ç”¨pathæŸ¥è¯¢æ¥è®¿é—®åµŒå¥—çš„metadataå­—æ®µ
                    filter_conditions.append(Filter.by_property(f"metadata.{key}").equal(value))
                    logger.debug(f"ğŸ” æ·»åŠ é€šç”¨metadataè¿‡æ»¤æ¡ä»¶: {key}={value}")
            
            if not filter_conditions:
                return None
            
            # å¦‚æœåªæœ‰ä¸€ä¸ªæ¡ä»¶ï¼Œç›´æ¥è¿”å›
            if len(filter_conditions) == 1:
                return filter_conditions[0]
            
            # å¤šä¸ªæ¡ä»¶ä½¿ç”¨ANDé€»è¾‘è¿æ¥
            combined_filter = filter_conditions[0]
            for condition in filter_conditions[1:]:
                combined_filter = combined_filter & condition
                
            logger.debug(f"ğŸ” æ„å»ºäº†åŒ…å«{len(filter_conditions)}ä¸ªæ¡ä»¶çš„å¤åˆè¿‡æ»¤å™¨")
            return combined_filter
            
        except Exception as e:
            logger.error(f"æ„å»ºWeaviateè¿‡æ»¤å™¨å¤±è´¥: {e}")
            return None

    async def cleanup(self) -> None:
        """æ¸…ç†å‘é‡å­˜å‚¨èµ„æº"""
        if self._client:
            try:
                self._client.close()
            except Exception as e:
                logger.warning(f"å…³é—­Weaviateå®¢æˆ·ç«¯å¤±è´¥: {e}")
            self._client = None
        
        self._initialized = False
        logger.info("Weaviateå‘é‡å­˜å‚¨èµ„æºå·²æ¸…ç†")
    
    async def _create_default_collections(self) -> None:
        """åˆ›å»ºé»˜è®¤é›†åˆï¼Œfail fastæœºåˆ¶"""
        default_collections = ["documents"]  # å¯ä»¥æ·»åŠ æ›´å¤šé»˜è®¤é›†åˆ
        
        for collection_name in default_collections:
            try:
                logger.info(f"æ£€æŸ¥/åˆ›å»ºé»˜è®¤é›†åˆ: {collection_name}")
                
                # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
                if self._client.collections.exists(collection_name):
                    logger.info(f"é›†åˆ {collection_name} å·²å­˜åœ¨")
                    continue
                
                # åˆ›å»ºé›†åˆé…ç½®
                default_config = VectorStoreConfig(
                    provider=VectorStoreProvider.WEAVIATE,
                    connection_string=self.url,
                    collection_name=collection_name,
                    dimension=1536,  # OpenAI text-embedding-3-smallç»´åº¦
                    similarity_metric=SimilarityMetric.COSINE,
                    enable_auto_vectorization=False,
                    description=f"é»˜è®¤RAGæ–‡æ¡£é›†åˆ: {collection_name}"
                )
                
                # åˆ›å»ºé›†åˆ
                success = await self.create_collection(default_config)
                if not success:
                    raise VectorStoreError(f"åˆ›å»ºé»˜è®¤é›†åˆ {collection_name} å¤±è´¥")
                
                logger.info(f"æˆåŠŸåˆ›å»ºé»˜è®¤é›†åˆ: {collection_name}")
                
            except Exception as e:
                logger.error(f"åˆ›å»ºé»˜è®¤é›†åˆ {collection_name} å¤±è´¥: {e}")
                # Fail fast - å¦‚æœé»˜è®¤é›†åˆåˆ›å»ºå¤±è´¥ï¼Œæ•´ä¸ªåˆå§‹åŒ–å¤±è´¥
                raise VectorStoreError(
                    f"åˆ›å»ºé»˜è®¤é›†åˆ {collection_name} å¤±è´¥: {e}",
                    provider="weaviate",
                    error_code="DEFAULT_COLLECTION_CREATION_FAILED"
                )
    
    async def create_collection(self, config: VectorStoreConfig) -> bool:
        """
        åˆ›å»ºå‘é‡é›†åˆ
        
        Args:
            config: é›†åˆé…ç½®
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        try:
            collection_name = config.collection_name
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨
            if self._client.collections.exists(collection_name):
                logger.info(f"é›†åˆ {collection_name} å·²å­˜åœ¨")
                self._collection_configs[collection_name] = config
                return True
            
            # åˆ›å»ºé›†åˆå±æ€§
            properties = [
                Property(name="content", data_type=DataType.TEXT),
                Property(name="document_id", data_type=DataType.TEXT),
                Property(name="chunk_index", data_type=DataType.INT),
                Property(name="content_type", data_type=DataType.TEXT),
                Property(name="topic_id", data_type=DataType.TEXT),
                Property(name="file_id", data_type=DataType.TEXT),
                Property(name="title", data_type=DataType.TEXT),
                Property(name="metadata", data_type=DataType.TEXT),  # ä½¿ç”¨TEXTå­˜å‚¨JSONå­—ç¬¦ä¸²
                Property(name="created_at", data_type=DataType.TEXT),
            ]
            
            # å‘é‡åŒ–å™¨é…ç½®
            vectorizer_config = None
            if config.enable_auto_vectorization:
                vectorizer_config = Configure.Vectorizer.none()  # ä½¿ç”¨å¤–éƒ¨å‘é‡
            
            # åˆ›å»ºé›†åˆ
            collection = self._client.collections.create(
                name=collection_name,
                properties=properties,
                vectorizer_config=vectorizer_config,
                vector_index_config=Configure.VectorIndex.hnsw(
                    distance_metric=self._convert_similarity_metric(config.similarity_metric)
                ),
                description=f"RAGæ–‡æ¡£é›†åˆ: {config.description or collection_name}",
            )
            
            self._collection_configs[collection_name] = config
            logger.info(f"æˆåŠŸåˆ›å»ºé›†åˆ: {collection_name}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé›†åˆå¤±è´¥ {config.collection_name}: {e}")
            raise VectorStoreError(
                f"åˆ›å»ºé›†åˆå¤±è´¥: {e}",
                provider="weaviate",
                error_code="COLLECTION_CREATION_FAILED"
            )
    
    async def delete_collection(self, collection_name: str) -> bool:
        """
        åˆ é™¤å‘é‡é›†åˆ
        
        Args:
            collection_name: é›†åˆåç§°
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        try:
            if not self._client.collections.exists(collection_name):
                logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
                return True
            
            self._client.collections.delete(collection_name)
            
            # æ¸…ç†é…ç½®ç¼“å­˜
            if collection_name in self._collection_configs:
                del self._collection_configs[collection_name]
            
            logger.info(f"æˆåŠŸåˆ é™¤é›†åˆ: {collection_name}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤é›†åˆå¤±è´¥ {collection_name}: {e}")
            raise VectorStoreError(
                f"åˆ é™¤é›†åˆå¤±è´¥: {e}",
                provider="weaviate",
                error_code="COLLECTION_DELETION_FAILED"
            )
    
    async def upsert_vectors(
        self, documents: List[VectorDocument]
    ) -> BulkOperationResult:
        """
        æ‰¹é‡æ’å…¥æˆ–æ›´æ–°å‘é‡
        
        Args:
            documents: å‘é‡æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            BulkOperationResult: æ‰¹é‡æ“ä½œç»“æœ
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        if not documents:
            return BulkOperationResult(
                success_count=0,
                failed_count=0,
                total_count=0,
                errors=[]
            )
        
        start_time = time.time()
        # ä»ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„metadataä¸­è·å–collection_nameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        collection_name = documents[0].metadata.get('collection_name', 'documents')
        
        try:
            # ç¡®ä¿é›†åˆå­˜åœ¨
            await self._ensure_collection_exists(collection_name)
            
            collection = self._client.collections.get(collection_name)
            
            # æ‰¹é‡å¤„ç†
            success_count = 0
            failed_count = 0
            errors = []
            
            for i in range(0, len(documents), self.batch_size):
                batch_docs = documents[i:i + self.batch_size]
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_objects = []
                for doc in batch_docs:
                    # å°†metadataåºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²
                    metadata_json = json.dumps(doc.metadata.get("chunk_metadata", {}))
                    
                    obj_data = {
                        "content": doc.content,  # ç›´æ¥ä½¿ç”¨doc.contentï¼Œä¸æ˜¯metadataä¸­çš„
                        "document_id": doc.document_id or doc.metadata.get("document_id", ""),
                        "chunk_index": doc.chunk_index if hasattr(doc, 'chunk_index') else doc.metadata.get("chunk_index", 0),
                        "content_type": doc.metadata.get("content_type", ""),
                        "topic_id": doc.metadata.get("topic_id", ""),
                        "file_id": doc.metadata.get("file_id", ""),
                        "title": doc.metadata.get("title", ""),
                        "metadata": metadata_json,  # JSONå­—ç¬¦ä¸²
                        "created_at": doc.metadata.get("created_at", ""),
                    }
                    
                    batch_objects.append({
                        "uuid": doc.id,
                        "properties": obj_data,
                        "vector": doc.vector
                    })
                
                # æ‰§è¡Œæ‰¹é‡æ’å…¥
                try:
                    # ç›´æ¥æ‰¹é‡æ“ä½œï¼Œä¸ä½¿ç”¨ä»£ç†ç¦ç”¨å™¨
                    with collection.batch.dynamic() as batch:
                        for obj in batch_objects:
                            batch.add_object(
                                properties=obj["properties"],
                                vector=obj["vector"],
                                uuid=obj["uuid"]
                            )
                    
                    success_count += len(batch_docs)
                    logger.debug(f"æ‰¹é‡æ’å…¥æˆåŠŸ: {len(batch_docs)} æ–‡æ¡£")
                    
                except Exception as e:
                    failed_count += len(batch_docs)
                    error_msg = f"æ‰¹é‡æ’å…¥å¤±è´¥: {e}"
                    errors.append(error_msg)
                    logger.error(error_msg)
                
                # é¿å…è¿‡è½½
                if i + self.batch_size < len(documents):
                    await asyncio.sleep(0.01)
            
            processing_time = (time.time() - start_time) * 1000
            
            result = BulkOperationResult(
                success_count=success_count,
                failed_count=failed_count,
                total_count=len(documents),
                processing_time_ms=processing_time,
                errors=errors
            )
            
            logger.info(
                f"æ‰¹é‡å‘é‡æ“ä½œå®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥, "
                f"è€—æ—¶ {processing_time:.1f}ms"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å‘é‡æ“ä½œå¤±è´¥: {e}")
            raise VectorStoreError(
                f"æ‰¹é‡å‘é‡æ“ä½œå¤±è´¥: {e}",
                provider="weaviate",
                error_code="BULK_OPERATION_FAILED"
            )
    
    async def upsert_single_vector(self, document: VectorDocument) -> bool:
        """
        æ’å…¥æˆ–æ›´æ–°å•ä¸ªå‘é‡
        
        Args:
            document: å‘é‡æ–‡æ¡£
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        result = await self.upsert_vectors([document])
        return result.success_count > 0
    
    async def search_similar(
        self,
        query_vector: List[float],
        limit: int = 10,
        score_threshold: Optional[float] = None,
        filters: Optional[SearchFilter] = None,
        collection_name: str = "documents",
    ) -> List[SearchResult]:
        """
        æœç´¢ç›¸ä¼¼å‘é‡
        
        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            filters: æœç´¢è¿‡æ»¤æ¡ä»¶
            collection_name: é›†åˆåç§°
            
        Returns:
            List[SearchResult]: æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        try:
            collection = self._client.collections.get(collection_name)
            
            # æ£€æŸ¥é›†åˆä¸­çš„æ–‡æ¡£æ€»æ•°
            try:
                total_objects = collection.aggregate.over_all(total_count=True)
                total_count = total_objects.total_count
                logger.info(f"ğŸ“š å‘é‡æ•°æ®åº“çŠ¶æ€: collection='{collection_name}', æ€»æ–‡æ¡£æ•°={total_count}")
                
                if total_count == 0:
                    logger.warning(f"âš ï¸ å‘é‡æ•°æ®åº“ä¸ºç©ºï¼collection '{collection_name}' ä¸­æ²¡æœ‰ä»»ä½•æ–‡æ¡£")
                    return []
                    
            except Exception as count_error:
                logger.warning(f"âš ï¸ æ— æ³•è·å–æ–‡æ¡£æ€»æ•°: {count_error}")
            
            # æ„å»ºWeaviateåŸç”Ÿwhereè¿‡æ»¤æ¡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨æ•°æ®åº“å±‚è¿‡æ»¤ï¼‰
            where_filter = self._build_weaviate_filter(filters) if filters else None
            
            # ä½¿ç”¨åŸç”Ÿè¿‡æ»¤æ—¶ä¸éœ€è¦å¢åŠ æœç´¢æ•°é‡ï¼Œåº”ç”¨å±‚è¿‡æ»¤æ—¶æ‰éœ€è¦
            if where_filter:
                search_limit = limit  # æ•°æ®åº“å±‚å·²è¿‡æ»¤ï¼Œä½¿ç”¨ç²¾ç¡®é™åˆ¶
                logger.debug(f"ğŸ¯ ä½¿ç”¨WeaviateåŸç”Ÿwhereè¿‡æ»¤ï¼Œç²¾ç¡®é™åˆ¶: {search_limit}")
            else:
                search_limit = limit * 3 if filters else limit  # åº”ç”¨å±‚è¿‡æ»¤éœ€è¦æ›´å¤šå€™é€‰
                logger.debug(f"ğŸ”„ ä½¿ç”¨åº”ç”¨å±‚è¿‡æ»¤ï¼Œæ‰©å¤§æœç´¢èŒƒå›´: {search_limit}")
            
            logger.debug(f"ğŸ” Weaviateæœç´¢å‚æ•°: collection={collection_name}, "
                        f"å‘é‡ç»´åº¦={len(query_vector)}, limit={search_limit}, "
                        f"score_threshold={score_threshold}")
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°ï¼Œæ ¹æ®æ˜¯å¦æœ‰è¿‡æ»¤æ¡ä»¶é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
            query_params = {
                "near_vector": query_vector,
                "limit": search_limit,
                "return_metadata": ["score", "distance"]
            }
            
            # å¦‚æœæœ‰è¿‡æ»¤æ¡ä»¶ï¼Œæ·»åŠ filterså‚æ•°ï¼ˆv4å®¢æˆ·ç«¯ä½¿ç”¨filtersè€Œä¸æ˜¯whereï¼‰
            if where_filter:
                query_params["filters"] = where_filter
                logger.debug(f"ğŸ¯ æ·»åŠ åŸç”Ÿfiltersè¿‡æ»¤æ¡ä»¶: {where_filter}")
            
            response = collection.query.near_vector(**query_params)
            
            logger.debug(f"ğŸ“Š WeaviateåŸå§‹å“åº”: {len(response.objects)} ä¸ªå¯¹è±¡")
            
            # å¤„ç†ç»“æœå¹¶åº”ç”¨åº”ç”¨å±‚è¿‡æ»¤
            results = []
            filtered_count = 0
            score_filtered_count = 0
            
            logger.debug(f"ğŸ” å¼€å§‹å¤„ç† {len(response.objects)} ä¸ªWeaviateå“åº”å¯¹è±¡")
            
            for i, obj in enumerate(response.objects):
                # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                score = getattr(obj.metadata, 'score', 0.0)
                distance = getattr(obj.metadata, 'distance', 1.0)
                
                logger.debug(f"ğŸ“„ å¤„ç†å¯¹è±¡ {i+1}: UUID={obj.uuid}, score={score:.4f}, distance={distance:.4f}")
                
                # åº”ç”¨åˆ†æ•°é˜ˆå€¼
                if score_threshold and score < score_threshold:
                    score_filtered_count += 1
                    logger.debug(f"âŒ å¯¹è±¡ {i+1} è¢«åˆ†æ•°é˜ˆå€¼è¿‡æ»¤ (score={score:.4f} < threshold={score_threshold})")
                    continue
                
                # ååºåˆ—åŒ–metadata JSONå­—ç¬¦ä¸²
                properties = dict(obj.properties)
                if "metadata" in properties and isinstance(properties["metadata"], str):
                    try:
                        properties["metadata"] = json.loads(properties["metadata"])
                    except (json.JSONDecodeError, TypeError):
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²
                        logger.debug(f"âš ï¸ å¯¹è±¡ {i+1} metadata JSONè§£æå¤±è´¥ï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²")
                        pass
                
                # åº”ç”¨å±‚è¿‡æ»¤ï¼ˆä»…åœ¨æ²¡æœ‰ä½¿ç”¨åŸç”Ÿwhereè¿‡æ»¤æ—¶æ‰§è¡Œï¼‰
                if filters and not where_filter and not self._apply_filters_on_result(properties, filters):
                    filtered_count += 1
                    logger.debug(f"âŒ å¯¹è±¡ {i+1} è¢«åº”ç”¨å±‚è¿‡æ»¤å™¨è¿‡æ»¤")
                    continue
                elif where_filter:
                    # ä½¿ç”¨äº†åŸç”Ÿè¿‡æ»¤ï¼Œè·³è¿‡åº”ç”¨å±‚è¿‡æ»¤
                    logger.debug(f"âœ… å¯¹è±¡ {i+1} å·²é€šè¿‡WeaviateåŸç”Ÿè¿‡æ»¤")
                
                # å¦‚æœå·²ç»æœ‰è¶³å¤Ÿçš„ç»“æœï¼Œåœæ­¢å¤„ç†
                if len(results) >= limit:
                    logger.debug(f"âœ… å·²è¾¾åˆ°ç»“æœé™åˆ¶ {limit}ï¼Œåœæ­¢å¤„ç†")
                    break
                
                # æå–æ–‡æ¡£ä¿¡æ¯ç”¨äºæ—¥å¿—
                content = obj.properties.get("content", "")
                content_preview = content[:50] + "..." if len(content) > 50 else content
                doc_id = obj.properties.get("document_id", "")
                
                logger.debug(f"âœ… å¯¹è±¡ {i+1} é€šè¿‡æ‰€æœ‰è¿‡æ»¤: UUID={obj.uuid}, "
                           f"doc_id={doc_id}, content_preview='{content_preview}'")
                
                # åˆ›å»ºVectorDocument
                vector_doc = VectorDocument(
                    id=str(obj.uuid),
                    content=content,
                    metadata=properties.get("metadata", {}),
                    vector=None  # å‘é‡ä¸éœ€è¦åœ¨æœç´¢ç»“æœä¸­è¿”å›
                )
                
                result = SearchResult(
                    document=vector_doc,
                    score=score,
                    rank=0,  # Weaviateä¸æä¾›rankï¼Œè®¾ä¸º0
                    metadata=properties
                )
                results.append(result)
            
            # è¯¦ç»†çš„è¿‡æ»¤ç»Ÿè®¡æ—¥å¿—
            if score_filtered_count > 0:
                logger.info(f"ğŸ¯ åˆ†æ•°é˜ˆå€¼è¿‡æ»¤ç§»é™¤äº† {score_filtered_count} ä¸ªç»“æœ (< {score_threshold})")
            if filtered_count > 0:
                logger.info(f"ğŸ¯ åº”ç”¨å±‚è¿‡æ»¤ç§»é™¤äº† {filtered_count} ä¸ªç»“æœ")
            if where_filter:
                logger.info(f"ğŸš€ ä½¿ç”¨WeaviateåŸç”Ÿwhereè¿‡æ»¤ï¼Œè·³è¿‡åº”ç”¨å±‚è¿‡æ»¤æå‡æ€§èƒ½")
            
            logger.info(f"ğŸ“Š Weaviateæœç´¢å®Œæˆ: åŸå§‹{len(response.objects)}ä¸ª â†’ æœ€ç»ˆ{len(results)}ä¸ªç»“æœ")
            
            logger.debug(f"å‘é‡æœç´¢å®Œæˆ: æŸ¥è¯¢å‘é‡ç»´åº¦ {len(query_vector)}, è¿”å› {len(results)} ç»“æœ")
            
            return results
            
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±è´¥: {e}")
            raise VectorStoreError(
                f"å‘é‡æœç´¢å¤±è´¥: {e}",
                provider="weaviate",
                error_code="SEARCH_FAILED"
            )
    
    async def delete_vectors(
        self,
        ids: List[str],
        collection_name: str = "documents"
    ) -> BulkOperationResult:
        """
        åˆ é™¤å‘é‡
        
        Args:
            ids: è¦åˆ é™¤çš„å‘é‡IDåˆ—è¡¨
            collection_name: é›†åˆåç§°
            
        Returns:
            BulkOperationResult: æ‰¹é‡æ“ä½œç»“æœ
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        try:
            collection = self._client.collections.get(collection_name)
            
            success_count = 0
            failed_count = 0
            errors = []
            
            for doc_id in ids:
                try:
                    collection.data.delete_by_id(doc_id)
                    success_count += 1
                except Exception as e:
                    failed_count += 1
                    errors.append(f"åˆ é™¤ {doc_id} å¤±è´¥: {e}")
            
            result = BulkOperationResult(
                success_count=success_count,
                failed_count=failed_count,
                total_count=len(ids),
                errors=errors
            )
            
            logger.info(f"æ‰¹é‡åˆ é™¤å®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥")
            
            return result
            
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
            raise VectorStoreError(
                f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}",
                provider="weaviate",
                error_code="BULK_DELETE_FAILED"
            )
    
    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:
        """
        è·å–é›†åˆä¿¡æ¯
        
        Args:
            collection_name: é›†åˆåç§°
            
        Returns:
            Dict[str, Any]: é›†åˆä¿¡æ¯
        """
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        try:
            if not self._client.collections.exists(collection_name):
                raise VectorStoreError(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
            
            collection = self._client.collections.get(collection_name)
            
            # è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
            aggregate_result = collection.aggregate.over_all(total_count=True)
            total_count = aggregate_result.total_count
            
            info = {
                "name": collection_name,
                "total_objects": total_count,
                "exists": True,
                "config": self._collection_configs.get(collection_name, {})
            }
            
            return info
            
        except Exception as e:
            logger.error(f"è·å–é›†åˆä¿¡æ¯å¤±è´¥ {collection_name}: {e}")
            raise VectorStoreError(
                f"è·å–é›†åˆä¿¡æ¯å¤±è´¥: {e}",
                provider="weaviate",
                error_code="GET_COLLECTION_INFO_FAILED"
            )
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        status = {
            "service": "weaviate_vector_store",
            "status": "healthy" if self._initialized else "not_initialized",
            "url": self.url,
            "timeout": self.timeout,
            "batch_size": self.batch_size,
        }
        
        if self._initialized and self._client:
            try:
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å°±ç»ª
                is_ready = self._client.is_ready()
                status["is_ready"] = is_ready
                status["is_live"] = self._client.is_live()
                
                if is_ready:
                    # è·å–æœåŠ¡å™¨ä¿¡æ¯
                    meta_info = self._client.get_meta()
                    status["version"] = meta_info.get("version", "unknown")
                
            except Exception as e:
                status["status"] = "unhealthy"
                status["error"] = str(e)
        
        return status
    
    async def _ensure_collection_exists(self, collection_name: str) -> None:
        """ç¡®ä¿é›†åˆå­˜åœ¨(é€šå¸¸åœ¨å¯åŠ¨æ—¶å·²åˆ›å»ºï¼Œè¿™æ˜¯å¤‡ç”¨æ£€æŸ¥)"""
        if not self._client.collections.exists(collection_name):
            logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...")
            
            # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºé›†åˆ
            default_config = VectorStoreConfig(
                provider=VectorStoreProvider.WEAVIATE,
                connection_string=self.url,
                collection_name=collection_name,
                dimension=1536,  # é»˜è®¤OpenAIåµŒå…¥ç»´åº¦
                similarity_metric=SimilarityMetric.COSINE,
                enable_auto_vectorization=False,  # æˆ‘ä»¬æä¾›è‡ªå·±çš„å‘é‡
                description=f"è¿è¡Œæ—¶åˆ›å»ºçš„é›†åˆ: {collection_name}"
            )
            
            success = await self.create_collection(default_config)
            if not success:
                raise VectorStoreError(f"è¿è¡Œæ—¶åˆ›å»ºé›†åˆ {collection_name} å¤±è´¥")
            
            logger.info(f"è¿è¡Œæ—¶æˆåŠŸåˆ›å»ºé›†åˆ: {collection_name}")
        else:
            logger.debug(f"é›†åˆ {collection_name} å·²å­˜åœ¨")
    
    def _convert_similarity_metric(self, metric: SimilarityMetric) -> VectorDistances:
        """è½¬æ¢ç›¸ä¼¼åº¦åº¦é‡ä¸ºWeaviate VectorDistancesæšä¸¾"""
        mapping = {
            SimilarityMetric.COSINE: VectorDistances.COSINE,
            SimilarityMetric.DOT_PRODUCT: VectorDistances.DOT,
            SimilarityMetric.EUCLIDEAN: VectorDistances.L2_SQUARED,
            SimilarityMetric.MANHATTAN: VectorDistances.MANHATTAN,
        }
        return mapping.get(metric, VectorDistances.COSINE)
    
    def _build_where_filter(self, filters: SearchFilter) -> Optional[Filter]:
        """æ„å»ºWeaviateæŸ¥è¯¢è¿‡æ»¤å™¨"""
        if not filters:
            return None
        
        try:
            conditions = []
            
            # å¤„ç†metadata_filters
            if filters.metadata_filters:
                for field, value in filters.metadata_filters.items():
                    if value is not None:
                        # æ ¹æ®å€¼ç±»å‹å†³å®šè¿‡æ»¤æ–¹å¼
                        if isinstance(value, list):
                            conditions.append(
                                Filter.by_property(field).contains_any(value)
                            )
                        else:
                            conditions.append(
                                Filter.by_property(field).equal(value)
                            )
            
            # å¤„ç†document_ids
            if filters.document_ids:
                conditions.append(
                    Filter.by_property("document_id").contains_any(filters.document_ids)
                )
            
            # å¤„ç†content_filters
            if filters.content_filters:
                for field, value in filters.content_filters.items():
                    if value:
                        conditions.append(
                            Filter.by_property(field).like(f"*{value}*")
                        )
            
            # å¤„ç†date_range
            if filters.date_range:
                start_date, end_date = filters.date_range
                conditions.append(
                    Filter.by_property("created_at").greater_or_equal(start_date.isoformat())
                )
                conditions.append(
                    Filter.by_property("created_at").less_or_equal(end_date.isoformat())
                )
            
            # ç»„åˆæ¡ä»¶ (é»˜è®¤ä½¿ç”¨AND)
            if len(conditions) == 1:
                return conditions[0]
            elif len(conditions) > 1:
                result = conditions[0]
                for condition in conditions[1:]:
                    result = result & condition
                return result
        
        except Exception as e:
            logger.warning(f"æ„å»ºè¿‡æ»¤å™¨å¤±è´¥: {e}")
            return None
        
        return None

    def _apply_filters_on_result(self, properties: Dict[str, Any], filters: SearchFilter) -> bool:
        """åœ¨åº”ç”¨å±‚åº”ç”¨è¿‡æ»¤æ¡ä»¶"""
        try:
            # è·å–å®é™…çš„metadata
            metadata = properties.get("metadata", {})
            if isinstance(metadata, str):
                try:
                    metadata = json.loads(metadata)
                except (json.JSONDecodeError, TypeError):
                    metadata = {}
            
            # æ£€æŸ¥metadata_filters
            if filters.metadata_filters:
                for key, expected_value in filters.metadata_filters.items():
                    actual_value = None
                    
                    # åœ¨propertiesæˆ–metadataä¸­æŸ¥æ‰¾å€¼
                    if key in properties:
                        actual_value = properties[key]
                    elif key in metadata:
                        actual_value = metadata[key]
                    
                    # æ£€æŸ¥å€¼æ˜¯å¦åŒ¹é…
                    if actual_value is None:
                        return False
                    
                    if isinstance(expected_value, list):
                        if actual_value not in expected_value:
                            return False
                    else:
                        if actual_value != expected_value:
                            return False
            
            # æ£€æŸ¥document_ids
            if filters.document_ids:
                document_id = properties.get("document_id") or metadata.get("document_id")
                if document_id not in filters.document_ids:
                    return False
            
            # æ£€æŸ¥content_filters
            if filters.content_filters:
                content = properties.get("content", "")
                for field, pattern in filters.content_filters.items():
                    if pattern and pattern.lower() not in content.lower():
                        return False
            
            # æ£€æŸ¥date_range (ç®€åŒ–å®ç°)
            if filters.date_range:
                # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°æ—¥æœŸèŒƒå›´è¿‡æ»¤
                pass
            
            return True
            
        except Exception as e:
            logger.warning(f"åº”ç”¨è¿‡æ»¤å™¨æ—¶å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶ä¸è¿‡æ»¤

    async def get_vector_by_id(self, vector_id: str) -> Optional[VectorDocument]:
        """æ ¹æ®IDè·å–å‘é‡"""
        if not self._client:
            await self.initialize()
        
        try:
            # è·å–é»˜è®¤é›†åˆ
            collection_name = "documents"  # Default collection name
            collection = self._client.collections.get(collection_name)
            
            # æŸ¥è¯¢å‘é‡
            response = collection.query.fetch_object_by_id(vector_id)
            if not response:
                return None
            
            # è½¬æ¢ä¸ºVectorDocument
            properties = response.properties
            return VectorDocument(
                id=vector_id,
                vector=response.vector if hasattr(response, 'vector') else [],
                content=properties.get('content', ''),
                metadata=properties.get('metadata', {}),
                document_id=properties.get('document_id'),
                chunk_index=properties.get('chunk_index'),
            )
            
        except Exception as e:
            logger.error(f"è·å–å‘é‡å¤±è´¥ {vector_id}: {e}")
            return None

    async def delete_vectors_by_document_id(self, document_id: str) -> BulkOperationResult:
        """æ ¹æ®æ–‡æ¡£IDåˆ é™¤æ‰€æœ‰ç›¸å…³å‘é‡"""
        if not self._client:
            await self.initialize()
        
        try:
            collection_name = "documents"  # Default collection name
            collection = self._client.collections.get(collection_name)
            
            # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰å‘é‡
            where_filter = Filter.by_property("document_id").equal(document_id)
            
            # åˆ é™¤å‘é‡
            result = collection.data.delete_many(where=where_filter)
            
            return BulkOperationResult(
                successful=result.successful if hasattr(result, 'successful') else 0,
                failed=result.failed if hasattr(result, 'failed') else 0,
                errors=[]
            )
            
        except Exception as e:
            logger.error(f"æ ¹æ®æ–‡æ¡£IDåˆ é™¤å‘é‡å¤±è´¥ {document_id}: {e}")
            return BulkOperationResult(successful=0, failed=1, errors=[str(e)])

    async def update_metadata(self, vector_id: str, metadata: Dict[str, Any]) -> bool:
        """æ›´æ–°å‘é‡å…ƒæ•°æ®"""
        if not self._client:
            await self.initialize()
        
        try:
            collection_name = "documents"  # Default collection name
            collection = self._client.collections.get(collection_name)
            
            # æ›´æ–°å…ƒæ•°æ®
            collection.data.update(
                uuid=vector_id,
                properties={"metadata": metadata}
            )
            
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°å‘é‡å…ƒæ•°æ®å¤±è´¥ {vector_id}: {e}")
            return False

    async def get_collection_stats(self) -> Dict[str, Any]:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if not self._client:
            await self.initialize()
        
        try:
            collection_name = "documents"  # Default collection name
            collection = self._client.collections.get(collection_name)
            
            # è·å–é›†åˆä¿¡æ¯
            response = collection.aggregate.over_all()
            
            return {
                "collection_name": collection_name,
                "total_objects": response.total_count if hasattr(response, 'total_count') else 0,
                "status": "active"
            }
            
        except Exception as e:
            logger.error(f"è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "collection_name": "documents",
                "total_objects": 0,
                "status": "error",
                "error": str(e)
            }
    
    async def upsert_summary_documents(
        self, summaries: List[SummaryDocument]
    ) -> BulkOperationResult:
        """æ’å…¥æˆ–æ›´æ–°æ‘˜è¦æ–‡æ¡£"""
        if not summaries:
            return BulkOperationResult(0, 0, 0, 0.0)
        
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        start_time = time.time()
        success_count = 0
        failed_count = 0
        errors = []
        
        # ç¡®å®šæ‘˜è¦é›†åˆåç§° 
        summary_collection_name = "summaries"
        
        try:
            # ç¡®ä¿æ‘˜è¦é›†åˆå­˜åœ¨
            await self._ensure_summary_collection(summary_collection_name)
            
            collection = self._client.collections.get(summary_collection_name)
            
            # æ‰¹é‡æ’å…¥
            with collection.batch.rate_limit(requests_per_minute=600) as batch:
                for summary in summaries:
                    try:
                        properties = {
                            "summary": summary.summary,
                            "key_topics": summary.key_topics,
                            "document_ids": summary.document_ids,
                            "scope_level": summary.scope_level,
                            "created_at": summary.created_at.isoformat(),
                            **summary.metadata
                        }
                        
                        batch.add_object(
                            properties=properties,
                            vector=summary.vector,
                            uuid=summary.id
                        )
                        success_count += 1
                        
                    except Exception as e:
                        failed_count += 1
                        errors.append(f"Failed to process summary {summary.id}: {e}")
                        logger.error(f"æ’å…¥æ‘˜è¦æ–‡æ¡£å¤±è´¥ {summary.id}: {e}")
            
            processing_time = (time.time() - start_time) * 1000
            logger.info(f"æ’å…¥æ‘˜è¦æ–‡æ¡£å®Œæˆ: æˆåŠŸ={success_count}, å¤±è´¥={failed_count}")
            
            return BulkOperationResult(
                success_count=success_count,
                failed_count=failed_count,
                total_count=len(summaries),
                processing_time_ms=processing_time,
                errors=errors
            )
            
        except Exception as e:
            logger.error(f"æ‰¹é‡æ’å…¥æ‘˜è¦æ–‡æ¡£å¤±è´¥: {e}")
            raise VectorStoreError(
                f"æ‰¹é‡æ’å…¥æ‘˜è¦æ–‡æ¡£å¤±è´¥: {e}",
                provider="weaviate",
                error_code="BULK_UPSERT_SUMMARIES_FAILED"
            )
    
    async def search_summaries(
        self,
        query_vector: List[float],
        top_k: int = 10,
        score_threshold: float = 0.0,
        filters: Optional[SearchFilter] = None,
    ) -> List[SearchResult]:
        """æœç´¢æ‘˜è¦æ–‡æ¡£"""
        if not self._initialized:
            raise VectorStoreError("æœåŠ¡æœªåˆå§‹åŒ–", provider="weaviate")
        
        summary_collection_name = "summaries"
        
        try:
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if not self._client.collections.exists(summary_collection_name):
                logger.warning(f"æ‘˜è¦é›†åˆ {summary_collection_name} ä¸å­˜åœ¨")
                return []
            
            collection = self._client.collections.get(summary_collection_name)
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_filter = None
            if filters and filters.metadata_filters:
                where_filter = self._build_weaviate_filter(filters)
            
            # æ‰§è¡Œå‘é‡æœç´¢
            query_result = collection.query.near_vector(
                near_vector=query_vector,
                limit=top_k,
                distance=1 - score_threshold if score_threshold > 0 else None,
                where=where_filter,
                return_metadata=['distance', 'certainty']
            )
            
            results = []
            for i, obj in enumerate(query_result.objects):
                # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                certainty = obj.metadata.certainty if obj.metadata.certainty is not None else 0.0
                
                # åˆ›å»ºæ‘˜è¦æ–‡æ¡£å¯¹è±¡
                summary_doc = SummaryDocument(
                    id=str(obj.uuid),
                    vector=[],  # ä¸è¿”å›å‘é‡ä»¥èŠ‚çœå†…å­˜
                    summary=obj.properties.get('summary', ''),
                    key_topics=obj.properties.get('key_topics', []),
                    document_ids=obj.properties.get('document_ids', []),
                    scope_level=obj.properties.get('scope_level', 'document'),
                    metadata={k: v for k, v in obj.properties.items() 
                             if k not in ['summary', 'key_topics', 'document_ids', 'scope_level', 'created_at']}
                )
                
                # åŒ…è£…ä¸ºVectorDocumentä»¥ä¾¿ä¸SearchResultå…¼å®¹
                vector_doc = VectorDocument(
                    id=str(obj.uuid),
                    vector=[],
                    content=summary_doc.summary,
                    metadata={
                        'summary_document': True,
                        'key_topics': summary_doc.key_topics,
                        'document_ids': summary_doc.document_ids,
                        'scope_level': summary_doc.scope_level,
                        **summary_doc.metadata
                    }
                )
                
                result = SearchResult(
                    document=vector_doc,
                    score=certainty,
                    rank=i + 1
                )
                results.append(result)
            
            logger.info(f"æ‘˜è¦æœç´¢å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"æ‘˜è¦æœç´¢å¤±è´¥: {e}")
            raise VectorStoreError(
                f"æ‘˜è¦æœç´¢å¤±è´¥: {e}",
                provider="weaviate",
                error_code="SUMMARY_SEARCH_FAILED"
            )
    
    async def _ensure_summary_collection(self, collection_name: str) -> None:
        """ç¡®ä¿æ‘˜è¦é›†åˆå­˜åœ¨"""
        if not self._client.collections.exists(collection_name):
            logger.info(f"åˆ›å»ºæ‘˜è¦é›†åˆ: {collection_name}")
            
            # å®šä¹‰æ‘˜è¦é›†åˆçš„å±æ€§
            properties = [
                Property(name="summary", data_type=DataType.TEXT),
                Property(name="key_topics", data_type=DataType.TEXT_ARRAY),
                Property(name="document_ids", data_type=DataType.TEXT_ARRAY),
                Property(name="scope_level", data_type=DataType.TEXT),
                Property(name="created_at", data_type=DataType.TEXT),
            ]
            
            # åˆ›å»ºé›†åˆ
            self._client.collections.create(
                name=collection_name,
                properties=properties,
                vectorizer_config=Configure.Vectorizer.none(),  # ä½¿ç”¨å¤–éƒ¨å‘é‡
                vector_index_config=Configure.VectorIndex.hnsw(
                    distance_metric=VectorDistances.COSINE
                ),
                description="æ–‡æ¡£æ‘˜è¦é›†åˆï¼Œç”¨äºé«˜çº§æ¦‚å¿µå’Œä¸»é¢˜æ£€ç´¢"
            )
            
            # ç¼“å­˜é›†åˆé…ç½®
            self._collection_configs[collection_name] = VectorStoreConfig(
                provider=VectorStoreProvider.WEAVIATE,
                connection_string=self.url,
                collection_name=collection_name,
                dimension=1536,  # é»˜è®¤OpenAIåµŒå…¥ç»´åº¦
                similarity_metric=SimilarityMetric.COSINE,
                index_type=IndexType.SUMMARY,
                description="æ‘˜è¦æ–‡æ¡£é›†åˆ"
            )
            
            logger.info(f"æ‘˜è¦é›†åˆ {collection_name} åˆ›å»ºå®Œæˆ")

    @property
    def service_name(self) -> str:
        """è·å–æœåŠ¡åç§°"""
        return "weaviate"

    @property
    def config(self) -> VectorStoreConfig:
        """è·å–é…ç½®ä¿¡æ¯"""
        return VectorStoreConfig(
            provider=VectorStoreProvider.WEAVIATE,
            connection_string=self.url,
            collection_name="documents",  # Default collection name
            dimension=1536,  # Default OpenAI embedding dimension
            similarity_metric=SimilarityMetric.COSINE,
            batch_size=self.batch_size,
            enable_auto_vectorization=False,  # æˆ‘ä»¬æä¾›è‡ªå·±çš„å‘é‡
            description="é»˜è®¤æ–‡æ¡£é›†åˆ"
        )
