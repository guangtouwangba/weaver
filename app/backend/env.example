# ============================================================================
# Research Agent RAG - Environment Configuration Example
# ============================================================================
# 
# Copy this file to .env in the project root and fill in your values:
#   cp app/backend/env.example .env
#
# ============================================================================

# ====================================
# General Settings
# ====================================

# Environment: development | production
ENVIRONMENT=development

# Log level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# ====================================
# Database Configuration
# ====================================

# PostgreSQL connection string
# Note: The asyncpg driver prefix is added automatically, just use postgresql://
DATABASE_URL=postgresql://research_rag:research_rag_dev@localhost:5432/research_rag

# Database Client Type
# "postgres" - Direct PostgreSQL connection (default for local development)
# "supabase" - Supabase SDK (for production/cloud)
DATABASE_CLIENT_TYPE=postgres

# ====================================
# Supabase Configuration (Production)
# ====================================
# Required when DATABASE_CLIENT_TYPE=supabase

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# JWT secret for verifying Supabase Auth tokens
SUPABASE_JWT_SECRET=your-jwt-secret

# Frontend Supabase keys (also used by backend for storage)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key

# Storage bucket name
STORAGE_BUCKET=documents

# ====================================
# Vector Store Configuration
# ====================================

# Provider: pgvector | qdrant
# - pgvector: Use PostgreSQL with pgvector extension (default)
# - qdrant: Use Qdrant vector database (recommended for scalability)
VECTOR_STORE_PROVIDER=pgvector

# Qdrant Configuration (only needed if VECTOR_STORE_PROVIDER=qdrant)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=document_chunks

# ====================================
# LLM Configuration
# ====================================

# LLM Model (via OpenRouter)
LLM_MODEL=google/gemini-2.5-flash

# OpenRouter API Key
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# ====================================
# Embedding Configuration
# ====================================

# Embedding Model
# OpenRouter: openai/text-embedding-3-small, google/gemini-embedding-001
# OpenAI: text-embedding-3-small, text-embedding-3-large
EMBEDDING_MODEL=openai/text-embedding-3-small

# ====================================
# OpenAI Configuration (Optional)
# ====================================
# Only needed if using OpenAI directly instead of OpenRouter

OPENAI_API_KEY=

# ====================================
# Google Gemini Configuration
# ====================================
# Required for Gemini OCR and audio transcription

GOOGLE_API_KEY=your-google-api-key

# ====================================
# OCR Configuration
# ====================================

# OCR Mode: auto | unstructured | gemini | docling
# - auto: Use unstructured, fallback to Gemini for scanned PDFs
# - unstructured: Lightweight parser (default, no PyTorch)
# - gemini: Google Gemini Vision OCR (best quality)
# - docling: Heavy parser with PyTorch (optional install)
OCR_MODE=auto

# Gemini OCR settings
GEMINI_OCR_CONCURRENCY=3

# ====================================
# RAG Configuration
# ====================================

# RAG Mode: traditional | long_context | auto
# - traditional: Chunk-based retrieval (default)
# - long_context: Full document context (NotebookLM style)
# - auto: Choose based on document size
RAG_MODE=traditional

# Retrieval settings
RETRIEVAL_TOP_K=5
RETRIEVAL_MIN_SIMILARITY=0.0

# Long context mode settings
LONG_CONTEXT_SAFETY_RATIO=0.55
LONG_CONTEXT_MIN_TOKENS=10000

# Citation settings
ENABLE_CITATION_GROUNDING=true
CITATION_FORMAT=both

# Intent classification
INTENT_CLASSIFICATION_ENABLED=true
INTENT_CACHE_ENABLED=true

# ====================================
# Redis Configuration (Task Queue)
# ====================================
# Required for async task processing (URL extraction, document processing)

# Local development:
REDIS_URL=redis://localhost:6379

# Production (Upstash):
# REDIS_URL=rediss://default:xxx@xxx.upstash.io:6379

# ====================================
# URL Extraction Configuration
# ====================================

URL_EXTRACTION_TIMEOUT=60
URL_CONTENT_MAX_LENGTH=50000

# SSRF protection (NEVER disable in production!)
DISABLE_SSRF_CHECK=false

# ====================================
# YouTube Configuration
# ====================================

# Rate limiting (recommended, free)
YOUTUBE_RATE_LIMIT_ENABLED=true
YOUTUBE_MIN_DELAY=2.0
YOUTUBE_MAX_DELAY=60.0

# Proxy (optional, for high-volume usage)
YOUTUBE_PROXY_URL=

# Gemini audio transcription max duration (minutes)
GEMINI_AUDIO_MAX_DURATION_MINUTES=60

# ====================================
# Observability - Langfuse
# ====================================
# LLM tracing and analytics
# See: https://langfuse.com/docs

LANGFUSE_ENABLED=false
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com

# ====================================
# Observability - Loki
# ====================================
# Centralized logging

LOKI_ENABLED=false
LOKI_URL=http://localhost:3100/loki/api/v1/push

# ====================================
# CORS Configuration
# ====================================

CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# ====================================
# Development Tips
# ====================================
# 1. Never commit .env to git
# 2. Use strong passwords for production
# 3. Rotate API keys regularly
# 4. Keep DISABLE_SSRF_CHECK=false in production
