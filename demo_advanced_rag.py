#!/usr/bin/env python3
"""
Advanced RAG System Demonstration

This script demonstrates the capabilities of the advanced RAG system
including document indexing, multi-resource chat, and evaluation.
"""

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Any

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def main():
    """Main demonstration workflow"""
    print("ğŸš€ Advanced RAG System Demonstration")
    print("=" * 60)
    
    try:
        # Import the advanced RAG system
        from modules.rag import TopicChatSystem, ChatRequest, ChatMode
        
        # Initialize the system
        print("\n1. ğŸ”§ Initializing Advanced RAG System...")
        config = {
            "vector_store_type": "chromadb",
            "vector_store_config": {
                "persist_directory": "./demo_data/chroma_db"
            },
            "embedding_cache_config": {
                "enabled": False  # Disable for demo simplicity
            },
            "generation_config": {
                "llm_provider": "openai",
                "model": "gpt-3.5-turbo",
                "max_tokens": 1000,
                "temperature": 0.1,
                # Note: In production, set via environment variables
                # "openai_api_key": "your-api-key-here"
            }
        }
        
        rag_system = TopicChatSystem(config)
        await rag_system.initialize()
        print("âœ… System initialized successfully!")
        
        # Perform health check
        print("\n2. â¤ï¸ System Health Check...")
        health = await rag_system.health_check()
        print(f"   Status: {health['status']}")
        print(f"   Components healthy: {health['health_ratio']:.1%}")
        
        # Create sample documents for demonstration
        print("\n3. ğŸ“š Creating Sample Documents...")
        sample_documents = create_sample_documents()
        
        # Index documents for topic
        topic_id = 1
        print(f"\n4. ğŸ“Š Indexing {len(sample_documents)} documents for topic {topic_id}...")
        
        index_result = await rag_system.index_topic_documents(
            topic_id=topic_id,
            documents=sample_documents
        )
        
        if index_result["success"]:
            print("âœ… Documents indexed successfully!")
            print(f"   Documents processed: {index_result['documents_processed']}")
            print(f"   Chunks created: {index_result['chunks_created']}")
        else:
            print(f"âŒ Indexing failed: {index_result.get('error')}")
            return
        
        # Get topic statistics
        print(f"\n5. ğŸ“Š Topic {topic_id} Statistics...")
        stats = await rag_system.get_topic_statistics(topic_id)
        if stats:
            print(f"   Documents: {stats['document_count']}")
            print(f"   Chunks: {stats['total_chunks']}")
            print(f"   Languages: {list(stats['languages'].keys())}")
            print(f"   Content types: {list(stats['content_types'].keys())}")
        
        # Demonstrate chat functionality
        print(f"\n6. ğŸ’¬ Demonstrating Multi-Resource Chat...")
        await demonstrate_chat_scenarios(rag_system, topic_id)
        
        # Show system metrics
        print(f"\n7. ğŸ“ˆ System Performance Metrics...")
        metrics = await rag_system.get_system_metrics()
        print(f"   Total queries: {metrics['total_queries']}")
        print(f"   Successful responses: {metrics['successful_responses']}")
        print(f"   Average response time: {metrics['average_response_time']:.2f}s")
        print(f"   Active conversations: {metrics['active_conversations']}")
        
        # Demonstrate evaluation
        print(f"\n8. ğŸ§ª Running System Evaluation...")
        await demonstrate_evaluation(rag_system)
        
        print(f"\nâœ¨ Demonstration completed successfully!")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure all required packages are installed.")
        print("Run: pip install -r requirements.txt")
    except Exception as e:
        logger.error(f"Demonstration failed: {e}")
        print(f"âŒ Error: {e}")
    finally:
        # Cleanup
        try:
            if 'rag_system' in locals():
                await rag_system.shutdown()
                print("\nğŸ§¹ System shutdown completed.")
        except:
            pass

def create_sample_documents() -> List[Dict[str, Any]]:
    """Create sample documents for demonstration"""
    documents = [
        {
            "id": "doc_ai_intro",
            "title": "äººå·¥æ™ºèƒ½æ¦‚è¿°",
            "content": """
            äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œ
            æ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨å’Œç³»ç»Ÿã€‚

            äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ï¼Œå½“æ—¶ç§‘å­¦å®¶ä»¬å¼€å§‹æ¢ç´¢å¦‚ä½•è®©æœºå™¨
            æ¨¡æ‹Ÿäººç±»çš„æ€ç»´è¿‡ç¨‹ã€‚ç»è¿‡å‡ åå¹´çš„å‘å±•ï¼ŒAIå·²ç»ä»ç†è®ºç ”ç©¶å‘å±•æˆä¸ºå®é™…åº”ç”¨çš„
            é‡è¦æŠ€æœ¯ã€‚

            ç°ä»£äººå·¥æ™ºèƒ½ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé‡è¦é¢†åŸŸï¼š
            1. æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰
            2. æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰
            3. è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼‰
            4. è®¡ç®—æœºè§†è§‰ï¼ˆComputer Visionï¼‰
            5. ä¸“å®¶ç³»ç»Ÿï¼ˆExpert Systemsï¼‰

            äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸéå¸¸å¹¿æ³›ï¼ŒåŒ…æ‹¬åŒ»ç–—è¯Šæ–­ã€é‡‘èåˆ†æã€è‡ªåŠ¨é©¾é©¶ã€
            æ™ºèƒ½åŠ©æ‰‹ç­‰å¤šä¸ªè¡Œä¸šå’Œåœºæ™¯ã€‚
            """,
            "metadata": {
                "author": "AIä¸“å®¶",
                "category": "æ¦‚è¿°",
                "created_at": "2024-01-01",
                "tags": ["äººå·¥æ™ºèƒ½", "æ¦‚è¿°", "åŸºç¡€çŸ¥è¯†"]
            }
        },
        {
            "id": "doc_machine_learning",
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "content": """
            æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦å­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­
            è‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€è¿›è¡Œæ˜ç¡®çš„ç¼–ç¨‹ã€‚

            æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ç®—æ³•åˆ†æå¤§é‡æ•°æ®ï¼Œè¯†åˆ«å…¶ä¸­çš„æ¨¡å¼ï¼Œ
            å¹¶åˆ©ç”¨è¿™äº›æ¨¡å¼å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–å†³ç­–ã€‚

            ä¸»è¦çš„æœºå™¨å­¦ä¹ ç±»å‹åŒ…æ‹¬ï¼š

            1. ç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰
               - ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»
               - åŒ…æ‹¬åˆ†ç±»å’Œå›å½’ä»»åŠ¡
               - å¸¸è§ç®—æ³•ï¼šçº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—

            2. æ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervised Learningï¼‰
               - åœ¨æ²¡æœ‰æ ‡è®°æ•°æ®çš„æƒ…å†µä¸‹å‘ç°æ•°æ®ä¸­çš„éšè—æ¨¡å¼
               - åŒ…æ‹¬èšç±»ã€é™ç»´ã€å…³è”è§„åˆ™æŒ–æ˜
               - å¸¸è§ç®—æ³•ï¼šK-meansã€å±‚æ¬¡èšç±»ã€PCA

            3. å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰
               - é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥
               - é€‚ç”¨äºæ¸¸æˆã€æœºå™¨äººæ§åˆ¶ç­‰åœºæ™¯
               - è‘—ååº”ç”¨ï¼šAlphaGoã€è‡ªåŠ¨é©¾é©¶

            æœºå™¨å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€æ¨èç³»ç»Ÿã€æ¬ºè¯ˆæ£€æµ‹ç­‰é¢†åŸŸ
            éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
            """,
            "metadata": {
                "author": "MLç ”ç©¶å‘˜",
                "category": "æŠ€æœ¯è¯¦è§£",
                "created_at": "2024-01-15",
                "tags": ["æœºå™¨å­¦ä¹ ", "ç®—æ³•", "ç›‘ç£å­¦ä¹ ", "æ— ç›‘ç£å­¦ä¹ "]
            }
        },
        {
            "id": "doc_deep_learning",
            "title": "æ·±åº¦å­¦ä¹ è¯¦è§£",
            "content": """
            æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªä¸“é—¨å­é¢†åŸŸï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼Œ
            ç‰¹åˆ«æ˜¯æ·±å±‚ç¥ç»ç½‘ç»œæ¥è¿›è¡Œå­¦ä¹ å’Œè¡¨ç¤ºã€‚

            æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒç‰¹å¾ï¼š
            1. å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„
            2. è‡ªåŠ¨ç‰¹å¾æå–èƒ½åŠ›
            3. ç«¯åˆ°ç«¯å­¦ä¹ æ–¹å¼
            4. å¤§æ•°æ®é©±åŠ¨

            ä¸»è¦çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼š

            1. å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
               - ä¸»è¦ç”¨äºå›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰
               - åŒ…å«å·ç§¯å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚
               - è‘—åæ¨¡å‹ï¼šLeNetã€AlexNetã€VGGã€ResNet

            2. å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰
               - é€‚åˆå¤„ç†åºåˆ—æ•°æ®
               - åŒ…æ‹¬LSTMã€GRUç­‰å˜ä½“
               - åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€æ—¶é—´åºåˆ—é¢„æµ‹

            3. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰
               - ç”±ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç»„æˆ
               - èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€æ–‡æœ¬ç­‰å†…å®¹
               - åº”ç”¨äºå›¾åƒç”Ÿæˆã€æ•°æ®å¢å¼º

            4. å˜æ¢å™¨ï¼ˆTransformerï¼‰
               - åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¶æ„
               - åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸè¡¨ç°å‡ºè‰²
               - ä»£è¡¨æ¨¡å‹ï¼šBERTã€GPTã€T5

            æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼š
            - æ·±åº¦å­¦ä¹ èƒ½è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤º
            - éœ€è¦æ›´å¤šçš„æ•°æ®å’Œè®¡ç®—èµ„æº
            - åœ¨æŸäº›å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½

            æ·±åº¦å­¦ä¹ å·²æˆä¸ºå½“å‰AIå‘å±•çš„é‡è¦æ¨åŠ¨åŠ›ï¼Œåœ¨è¯­éŸ³è¯†åˆ«ã€
            è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
            """,
            "metadata": {
                "author": "DLä¸“å®¶",
                "category": "æ·±å…¥ç ”ç©¶",
                "created_at": "2024-02-01",
                "tags": ["æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "CNN", "RNN", "Transformer"]
            }
        },
        {
            "id": "doc_nlp",
            "title": "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯",
            "content": """
            è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼Œç®€ç§°NLPï¼‰æ˜¯äººå·¥æ™ºèƒ½
            çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºç†è§£ã€å¤„ç†å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚

            NLPçš„ä¸»è¦ä»»åŠ¡åŒ…æ‹¬ï¼š

            1. æ–‡æœ¬é¢„å¤„ç†
               - åˆ†è¯ï¼ˆTokenizationï¼‰
               - è¯æ€§æ ‡æ³¨ï¼ˆPOS Taggingï¼‰
               - å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰
               - å¥æ³•åˆ†æï¼ˆParsingï¼‰

            2. è¯­ä¹‰ç†è§£
               - è¯ä¹‰æ¶ˆæ­§
               - è¯­ä¹‰è§’è‰²æ ‡æ³¨
               - æƒ…æ„Ÿåˆ†æ
               - æ„å›¾è¯†åˆ«

            3. æ–‡æœ¬ç”Ÿæˆ
               - æœºå™¨ç¿»è¯‘
               - æ–‡æœ¬æ‘˜è¦
               - å¯¹è¯ç”Ÿæˆ
               - å†…å®¹åˆ›ä½œ

            4. ä¿¡æ¯æå–
               - å…³é”®è¯æå–
               - å…³ç³»æŠ½å–
               - äº‹ä»¶æŠ½å–
               - çŸ¥è¯†å›¾è°±æ„å»º

            ç°ä»£NLPæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿ï¼š

            1. ä»ç»Ÿè®¡æ–¹æ³•åˆ°ç¥ç»ç½‘ç»œæ–¹æ³•
            2. ä»æµ…å±‚æ¨¡å‹åˆ°æ·±åº¦æ¨¡å‹
            3. ä»ä»»åŠ¡ç‰¹å®šåˆ°é€šç”¨é¢„è®­ç»ƒæ¨¡å‹
            4. ä»å°æ•°æ®åˆ°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹

            é‡è¦çš„NLPæ¨¡å‹å’ŒæŠ€æœ¯ï¼š
            - Word2Vecã€GloVeç­‰è¯åµŒå…¥æŠ€æœ¯
            - BERTã€GPTç­‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
            - Attentionæœºåˆ¶å’ŒTransformeræ¶æ„
            - å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹

            NLPçš„åº”ç”¨åœºæ™¯ï¼š
            - æœç´¢å¼•æ“
            - æ™ºèƒ½å®¢æœ
            - æœºå™¨ç¿»è¯‘
            - å†…å®¹æ¨è
            - æ–‡æ¡£åˆ†æ
            - è¯­éŸ³åŠ©æ‰‹

            éšç€å¤§è¯­è¨€æ¨¡å‹çš„å‘å±•ï¼ŒNLPæ­£åœ¨è¿æ¥æ–°çš„å˜é©ï¼Œ
            ChatGPTç­‰æ¨¡å‹å±•ç¤ºäº†å¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚
            """,
            "metadata": {
                "author": "NLPä¸“å®¶",
                "category": "æŠ€æœ¯åº”ç”¨",
                "created_at": "2024-02-15",
                "tags": ["è‡ªç„¶è¯­è¨€å¤„ç†", "NLP", "BERT", "GPT", "æ–‡æœ¬å¤„ç†"]
            }
        }
    ]
    
    print(f"   Created {len(documents)} sample documents")
    for doc in documents:
        print(f"   - {doc['title']} ({len(doc['content'])} chars)")
    
    return documents

async def demonstrate_chat_scenarios(rag_system, topic_id: int):
    """Demonstrate different chat scenarios"""
    scenarios = [
        {
            "name": "åŸºç¡€é—®ç­”",
            "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "description": "æµ‹è¯•åŸºç¡€çš„å®šä¹‰æ€§é—®ç­”"
        },
        {
            "name": "æ¯”è¾ƒåˆ†æ", 
            "query": "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "description": "æµ‹è¯•è·¨æ–‡æ¡£çš„æ¯”è¾ƒåˆ†æèƒ½åŠ›"
        },
        {
            "name": "æŠ€æœ¯ç»†èŠ‚",
            "query": "æ·±åº¦å­¦ä¹ ä¸­çš„CNNå’ŒRNNåˆ†åˆ«ç”¨äºä»€ä¹ˆåœºæ™¯ï¼Ÿ",
            "description": "æµ‹è¯•æŠ€æœ¯ç»†èŠ‚çš„æå–å’Œè§£é‡Š"
        },
        {
            "name": "åº”ç”¨åœºæ™¯",
            "query": "NLPæŠ€æœ¯æœ‰å“ªäº›å®é™…åº”ç”¨ï¼Ÿ",
            "description": "æµ‹è¯•åº”ç”¨åœºæ™¯çš„æ•´ç†å’Œå½’çº³"
        },
        {
            "name": "ç»¼åˆé—®é¢˜",
            "query": "å¦‚ä½•é€‰æ‹©åˆé€‚çš„AIæŠ€æœ¯æ¥è§£å†³æ–‡æœ¬åˆ†æé—®é¢˜ï¼Ÿ",
            "description": "æµ‹è¯•ç»¼åˆæ€§é—®é¢˜çš„å›ç­”èƒ½åŠ›"
        }
    ]
    
    conversation_id = f"demo_conversation_{int(time.time())}"
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n   åœºæ™¯ {i}: {scenario['name']}")
        print(f"   æè¿°: {scenario['description']}")
        print(f"   é—®é¢˜: {scenario['query']}")
        
        # Create chat request
        request = ChatRequest(
            query=scenario['query'],
            topic_id=topic_id,
            conversation_id=conversation_id,
            mode=ChatMode.CONVERSATION,
            max_sources=3
        )
        
        # Measure response time
        start_time = time.time()
        
        try:
            response = await rag_system.chat(request)
            response_time = time.time() - start_time
            
            print(f"   â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}s")
            print(f"   ğŸ¯ ç½®ä¿¡åº¦: {response.confidence:.2f}")
            print(f"   ğŸ“š ä½¿ç”¨æ¥æº: {len(response.sources)}")
            print(f"   ğŸ’¬ å›ç­”: {response.answer[:200]}...")
            
            if response.follow_up_questions:
                print(f"   ğŸ” åç»­é—®é¢˜å»ºè®®:")
                for q in response.follow_up_questions[:2]:
                    print(f"      - {q}")
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
        
        print("-" * 50)

async def demonstrate_evaluation(rag_system):
    """Demonstrate system evaluation"""
    try:
        print("   è¿è¡Œç³»ç»Ÿè¯„ä¼°...")
        
        # This would run actual evaluation in a real system
        # For demo, we'll show what the evaluation would look like
        evaluation_result = await rag_system.evaluate_system_performance()
        
        if evaluation_result["evaluation_completed"]:
            print("   âœ… è¯„ä¼°å®Œæˆ!")
            if "overall_score" in evaluation_result:
                print(f"   ğŸ“Š æ€»ä½“å¾—åˆ†: {evaluation_result['overall_score']:.2f}")
            
            if "metric_scores" in evaluation_result:
                print("   ğŸ“ˆ åˆ†é¡¹å¾—åˆ†:")
                for metric, score in evaluation_result["metric_scores"].items():
                    print(f"      {metric}: {score:.2f}")
            
            if "recommendations" in evaluation_result:
                print("   ğŸ’¡ æ”¹è¿›å»ºè®®:")
                for rec in evaluation_result["recommendations"][:3]:
                    print(f"      - {rec}")
        else:
            error = evaluation_result.get("error", "Unknown error")
            print(f"   âš ï¸ è¯„ä¼°æ¨¡æ‹Ÿ: {error}")
            print("   ğŸ“ è¯´æ˜: å®Œæ•´è¯„ä¼°éœ€è¦æµ‹è¯•æ•°æ®é›†å’ŒLLM APIè®¿é—®")
            
    except Exception as e:
        print(f"   âš ï¸ è¯„ä¼°æ¼”ç¤ºå¤±è´¥: {e}")
        print("   ğŸ“ è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ¼”ç¤ºç¯å¢ƒå¯èƒ½ç¼ºå°‘å®Œæ•´çš„è¯„ä¼°ä¾èµ–")

if __name__ == "__main__":
    print("ğŸ¯ Advanced RAG System Demo")
    print("ğŸ“ This demo showcases the multi-resource topic chat capabilities")
    print("ğŸ’¡ Note: Some features require API keys and external services")
    print()
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Demo interrupted by user")
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        logger.exception("Demo error")