# å¿«é€Ÿå¼€å§‹ - ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æŒ‡å—ï¼Œå¸®ä½ å¿«é€Ÿè®¾ç½®å’Œä½¿ç”¨åŸºäºæ•°æ®åº“çš„ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿã€‚

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿè®¾ç½®

### æ–¹å¼1: ä½¿ç”¨ SQLite (æœ¬åœ°å¼€å‘)

```bash
# 1. åˆå§‹åŒ–æ•°æ®åº“è¡¨
python scripts/init_job_tables.py

# 2. åˆ›å»ºç¬¬ä¸€ä¸ªä»»åŠ¡
python manage_jobs.py create "Daily Fetch" paper_fetch "0 9 * * *"

# 3. å¯åŠ¨è°ƒåº¦å™¨
python job_scheduler_main.py start

# 4. æŸ¥çœ‹ä»»åŠ¡
python manage_jobs.py list
```

### æ–¹å¼2: ä½¿ç”¨ Supabase (äº‘ç«¯)

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
echo "SUPABASE_URL=https://your-project.supabase.co" >> .env
echo "SUPABASE_ANON_KEY=your_anon_key_here" >> .env

# 2. åœ¨ Supabase SQL ç¼–è¾‘å™¨ä¸­è¿è¡Œä»¥ä¸‹ SQL:
```

```sql
-- å¤åˆ¶è¿™ä¸ª SQL åˆ° Supabase SQL ç¼–è¾‘å™¨
CREATE TABLE IF NOT EXISTS jobs (
    job_id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    name TEXT NOT NULL,
    job_type TEXT NOT NULL CHECK (job_type IN ('paper_fetch', 'maintenance', 'custom')),
    schedule_expression TEXT NOT NULL,
    config JSONB NOT NULL DEFAULT '{}'::jsonb,
    status TEXT NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'paused', 'deleted')),
    description TEXT DEFAULT '',
    timeout_seconds INTEGER DEFAULT 3600,
    retry_count INTEGER DEFAULT 3,
    retry_delay_seconds INTEGER DEFAULT 300,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_execution TIMESTAMP WITH TIME ZONE NULL,
    next_execution TIMESTAMP WITH TIME ZONE NULL
);

CREATE TABLE IF NOT EXISTS job_executions (
    execution_id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    job_id TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'running', 'success', 'failed', 'cancelled', 'timeout')),
    started_at TIMESTAMP WITH TIME ZONE NULL,
    finished_at TIMESTAMP WITH TIME ZONE NULL,
    duration_seconds REAL NULL,
    result JSONB NULL DEFAULT '{}'::jsonb,
    error_message TEXT NULL,
    retry_attempt INTEGER DEFAULT 0,
    logs TEXT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    FOREIGN KEY (job_id) REFERENCES jobs (job_id) ON DELETE CASCADE
);

ALTER TABLE jobs ENABLE ROW LEVEL SECURITY;
ALTER TABLE job_executions ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Allow anonymous access on jobs" ON jobs FOR ALL TO anon, authenticated USING (true) WITH CHECK (true);
CREATE POLICY "Allow anonymous access on job_executions" ON job_executions FOR ALL TO anon, authenticated USING (true) WITH CHECK (true);
```

```bash
# 3. æ›´æ–°é…ç½®ä½¿ç”¨ Supabase
# ç¼–è¾‘ config.yamlï¼Œå°† database.provider æ”¹ä¸º "supabase"

# 4. æµ‹è¯•è¿æ¥
python scripts/test_supabase_jobs.py

# 5. åˆ›å»ºä»»åŠ¡å’Œå¯åŠ¨
python manage_jobs.py create "Daily Fetch" paper_fetch "0 9 * * *"
python job_scheduler_main.py start
```

## ğŸ“‹ åŸºæœ¬å‘½ä»¤

### ä»»åŠ¡ç®¡ç†
```bash
# åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
python manage_jobs.py list

# æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
python manage_jobs.py show <job_id>

# åˆ›å»ºä»»åŠ¡
python manage_jobs.py create <name> <type> <schedule>

# ç«‹å³æ‰§è¡Œä»»åŠ¡
python manage_jobs.py trigger <job_id>

# æš‚åœ/æ¢å¤ä»»åŠ¡
python manage_jobs.py pause <job_id>
python manage_jobs.py resume <job_id>

# åˆ é™¤ä»»åŠ¡
python manage_jobs.py delete <job_id>
```

### è°ƒåº¦å™¨æ§åˆ¶
```bash
# å¯åŠ¨è°ƒåº¦å™¨ (å®ˆæŠ¤è¿›ç¨‹)
python job_scheduler_main.py start --daemon

# å¯åŠ¨è°ƒåº¦å™¨ (äº¤äº’æ¨¡å¼)
python job_scheduler_main.py start

# æŸ¥çœ‹çŠ¶æ€
python job_scheduler_main.py status

# åˆ—å‡ºä»»åŠ¡
python job_scheduler_main.py list
```

## â° å¸¸ç”¨è°ƒåº¦è¡¨è¾¾å¼

```bash
"0 9 * * *"        # æ¯å¤©ä¸Šåˆ9ç‚¹
"0 */2 * * *"      # æ¯2å°æ—¶
"*/30 * * * *"     # æ¯30åˆ†é’Ÿ
"0 9 * * 1-5"      # å·¥ä½œæ—¥ä¸Šåˆ9ç‚¹
"0 2 * * 0"        # æ¯å‘¨æ—¥å‡Œæ™¨2ç‚¹
"0 0 1 * *"        # æ¯æœˆ1å·
```

## ğŸ¯ ä»»åŠ¡ç±»å‹

1. **paper_fetch**: è®ºæ–‡è·å–ä»»åŠ¡
   - è‡ªåŠ¨ä½¿ç”¨ `config.yaml` ä¸­çš„æœç´¢é…ç½®
   - ä¸‹è½½æ–°è®ºæ–‡å¹¶å­˜å‚¨åˆ°æ•°æ®åº“

2. **maintenance**: ç»´æŠ¤ä»»åŠ¡
   - æ¸…ç†æ—§çš„æ‰§è¡Œè®°å½•
   - æ•°æ®åº“ä¼˜åŒ–

3. **custom**: è‡ªå®šä¹‰ä»»åŠ¡
   - å¯ä»¥æ³¨å†Œè‡ªå®šä¹‰å¤„ç†å™¨

## ğŸ”§ æ•…éšœæ’é™¤

### SQLite é—®é¢˜
```bash
# å¦‚æœè¡¨ä¸å­˜åœ¨
python scripts/init_job_tables.py

# å¦‚æœæ•°æ®åº“æŸåï¼Œåˆ é™¤é‡å»º
rm papers.db
python scripts/init_job_tables.py
```

### Supabase é—®é¢˜
```bash
# æµ‹è¯•è¿æ¥
python scripts/test_supabase_jobs.py

# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $SUPABASE_URL
echo $SUPABASE_ANON_KEY
```

## ğŸ“Š ç›‘æ§

```bash
# å®æ—¶ç›‘æ§
python manage_jobs.py  # è¿›å…¥äº¤äº’æ¨¡å¼

# æŸ¥çœ‹ç»Ÿè®¡
> status

# æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨
> list

# æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
> show <job_id>
```

## ğŸ³ Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t arxiv-job-scheduler .

# ä½¿ç”¨ SQLite
docker run --rm -v $(pwd)/config.yaml:/app/config.yaml arxiv-job-scheduler

# ä½¿ç”¨ Supabase
docker run --rm \
  -e SUPABASE_URL=$SUPABASE_URL \
  -e SUPABASE_ANON_KEY=$SUPABASE_ANON_KEY \
  -v $(pwd)/config.yaml:/app/config.yaml \
  arxiv-job-scheduler
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

æœ‰é—®é¢˜å¯ä»¥æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£ï¼š`JOB_SCHEDULING.md` å’Œ `SUPABASE_SETUP.md`