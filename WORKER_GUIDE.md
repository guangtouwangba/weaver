# Worker ä½¿ç”¨æŒ‡å— - æ¶æ„ä¼˜åŒ–ç‰ˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»äº†æ¶æ„ä¼˜åŒ–åçš„ Celery Worker ç³»ç»Ÿï¼Œæ”¯æŒä»»åŠ¡åˆ†ç¦»å’Œä¸“ç”¨ Worker é…ç½®ã€‚

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

### é˜Ÿåˆ—è®¾è®¡

| é˜Ÿåˆ—åç§° | ç”¨é€” | ä»»åŠ¡ç±»å‹ | æ¨èå¹¶å‘æ•° |
|---------|------|----------|------------|
| `document_queue` | æ–‡æ¡£åˆ›å»ºå’Œç®¡ç† | `document.create`, `document.update_metadata` | 4 |
| `rag_queue` | RAGå¤„ç† | `rag.process_document_async`, `rag.*` | 2 |
| `file_queue` | æ–‡ä»¶å¤„ç† | `file.*`, ä¸Šä¼ å®Œæˆå¤„ç† | 3 |
| `workflow_queue` | å·¥ä½œæµåè°ƒ | å·¥ä½œæµç®¡ç†ä»»åŠ¡ | 2 |
| `default` | é€šç”¨ä»»åŠ¡ | å…¶ä»–ä»»åŠ¡ | 2 |
| `notification_queue` | é€šçŸ¥ä»»åŠ¡ | é€šçŸ¥ç›¸å…³ | 1 |

### ä»»åŠ¡åˆ†ç¦»

```
æ–‡ä»¶ä¸Šä¼  â†’ æ–‡ä»¶å¤„ç† â†’ æ–‡æ¡£åˆ›å»º â†’ RAGå¤„ç† â†’ çŠ¶æ€æ›´æ–°
    â†“           â†“          â†“          â†“          â†“
file_queue  file_queue  document_queue  rag_queue  document_queue
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬å¯åŠ¨

```bash
# å¯åŠ¨é€šç”¨ Workerï¼ˆç›‘å¬æ‰€æœ‰é˜Ÿåˆ—ï¼‰
python worker.py

# ä½¿ç”¨å¯åŠ¨è„šæœ¬
./start_workers.sh --all
```

### 2. ä¸“ç”¨ Worker

```bash
# å¯åŠ¨ä¸“ç”¨æ–‡æ¡£å¤„ç† Worker
python worker.py --specialized=document

# å¯åŠ¨ä¸“ç”¨ RAG å¤„ç† Worker  
python worker.py --specialized=rag

# å¯åŠ¨ä¸“ç”¨æ–‡ä»¶å¤„ç† Worker
python worker.py --specialized=file

# å¯åŠ¨ä¸“ç”¨å·¥ä½œæµåè°ƒ Worker
python worker.py --specialized=workflow
```

### 3. å¤š Worker éƒ¨ç½²ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

```bash
# ä¸€é”®å¯åŠ¨æ‰€æœ‰ä¸“ç”¨ Workers
./start_workers.sh --multi

# æˆ–æ‰‹åŠ¨å¯åŠ¨
python worker.py --specialized=document --concurrency=4 &
python worker.py --specialized=rag --concurrency=2 &
python worker.py --specialized=file --concurrency=3 &
python worker.py --specialized=workflow --concurrency=2 &
```

## ğŸ“ å‘½ä»¤è¡Œé€‰é¡¹

### worker.py é€‰é¡¹

```bash
python worker.py [é€‰é¡¹]

é€‰é¡¹:
  --loglevel LEVEL        æ—¥å¿—çº§åˆ« (debug/info/warning/error)
  --concurrency N         å¹¶å‘æ•°
  --queues QUEUES         è‡ªå®šä¹‰é˜Ÿåˆ—ï¼Œé€—å·åˆ†éš”
  --specialized TYPE      ä¸“ç”¨Workerç±»å‹ (document/rag/file/workflow)
  --max-tasks-per-child N æ¯ä¸ªè¿›ç¨‹æœ€å¤§ä»»åŠ¡æ•°
  --pool TYPE             Workeræ± ç±»å‹ (prefork/eventlet/gevent/solo)
```

### å¯åŠ¨è„šæœ¬é€‰é¡¹

```bash
./start_workers.sh [é€‰é¡¹]

é€‰é¡¹:
  -h, --help              æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
  -c, --check             æ£€æŸ¥ç¯å¢ƒé…ç½®
  -a, --all              å¯åŠ¨é€šç”¨Worker
  -d, --document         å¯åŠ¨ä¸“ç”¨æ–‡æ¡£å¤„ç†Worker
  -r, --rag              å¯åŠ¨ä¸“ç”¨RAGå¤„ç†Worker
  -f, --file             å¯åŠ¨ä¸“ç”¨æ–‡ä»¶å¤„ç†Worker
  -w, --workflow         å¯åŠ¨ä¸“ç”¨å·¥ä½œæµåè°ƒWorker
  -m, --multi            å¯åŠ¨å¤šä¸ªä¸“ç”¨Worker
  -s, --status           æ˜¾ç¤ºWorkerçŠ¶æ€
  -k, --kill             åœæ­¢æ‰€æœ‰Worker

é«˜çº§é€‰é¡¹:
  --concurrency N        è®¾ç½®å¹¶å‘æ•°
  --loglevel LEVEL       è®¾ç½®æ—¥å¿—çº§åˆ«
  --queues QUEUES        è‡ªå®šä¹‰é˜Ÿåˆ—
```

## ğŸ“Š ç›‘æ§

### å®æ—¶ç›‘æ§

```bash
# å¯åŠ¨å®æ—¶ç›‘æ§é¢æ¿
python monitor_workers.py

# è‡ªå®šä¹‰ç›‘æ§é—´éš”
python monitor_workers.py --interval=10

# å•æ¬¡çŠ¶æ€æ£€æŸ¥
python monitor_workers.py --once

# JSONæ ¼å¼è¾“å‡º
python monitor_workers.py --once --json
```

### ä½¿ç”¨å¯åŠ¨è„šæœ¬ç›‘æ§

```bash
# æŸ¥çœ‹WorkerçŠ¶æ€
./start_workers.sh --status

# åœæ­¢æ‰€æœ‰Worker
./start_workers.sh --kill
```

## ğŸ”§ é…ç½®ä¼˜åŒ–

### ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®

#### é«˜ååé‡åœºæ™¯

```bash
# æ–‡æ¡£å¤„ç†Workerï¼ˆé«˜å¹¶å‘ï¼‰
python worker.py --specialized=document --concurrency=8 --pool=prefork

# RAGå¤„ç†Workerï¼ˆä½å¹¶å‘ï¼Œé«˜èµ„æºï¼‰
python worker.py --specialized=rag --concurrency=2 --pool=prefork

# æ–‡ä»¶å¤„ç†Workerï¼ˆä¸­ç­‰å¹¶å‘ï¼‰
python worker.py --specialized=file --concurrency=4 --pool=prefork
```

#### ä½èµ„æºç¯å¢ƒ

```bash
# é€šç”¨Workerï¼ˆä½å¹¶å‘ï¼‰
python worker.py --concurrency=2 --pool=prefork
```

#### é«˜å¹¶å‘I/Oåœºæ™¯

```bash
# ä½¿ç”¨äº‹ä»¶é©±åŠ¨æ± 
python worker.py --pool=eventlet --concurrency=100
```

### é…ç½®æ–‡ä»¶è°ƒä¼˜

åœ¨ `config/settings.py` ä¸­è°ƒæ•´ Celery é…ç½®ï¼š

```python
# Celery é…ç½®
CELERY_WORKER_CONCURRENCY = 4
CELERY_WORKER_PREFETCH_MULTIPLIER = 1
CELERY_WORKER_MAX_TASKS_PER_CHILD = 1000
CELERY_TASK_TIME_LIMIT = 300
CELERY_TASK_SOFT_TIME_LIMIT = 240
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡

1. **é˜Ÿåˆ—é•¿åº¦** - ç›‘æ§å¾…å¤„ç†ä»»åŠ¡æ•°é‡
2. **Workerè´Ÿè½½** - CPUå’Œå†…å­˜ä½¿ç”¨ç‡
3. **ä»»åŠ¡æ‰§è¡Œæ—¶é—´** - å¹³å‡å¤„ç†æ—¶é—´
4. **é”™è¯¯ç‡** - ä»»åŠ¡å¤±è´¥æ¯”ä¾‹

### ç›‘æ§å‘½ä»¤

```bash
# æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€
python -c "
from celery import Celery
from config import get_config
config = get_config()
app = Celery(config.celery.app_name, broker=config.celery.broker_url)
inspect = app.control.inspect()
print('é˜Ÿåˆ—çŠ¶æ€:', inspect.active())
"

# æŸ¥çœ‹Workerç»Ÿè®¡
python monitor_workers.py --once --json | jq '.worker_stats'
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Worker å¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥ç¯å¢ƒ
./start_workers.sh --check

# æ£€æŸ¥æ—¥å¿—
tail -f logs/worker_*.log
```

#### 2. ä»»åŠ¡å †ç§¯

```bash
# æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
python monitor_workers.py --once

# å¢åŠ Workeræ•°é‡
python worker.py --specialized=rag --concurrency=4
```

#### 3. å†…å­˜æ³„æ¼

```bash
# è®¾ç½®æœ€å¤§ä»»åŠ¡æ•°
python worker.py --max-tasks-per-child=500
```

#### 4. è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥Redisè¿æ¥
python -c "
import redis
from config import get_config
config = get_config()
r = redis.from_url(config.celery.broker_url)
print(r.ping())
"
```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep -i error logs/worker_*.log

# ç›‘æ§ä»»åŠ¡æ‰§è¡Œæ—¶é—´
grep "execution time" logs/worker_*.log

# æŸ¥çœ‹ä»»åŠ¡è·¯ç”±
grep "routing" logs/worker_*.log
```

## ğŸ”„ éƒ¨ç½²ç­–ç•¥

### å•æœºéƒ¨ç½²

```bash
# å¯åŠ¨å¤šä¸ªä¸“ç”¨Worker
./start_workers.sh --multi
```

### å¤šæœºéƒ¨ç½²

```bash
# æœºå™¨1ï¼šæ–‡æ¡£å’Œæ–‡ä»¶å¤„ç†
python worker.py --specialized=document --concurrency=4
python worker.py --specialized=file --concurrency=3

# æœºå™¨2ï¼šRAGå¤„ç†ï¼ˆGPUæœºå™¨ï¼‰
python worker.py --specialized=rag --concurrency=2

# æœºå™¨3ï¼šå·¥ä½œæµåè°ƒ
python worker.py --specialized=workflow --concurrency=2
```

### å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "worker.py", "--specialized=document"]
```

```yaml
# docker-compose.yml
version: '3.8'
services:
  worker-document:
    build: .
    command: python worker.py --specialized=document --concurrency=4
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
    
  worker-rag:
    build: .
    command: python worker.py --specialized=rag --concurrency=2
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
```

## ğŸ“š æœ€ä½³å®è·µ

### 1. èµ„æºåˆ†é…

- **æ–‡æ¡£å¤„ç†**: CPUå¯†é›†ï¼Œé«˜å¹¶å‘
- **RAGå¤„ç†**: å†…å­˜/GPUå¯†é›†ï¼Œä½å¹¶å‘
- **æ–‡ä»¶å¤„ç†**: I/Oå¯†é›†ï¼Œä¸­ç­‰å¹¶å‘

### 2. é”™è¯¯å¤„ç†

- è®¾ç½®åˆé€‚çš„é‡è¯•æ¬¡æ•°
- ä½¿ç”¨æ­»ä¿¡é˜Ÿåˆ—å¤„ç†å¤±è´¥ä»»åŠ¡
- ç›‘æ§é”™è¯¯ç‡å’Œç±»å‹

### 3. æ‰©å±•ç­–ç•¥

- æ ¹æ®é˜Ÿåˆ—é•¿åº¦è‡ªåŠ¨æ‰©å±•Worker
- ä½¿ç”¨è´Ÿè½½å‡è¡¡åˆ†å‘ä»»åŠ¡
- å®ç°ä¼˜é›…çš„Workerå…³é—­

### 4. å®‰å…¨è€ƒè™‘

- é™åˆ¶ä»»åŠ¡æ‰§è¡Œæ—¶é—´
- éªŒè¯ä»»åŠ¡å‚æ•°
- éš”ç¦»ä¸åŒç±»å‹çš„Worker

## ğŸ†• æ–°åŠŸèƒ½

### å·¥ä½œæµæ”¯æŒ

```python
# å¯åŠ¨æ–‡æ¡£å¤„ç†å·¥ä½œæµ
curl -X POST http://localhost:8000/workflow/document-processing \
  -H 'Content-Type: application/json' \
  -d '{
    "file_id": "file123",
    "document_data": {...},
    "enable_rag": true
  }'
```

### ä»»åŠ¡åè°ƒ

- è‡ªåŠ¨ä»»åŠ¡ä¾èµ–ç®¡ç†
- å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ
- å¤±è´¥æ¢å¤æœºåˆ¶

### ç›‘æ§é›†æˆ

- å®æ—¶çŠ¶æ€ç›‘æ§
- æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- å‘Šè­¦æœºåˆ¶

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š

1. æ—¥å¿—æ–‡ä»¶ï¼š`logs/worker_*.log`
2. ç›‘æ§é¢æ¿ï¼š`python monitor_workers.py`
3. ç¯å¢ƒæ£€æŸ¥ï¼š`./start_workers.sh --check`

---

ğŸ‰ **æ¶æ„ä¼˜åŒ–å®Œæˆï¼äº«å—æ›´é«˜æ•ˆçš„ä»»åŠ¡å¤„ç†ä½“éªŒï¼**
