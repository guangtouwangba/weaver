# ArXiv Paper Fetcher Configuration
# This file defines the search keywords and settings for automated paper collection

# Database settings
database:
  # Database provider: "sqlite" for local, "supabase" for cloud
  provider: "supabase"  # Using Supabase for cloud database
  
  # SQLite configuration (local development)
  url: "sqlite:///papers.db"
  
  # Supabase configuration (cloud deployment)
  supabase_url: "${SUPABASE_URL}"        # Set in .env file
  supabase_key: "${SUPABASE_ANON_KEY}"   # Set in .env file
  
# ArXiv search configuration
search:
  max_papers_per_run: 1000  # Maximum papers to fetch in each run
  keywords:
    - "rag"
    - "RAG"
    - "agent"

  # Search filters (optional)
  categories:
    - "cs.AI"
    - "cs.LG"
    - "cs.CV"
    - "cs.CL"
    - "stat.ML"
    - "cs.IR"
  
  # Only search papers from the last N days (0 = all time)
  days_back: 7
  
  # Sort results by (options: Relevance, LastUpdatedDate, SubmittedDate)
  sort_by: "SubmittedDate"

# PDF storage settings
pdf_storage:
  # Storage backend: "local" or "oss"
  backend: "oss"  # Change to "oss" for Alibaba Cloud OSS storage
  
  # Local storage settings (used when backend = "local")
  local:
    base_directory: "./downloaded_papers"
    create_subdirectories: true  # Create subdirs by date (YYYY-MM-DD)
    filename_format: "{arxiv_id}.pdf"  # Available vars: {arxiv_id}, {title_safe}, {date}
  
  # Alibaba Cloud OSS settings (used when backend = "oss")
  oss:
    # OSS connection settings
    endpoint: "https://oss-cn-shanghai.aliyuncs.com"  # OSS endpoint URL
    access_key_id: "LTAI5tFzmAkMnTgUWtcuFUE2"  # Can use environment variable
    access_key_secret: "3kLDcKfSvFMbj86TCF2cGdWDq0A5JK"  # Can use environment variable
    bucket_name: "golearning"  # OSS bucket name
    
    # OSS storage settings
    base_prefix: "papers"  # Base directory in OSS bucket
    create_subdirectories: true  # Create subdirs by date (YYYY-MM-DD)
    filename_format: "{arxiv_id}.pdf"  # Available vars: {arxiv_id}, {title_safe}, {date}
    
    # OSS advanced settings
    multipart_threshold: 100  # MB - files larger than this use multipart upload
    max_concurrency: 3  # Maximum concurrent uploads
    
    # Security settings
    server_side_encryption: false  # Enable OSS server-side encryption
    storage_class: "Standard"  # Standard, IA, Archive, ColdArchive

# Scheduler settings
scheduler:
  # How often to run the search (in hours)
  interval_hours: 1
  
  # Whether to run immediately on startup
  run_on_startup: false
  
# Logging settings
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "paper_fetcher.log"
  max_file_size_mb: 10
  backup_count: 3

# Advanced settings
advanced:
  # Delay between requests to respect ArXiv rate limits (seconds)
  request_delay: 1.0
  
  # Maximum retries for failed downloads
  max_retries: 3
  
  # Timeout for PDF downloads (seconds)
  download_timeout: 300

# RAG问答配置
rag:
  # 向量数据库设置
  vector_db:
    type: "chroma"  # chroma, faiss
    persist_directory: "./rag_vector_db"
    collection_name: "arxiv_papers"
  
  # 文本处理设置
  text_processing:
    chunk_size: 1000
    chunk_overlap: 200
    max_chunks_per_doc: 50
  
  # 嵌入模型设置
  embeddings:
    provider: "openai"  # openai, sentence-transformers
    model: "text-embedding-3-small"  # OpenAI embedding model
    # model: "text-embedding-ada-002"  # Alternative OpenAI model
    device: "cpu"  # cpu, cuda (only for sentence-transformers)
  
  # LLM设置
  llm:
    provider: "openai"  # openai, anthropic, local
    model: "gpt-3.5-turbo"
    max_tokens: 2000
    temperature: 0.1
  
  # 检索设置
  retrieval:
    top_k: 5
    similarity_threshold: 0.7
    max_context_length: 4000
  
  # UI设置
  ui:
    max_keywords_display: 20
    results_per_page: 3
    show_similarity_scores: true