# Cloud Job Runner System

ç®€åŒ–çš„äº‘åŸç”Ÿä»»åŠ¡æ‰§è¡Œç³»ç»Ÿï¼Œä¸“ä¸ºæ— çŠ¶æ€ã€serverless ç¯å¢ƒè®¾è®¡ã€‚

## ğŸ¯ è®¾è®¡ç†å¿µ

**ä¼ ç»Ÿè°ƒåº¦å™¨çš„é—®é¢˜ï¼š**
- éœ€è¦é•¿æœŸè¿è¡Œçš„è¿›ç¨‹
- å¤æ‚çš„çº¿ç¨‹ç®¡ç†
- ä¸é€‚åˆäº‘å‡½æ•°å’Œå®¹å™¨åŒ–éƒ¨ç½²

**äº‘ç«¯Job Runnerçš„ä¼˜åŠ¿ï¼š**
- **æ— çŠ¶æ€**: æ¯æ¬¡è¿è¡Œç‹¬ç«‹ï¼Œæ‰§è¡Œå®Œå³é€€å‡º
- **è½»é‡çº§**: åªä¸“æ³¨æ‰§è¡Œjobï¼Œä¸åŒ…å«è°ƒåº¦é€»è¾‘  
- **äº‘åŸç”Ÿ**: é€‚åˆAWS Lambdaã€Kubernetes CronJobç­‰
- **æ°´å¹³æ‰©å±•**: å¤šå®ä¾‹å¹¶è¡Œè¿è¡Œï¼ŒåŸå­æ€§é˜²å†²çª

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
äº‘ç«¯è§¦å‘å™¨ â†’ Cloud Job Runner â†’ æ•°æ®åº“æŸ¥è¯¢ â†’ åŸå­é”å®šJob â†’ æ‰§è¡ŒJob â†’ æ›´æ–°ç»“æœ â†’ é€€å‡º
```

### æ ¸å¿ƒç»„ä»¶

1. **CloudJob æ•°æ®æ¨¡å‹**: ç®€åŒ–çš„jobå®šä¹‰ï¼Œæ”¯æŒé”å®šæœºåˆ¶
2. **CloudJobPicker**: åŸå­æ€§jobé€‰æ‹©å’Œé”å®šï¼Œé¿å…å¹¶å‘å†²çª
3. **SimpleJobExecutor**: è½»é‡åŒ–jobæ‰§è¡Œå™¨ï¼Œæ— çº¿ç¨‹ç®¡ç†
4. **cloud_job_runner.py**: ä¸»æ‰§è¡Œè„šæœ¬ï¼Œå•æ¬¡è¿è¡Œé€»è¾‘

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements-simple.txt

# è®¾ç½®ç¯å¢ƒå˜é‡ (.env æ–‡ä»¶)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_anon_key_here
```

### 2. åˆå§‹åŒ–æ•°æ®åº“

```bash
# åˆ›å»ºcloud jobè¡¨
python scripts/init_cloud_job_tables.py

# æµ‹è¯•ç³»ç»Ÿ
python scripts/test_cloud_job_system.py
```

### 3. åˆ›å»ºå’Œæ‰§è¡ŒJob

```bash
# åˆ›å»ºè®ºæ–‡è·å–ä»»åŠ¡
python cloud_job_manager.py create "Daily Papers" paper_fetch --job-config max_papers=50

# è¿è¡Œjobæ‰§è¡Œå™¨
python cloud_job_runner.py

# æŸ¥çœ‹ç»Ÿè®¡
python cloud_job_manager.py stats
```

## ğŸ“‹ Job ç®¡ç†

### åˆ›å»ºJob

```bash
# è®ºæ–‡è·å–job
python cloud_job_manager.py create "Daily Fetch" paper_fetch \\
  --description "æ¯æ—¥è®ºæ–‡è·å–" \\
  --job-config config_path=config.yaml max_papers=100

# ç»´æŠ¤job  
python cloud_job_manager.py create "Weekly Cleanup" maintenance \\
  --job-config cleanup_days=30 cleanup_executions=true

# è‡ªå®šä¹‰job
python cloud_job_manager.py create "Custom Task" custom \\
  --job-config task_type=data_processing input_file=data.json
```

### ç›‘æ§Job

```bash
# åˆ—å‡ºæ‰€æœ‰job
python cloud_job_manager.py list

# æŸ¥çœ‹ç‰¹å®šjobè¯¦æƒ…
python cloud_job_manager.py show <job_id>

# å®æ—¶ç»Ÿè®¡
python cloud_job_manager.py stats

# æŸ¥çœ‹ç­‰å¾…æ‰§è¡Œçš„job
python cloud_job_manager.py list --status waiting
```

## ğŸ”§ éƒ¨ç½²æ–¹å¼

### 1. AWS Lambda

```yaml
# serverless.yml
service: arxiv-job-runner

provider:
  name: aws
  runtime: python3.9
  environment:
    SUPABASE_URL: ${env:SUPABASE_URL}
    SUPABASE_ANON_KEY: ${env:SUPABASE_ANON_KEY}

functions:
  jobRunner:
    handler: lambda_handler.main
    timeout: 900  # 15åˆ†é’Ÿ
    events:
      - schedule: rate(5 minutes)  # æ¯5åˆ†é’Ÿè§¦å‘
```

```python
# lambda_handler.py
import subprocess
import sys

def main(event, context):
    result = subprocess.run([
        sys.executable, 'cloud_job_runner.py'
    ], capture_output=True, text=True)
    
    return {
        'statusCode': 200 if result.returncode == 0 else 500,
        'body': result.stdout
    }
```

### 2. Kubernetes CronJob

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: arxiv-job-runner
spec:
  schedule: "*/5 * * * *"  # æ¯5åˆ†é’Ÿ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: job-runner
            image: arxiv-job-runner:latest
            env:
            - name: SUPABASE_URL
              valueFrom:
                secretKeyRef:
                  name: supabase-credentials
                  key: url
            - name: SUPABASE_ANON_KEY
              valueFrom:
                secretKeyRef:
                  name: supabase-credentials
                  key: anon_key
            command: ["python", "cloud_job_runner.py"]
          restartPolicy: OnFailure
```

### 3. Google Cloud Functions

```python
# main.py
from cloud_job_runner import main as runner_main
import sys
from io import StringIO

def cloud_job_runner(request):
    # Capture stdout
    old_stdout = sys.stdout
    sys.stdout = captured_output = StringIO()
    
    try:
        runner_main()
        output = captured_output.getvalue()
        return {'status': 'success', 'output': output}
    except SystemExit as e:
        output = captured_output.getvalue()
        return {'status': 'error' if e.code != 0 else 'success', 'output': output}
    finally:
        sys.stdout = old_stdout
```

### 4. Docker å®¹å™¨

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . .
RUN pip install -r requirements-simple.txt

ENV PYTHONPATH=/app/backend
CMD ["python", "cloud_job_runner.py"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t arxiv-job-runner .
docker run --env-file .env arxiv-job-runner
```

## ğŸ”’ å¹¶å‘å®‰å…¨

### åŸå­æ€§Jobé”å®š

ç³»ç»Ÿä½¿ç”¨æ•°æ®åº“çº§åˆ«çš„åŸå­æ“ä½œç¡®ä¿å¤šå®ä¾‹å¹¶å‘å®‰å…¨ï¼š

**Supabase (PostgreSQL):**
```sql
-- åŸå­æ€§è·å–ä¸‹ä¸€ä¸ªjob
UPDATE cloud_jobs SET 
    status = 'locked',
    locked_at = NOW(),
    locked_by = 'instance-id',
    lock_expires_at = NOW() + INTERVAL '30 minutes'
WHERE job_id = (
    SELECT job_id FROM cloud_jobs
    WHERE status = 'waiting'
    ORDER BY created_at ASC
    LIMIT 1
    FOR UPDATE SKIP LOCKED
)
```

**SQLite:**
```sql
-- äº‹åŠ¡ä¸­çš„åŸå­æ€§æ“ä½œ
BEGIN IMMEDIATE;
UPDATE cloud_jobs SET status = 'locked' WHERE job_id = ?;
COMMIT;
```

### é”å®šè¶…æ—¶å¤„ç†

- é»˜è®¤é”å®š30åˆ†é’Ÿ
- è‡ªåŠ¨é‡Šæ”¾è¿‡æœŸé”å®š
- æ”¯æŒå¤±è´¥é‡è¯•æœºåˆ¶

## ğŸ“Š Job ç±»å‹

### 1. paper_fetch
è‡ªåŠ¨è·å–ArXivè®ºæ–‡

```json
{
  "config_path": "config.yaml",
  "max_papers": 100,
  "keywords": ["AI", "ML", "RAG"]
}
```

### 2. maintenance  
ç³»ç»Ÿç»´æŠ¤ä»»åŠ¡

```json
{
  "cleanup_days": 30,
  "cleanup_executions": true
}
```

### 3. custom
è‡ªå®šä¹‰ä»»åŠ¡

```python
# æ³¨å†Œè‡ªå®šä¹‰å¤„ç†å™¨
def my_custom_handler(job):
    # è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘
    return {"success": True, "processed": 100}

executor.register_handler('my_task', my_custom_handler)
```

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### æ—¥å¿—åˆ†æ

```bash
# è¯¦ç»†æ—¥å¿—
python cloud_job_runner.py --verbose

# æŸ¥çœ‹å¯ç”¨jobï¼ˆä¸æ‰§è¡Œï¼‰
python cloud_job_runner.py --dry-run
```

### æ‰§è¡Œç»Ÿè®¡

æ¯ä¸ªjobæ‰§è¡Œéƒ½ä¼šè®°å½•ï¼š
- å¼€å§‹/ç»“æŸæ—¶é—´
- æ‰§è¡Œæ—¶é•¿
- ç»“æœæ•°æ®
- é”™è¯¯ä¿¡æ¯
- æ‰§è¡Œå®ä¾‹ID

### æ•…éšœæ’é™¤

```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
python scripts/test_cloud_job_system.py

# æŸ¥çœ‹å¤±è´¥çš„job
python cloud_job_manager.py list --status failed

# æŸ¥çœ‹jobæ‰§è¡Œå†å²
python cloud_job_manager.py show <job_id>

# é‡Šæ”¾æ­»é”
python -c "
from jobs.job_picker import CloudJobPicker
from database.database_adapter import create_database_manager
picker = CloudJobPicker(create_database_manager({}))
picker._release_expired_locks()
"
```

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

```bash
# æ•°æ®åº“é…ç½®
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_anon_key_here

# å¯é€‰é…ç½®
JOB_LOCK_DURATION=30  # é”å®šæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
JOB_INSTANCE_ID=custom-id  # å®ä¾‹ID
```

### è¿è¡Œå‚æ•°

```bash
python cloud_job_runner.py \\
  --config custom_config.yaml \\
  --instance-id worker-01 \\
  --lock-duration 60 \\
  --verbose
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. åˆç†è®¾ç½®è§¦å‘é¢‘ç‡
- å¼€å‘ç¯å¢ƒ: 5-10åˆ†é’Ÿ
- ç”Ÿäº§ç¯å¢ƒ: æ ¹æ®jobæ•°é‡å’Œæ‰§è¡Œæ—¶é—´è°ƒæ•´
- é¿å…é¢‘ç¹è§¦å‘å¯¼è‡´èµ„æºæµªè´¹

### 2. ç›‘æ§jobæ‰§è¡Œ
- è®¾ç½®å‘Šè­¦ï¼šè¿ç»­å¤±è´¥è¶…è¿‡é˜ˆå€¼
- ç›‘æ§æ‰§è¡Œæ—¶é•¿ï¼šå‘ç°æ€§èƒ½é—®é¢˜
- è·Ÿè¸ªé”å®šè¶…æ—¶ï¼šé¿å…æ­»é”

### 3. åˆç†é…ç½®é‡è¯•
- ç½‘ç»œç›¸å…³ä»»åŠ¡ï¼šå¢åŠ é‡è¯•æ¬¡æ•°
- èµ„æºå¯†é›†å‹ä»»åŠ¡ï¼šå‡å°‘é‡è¯•ï¼Œå¿«é€Ÿå¤±è´¥
- è®¾ç½®åˆç†çš„é‡è¯•é—´éš”

### 4. æ•°æ®åº“ä¼˜åŒ–
- å®šæœŸæ¸…ç†æ‰§è¡Œè®°å½•
- ç›‘æ§æ•°æ®åº“è¿æ¥æ•°
- ä½¿ç”¨è¿æ¥æ± ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

## ğŸ“ˆ æ‰©å±•åŠŸèƒ½

### Jobä¼˜å…ˆçº§
é€šè¿‡ä¿®æ”¹jobé€‰æ‹©æŸ¥è¯¢æ·»åŠ ä¼˜å…ˆçº§ï¼š

```sql
ORDER BY 
    priority DESC,  -- é«˜ä¼˜å…ˆçº§ä¼˜å…ˆ
    CASE WHEN status = 'waiting' THEN 0 ELSE 1 END,
    created_at ASC
```

### Jobä¾èµ–
å®ç°jobé—´ä¾èµ–å…³ç³»ï¼š

```python
class CloudJob:
    def __init__(self, ..., depends_on: List[str] = None):
        self.depends_on = depends_on or []
```

### åˆ†å¸ƒå¼é”
ä½¿ç”¨Rediså®ç°æ›´é«˜æ€§èƒ½çš„åˆ†å¸ƒå¼é”ï¼š

```python
import redis
r = redis.Redis()

def acquire_job_lock(job_id, instance_id, ttl=1800):
    return r.set(f"job_lock:{job_id}", instance_id, nx=True, ex=ttl)
```

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository>
cd research-agent-rag

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
python scripts/test_cloud_job_system.py

# è¿è¡Œlinter
make lint
```

### æäº¤è§„èŒƒ

- feat: æ–°åŠŸèƒ½
- fix: ä¿®å¤
- docs: æ–‡æ¡£æ›´æ–°
- test: æµ‹è¯•ç›¸å…³
- refactor: é‡æ„

---

## ğŸ“„ è®¸å¯è¯

[MIT License](LICENSE)

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ArXiv API æ–‡æ¡£](https://arxiv.org/help/api)
- [Supabase æ–‡æ¡£](https://supabase.com/docs)
- [Docker éƒ¨ç½²æŒ‡å—](./DOCKER_DEPLOYMENT.md)
- [AWS Lambda éƒ¨ç½²æŒ‡å—](./AWS_LAMBDA_DEPLOYMENT.md)

---

**Cloud Job Runner** - è®©æ‚¨çš„ä»»åŠ¡æ‰§è¡Œæ›´ç®€å•ã€æ›´å¯é ï¼ ğŸš€