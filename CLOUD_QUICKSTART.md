# Cloud Job Runner - 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

æœ€ç®€å•çš„äº‘ç«¯ä»»åŠ¡æ‰§è¡Œç³»ç»Ÿä¸Šæ‰‹æŒ‡å—ã€‚

## ğŸš€ ä¸€é”®éƒ¨ç½²

```bash
# å…‹éš†é¡¹ç›®
git clone <your-repo>
cd research-agent-rag

# è‡ªåŠ¨éƒ¨ç½²
python scripts/deploy_cloud_jobs.py
```

## âš¡ æ‰‹åŠ¨å¿«é€Ÿè®¾ç½®

### 1. å®‰è£…ä¾èµ– (30ç§’)

```bash
pip install python-dotenv pyyaml supabase
```

### 2. é…ç½®æ•°æ®åº“ (2åˆ†é’Ÿ)

**é€‰é¡¹A: ä½¿ç”¨ Supabase (æ¨èäº‘ç«¯)**

```bash
# åˆ›å»º .env æ–‡ä»¶
echo "SUPABASE_URL=https://your-project.supabase.co" >> .env
echo "SUPABASE_ANON_KEY=your_anon_key_here" >> .env

# åœ¨ Supabase SQL ç¼–è¾‘å™¨ä¸­è¿è¡Œ:
# CREATE TABLE cloud_jobs (...) -- è§ä¸‹æ–¹SQL
```

**é€‰é¡¹B: ä½¿ç”¨ SQLite (æœ¬åœ°æµ‹è¯•)**

```bash
# è‡ªåŠ¨åˆ›å»ºè¡¨
python scripts/init_cloud_job_tables.py
```

### 3. åˆ›å»ºä»»åŠ¡ (30ç§’)

```bash
# åˆ›å»ºè®ºæ–‡è·å–ä»»åŠ¡
python cloud_job_manager.py create "Daily Papers" paper_fetch

# æŸ¥çœ‹ä»»åŠ¡
python cloud_job_manager.py list
```

### 4. æ‰§è¡Œä»»åŠ¡ (10ç§’)

```bash
# è¿è¡Œä¸€æ¬¡
python cloud_job_runner.py

# æŸ¥çœ‹ç»“æœ
python cloud_job_manager.py stats
```

## ğŸ—„ï¸ å¿…éœ€çš„SQL (Supabase)

åœ¨ Supabase SQL ç¼–è¾‘å™¨ä¸­è¿è¡Œï¼š

```sql
CREATE TABLE cloud_jobs (
    job_id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    name TEXT NOT NULL,
    job_type TEXT NOT NULL CHECK (job_type IN ('paper_fetch', 'maintenance', 'custom')),
    config JSONB DEFAULT '{}'::jsonb,
    status TEXT DEFAULT 'waiting' CHECK (status IN ('waiting', 'locked', 'success', 'failed', 'disabled')),
    description TEXT DEFAULT '',
    max_retries INTEGER DEFAULT 3,
    current_retries INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_execution TIMESTAMP WITH TIME ZONE NULL,
    locked_at TIMESTAMP WITH TIME ZONE NULL,
    locked_by TEXT NULL,
    lock_expires_at TIMESTAMP WITH TIME ZONE NULL
);

CREATE TABLE cloud_job_executions (
    execution_id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    job_id TEXT NOT NULL REFERENCES cloud_jobs(job_id),
    status TEXT DEFAULT 'running' CHECK (status IN ('running', 'success', 'failed')),
    started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    finished_at TIMESTAMP WITH TIME ZONE NULL,
    duration_seconds REAL NULL,
    result JSONB DEFAULT '{}'::jsonb,
    error_message TEXT NULL,
    instance_id TEXT NULL
);

ALTER TABLE cloud_jobs ENABLE ROW LEVEL SECURITY;
ALTER TABLE cloud_job_executions ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Allow all" ON cloud_jobs FOR ALL USING (true) WITH CHECK (true);
CREATE POLICY "Allow all" ON cloud_job_executions FOR ALL USING (true) WITH CHECK (true);
```

## ğŸ“± å¸¸ç”¨å‘½ä»¤

```bash
# ğŸ” æŸ¥çœ‹çŠ¶æ€
python cloud_job_manager.py stats

# ğŸ“‹ åˆ—å‡ºä»»åŠ¡
python cloud_job_manager.py list

# â• åˆ›å»ºä»»åŠ¡
python cloud_job_manager.py create "My Task" paper_fetch

# ğŸƒ æ‰§è¡Œä»»åŠ¡  
python cloud_job_runner.py

# ğŸ” æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
python cloud_job_manager.py show <job_id>

# ğŸ§ª æµ‹è¯•ç³»ç»Ÿ
python scripts/test_cloud_job_system.py
```

## ğŸ³ Docker ä¸€é”®è¿è¡Œ

```bash
# æ„å»ºé•œåƒ
docker build -t cloud-job-runner .

# ä½¿ç”¨ Supabase
docker run --env-file .env cloud-job-runner

# ä½¿ç”¨ç¯å¢ƒå˜é‡
docker run -e SUPABASE_URL=... -e SUPABASE_ANON_KEY=... cloud-job-runner
```

## âš™ï¸ ä»»åŠ¡ç±»å‹

### ğŸ“„ è®ºæ–‡è·å– (paper_fetch)
```bash
python cloud_job_manager.py create "Daily Fetch" paper_fetch \\
  --job-config max_papers=50 keywords="['AI','ML']"
```

### ğŸ§¹ ç³»ç»Ÿç»´æŠ¤ (maintenance)  
```bash
python cloud_job_manager.py create "Cleanup" maintenance \\
  --job-config cleanup_days=30
```

### ğŸ”§ è‡ªå®šä¹‰ä»»åŠ¡ (custom)
```bash
python cloud_job_manager.py create "My Task" custom \\
  --job-config task_type=backup target_dir=/data
```

## â˜ï¸ äº‘ç«¯éƒ¨ç½²

### AWS Lambda
```python
# lambda_handler.py
import subprocess
def lambda_handler(event, context):
    result = subprocess.run(['python', 'cloud_job_runner.py'])
    return {'statusCode': 200 if result.returncode == 0 else 500}
```

### Kubernetes CronJob
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: job-runner
spec:
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: runner
            image: cloud-job-runner:latest
            command: ["python", "cloud_job_runner.py"]
          restartPolicy: OnFailure
```

## ğŸš¨ æ•…éšœæ’é™¤

### æ²¡æœ‰ä»»åŠ¡å¯æ‰§è¡Œ
```bash
# æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
python cloud_job_manager.py list

# åˆ›å»ºæµ‹è¯•ä»»åŠ¡
python cloud_job_manager.py create "Test" custom
```

### æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æµ‹è¯•è¿æ¥
python scripts/test_cloud_job_system.py

# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $SUPABASE_URL
echo $SUPABASE_ANON_KEY
```

### ä»»åŠ¡æ‰§è¡Œå¤±è´¥
```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯  
python cloud_job_manager.py show <job_id>

# è¯¦ç»†æ—¥å¿—
python cloud_job_runner.py --verbose
```

## ğŸ“ˆ ç”Ÿäº§ä½¿ç”¨

### 1. è®¾ç½®å®šæ—¶æ‰§è¡Œ
```bash
# Linux Cron (æ¯5åˆ†é’Ÿ)
*/5 * * * * cd /path/to/project && python cloud_job_runner.py

# ç³»ç»ŸæœåŠ¡ (systemd timer)
# è§ CLOUD_JOB_RUNNER.md è¯¦ç»†é…ç½®
```

### 2. ç›‘æ§å’Œå‘Šè­¦
```bash
# å¥åº·æ£€æŸ¥è„šæœ¬
if python cloud_job_runner.py --dry-run; then
    echo "System healthy"
else
    echo "System error" | mail admin@company.com
fi
```

### 3. æ‰©å±•å®ä¾‹
```bash
# å¯åŠ¨å¤šä¸ªå®ä¾‹å¹¶è¡Œæ‰§è¡Œ
python cloud_job_runner.py --instance-id worker-1 &
python cloud_job_runner.py --instance-id worker-2 &
python cloud_job_runner.py --instance-id worker-3 &
```

## ğŸ”— æ›´å¤šèµ„æº

- ğŸ“š **å®Œæ•´æ–‡æ¡£**: [CLOUD_JOB_RUNNER.md](CLOUD_JOB_RUNNER.md)
- ğŸ³ **DockeræŒ‡å—**: è§æ–‡æ¡£éƒ¨ç½²éƒ¨åˆ†
- â˜ï¸ **äº‘å¹³å°éƒ¨ç½²**: è§å„äº‘æœåŠ¡å•†é…ç½®
- ğŸ†˜ **æŠ€æœ¯æ”¯æŒ**: æäº¤ Issue

---

**ğŸ‰ æ­å–œï¼æ‚¨çš„äº‘ç«¯ä»»åŠ¡ç³»ç»Ÿå·²ç»readyï¼**

å¼€å§‹åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ªå®šæ—¶ä»»åŠ¡å§ï¼š
```bash
python cloud_job_manager.py create "æˆ‘çš„ç¬¬ä¸€ä¸ªä»»åŠ¡" paper_fetch
python cloud_job_runner.py
```