# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=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

# Vector Database Configuration
VECTOR_DB_PATH=./data/vector_db
MAX_PAPERS_PER_QUERY=50
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Agent Configuration
DEFAULT_MODEL=gpt-4o-mini
RESEARCH_TOPICS_CACHE_TTL=3600

# Logging
LOG_LEVEL=INFO


# Research Agent RAG System Configuration
# Copy this file to .env and fill in your actual values

# ===== API KEYS =====
# At least one API key is required
OPENAI_API_KEY=your_openai_api_key_here
DEEPSEEK_API_KEY=sk-e522840d73e44f9d99e40cd3f9507944
ANTHROPIC_API_KEY=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

# ===== PROVIDER CONFIGURATION =====
# Default provider for all agents (openai, deepseek, anthropic)
DEFAULT_PROVIDER=deepseek

# ===== MODEL CONFIGURATION =====
# Default models for each provider
OPENAI_MODEL=gpt-4o-mini
DEEPSEEK_MODEL=deepseek-chat
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ===== INDIVIDUAL AGENT CONFIGURATION =====
# Option 1: Individual environment variables (simpler)
# Setting ALL agents to use DeepSeek
GOOGLE_ENGINEER_PROVIDER=deepseek
GOOGLE_ENGINEER_MODEL=deepseek-chat
MIT_RESEARCHER_PROVIDER=deepseek
MIT_RESEARCHER_MODEL=deepseek-chat
INDUSTRY_EXPERT_PROVIDER=deepseek
INDUSTRY_EXPERT_MODEL=deepseek-chat
PAPER_ANALYST_PROVIDER=deepseek
PAPER_ANALYST_MODEL=deepseek-chat

# Option 2: JSON configuration (more flexible, overrides individual vars)
# AGENT_CONFIGS={"google_engineer": {"provider": "openai", "model": "gpt-4o"}, "mit_researcher": {"provider": "anthropic", "model": "claude-3-5-sonnet-20241022"}}

# ===== SEARCH CONFIGURATION =====
# Minimum similarity threshold for vector search results
MIN_SIMILARITY_THRESHOLD=0.5

# Enable ArXiv fallback search when local results are insufficient
ENABLE_ARXIV_FALLBACK=true

# Maximum papers to fetch from ArXiv fallback
ARXIV_FALLBACK_MAX_PAPERS=10

# Enable AI-powered query expansion
ENABLE_QUERY_EXPANSION=true

# Maximum number of query expansions to generate
MAX_QUERY_EXPANSIONS=3

# ===== AGENT DISCUSSION CONFIGURATION =====
# Enable multi-agent discussions and insights
ENABLE_AGENT_DISCUSSIONS=true

# Default selected agents (comma-separated)
DEFAULT_SELECTED_AGENTS=Google Engineer,MIT Researcher,Industry Expert,Paper Analyst

# ===== RESEARCH PARAMETERS =====
# Default maximum papers per research session
DEFAULT_MAX_PAPERS=20

# Default setting for including recent papers
DEFAULT_INCLUDE_RECENT=true

# ===== VECTOR DATABASE CONFIGURATION =====
# Path to vector database storage
VECTOR_DB_PATH=./data/vector_db

# Maximum papers per query
MAX_PAPERS_PER_QUERY=50

# Text chunking parameters
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ===== LOGGING CONFIGURATION =====
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path
LOG_FILE=logs/research_agent.log

# ===== SERVER CONFIGURATION =====
# Streamlit server settings
STREAMLIT_HOST=localhost
STREAMLIT_PORT=8501

# ===== ADVANCED CONFIGURATION =====
# Cache TTL for research topics (seconds)
RESEARCH_TOPICS_CACHE_TTL=3600